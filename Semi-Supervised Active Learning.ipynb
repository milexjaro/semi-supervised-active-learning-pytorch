{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6612ba4",
   "metadata": {},
   "source": [
    "This notebook serves as the Deep Bayesian Active Learning paper implementation based on:\n",
    "- https://github.com/damienlancry/DBAL/blob/master/dbal_pytorch.ipynb\n",
    "- https://github.com/wohlert/semi-supervised-pytorch/blob/master/examples/notebooks/Deep%20Generative%20Model.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6582b740",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "\n",
    "DATASET = \"FashionMNIST\"\n",
    "# Set number of initial labelled data per class\n",
    "INITIAL_LABEL_PER_CLASS = 10\n",
    "N_LABELS = 10 #MNIST\n",
    "SEED = 2022\n",
    "\n",
    "BASE_DIR = '.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56fa5b9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import MNIST, FashionMNIST, CIFAR10\n",
    "from skorch import NeuralNetClassifier\n",
    "from modAL.models import ActiveLearner\n",
    "from torchsummary import summary\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "\n",
    "import seaborn as sns\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8800ea06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use cuda if available\n",
    "cuda = torch.cuda.is_available()\n",
    "# Add a semi supervised module\n",
    "sys.path.insert(0, '{BASE_DIR}/semi-supervised')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24d9712a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "  random.seed(seed)\n",
    "  os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "  np.random.seed(seed)\n",
    "  torch.manual_seed(seed)\n",
    "  torch.backends.cudnn.deterministic = True\n",
    "  torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b93caa30",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0425ef",
   "metadata": {},
   "source": [
    "### Network Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "349924b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, dataset=\"MNIST\"):\n",
    "        super(CNN, self).__init__()\n",
    "        self.dataset = dataset\n",
    "        if dataset in (\"MNIST\", \"FashionMNIST\"):\n",
    "            self.convs = nn.Sequential(\n",
    "                            nn.Conv2d(1, 32, 4),\n",
    "                            nn.ReLU(),\n",
    "                            nn.Conv2d(32, 32, 4),\n",
    "                            nn.ReLU(),\n",
    "                            nn.MaxPool2d(2),\n",
    "                            nn.Dropout(0.25),\n",
    "                            nn.Flatten(),\n",
    "                            nn.Linear(11*11*32, 128),\n",
    "                            nn.ReLU(),\n",
    "                            nn.Dropout(0.5),\n",
    "                            nn.Linear(128, 10)\n",
    "                        )\n",
    "        elif dataset == \"CIFAR10\":\n",
    "            self.convs = nn.Sequential(\n",
    "                        nn.Conv2d(3, 32, 4),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Conv2d(32, 32, 4),\n",
    "                        nn.ReLU(),\n",
    "                        nn.MaxPool2d(2),\n",
    "                        nn.Dropout(0.25),\n",
    "                        nn.Flatten(),\n",
    "                        nn.Linear(13*13*32, 128),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Dropout(0.5),\n",
    "                        nn.Linear(128, 10)\n",
    "                    )\n",
    "\n",
    "    def forward(self, x):\n",
    "        if len(x.shape) != 2:\n",
    "            out = x\n",
    "        else:\n",
    "            if self.dataset in (\"MNIST\", \"FashionMNIST\"):\n",
    "                out = x.reshape(-1, 1, 28, 28)\n",
    "            elif self.dataset == \"CIFAR10\":\n",
    "                out = x.reshape(-1, 3, 32, 32)\n",
    "        out = self.convs(out)\n",
    "        out = F.softmax(out, dim=-1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "539f8cb0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if DATASET in (\"MNIST\", \"FashionMNIST\"):\n",
    "    summary(CNN().convs, (1,28,28), device=\"cpu\")\n",
    "elif DATASET == \"CIFAR10\":\n",
    "    summary(CNN().convs, (3,32,32), device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fa309851",
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATASET == \"MNIST\":\n",
    "    train = MNIST('.', train=True, download=True, transform=ToTensor())\n",
    "    test = MNIST('.', train=False, download=True, transform=ToTensor())\n",
    "    train_data_loader = DataLoader(train, shuffle = True, batch_size = 60_000)\n",
    "    test_data_loader = DataLoader(test, shuffle = True, batch_size = 10_000)\n",
    "elif DATASET == \"FashionMNIST\":\n",
    "    train = FashionMNIST('.', train=True, download=True, transform=ToTensor())\n",
    "    test = FashionMNIST('.', train=False, download=True, transform=ToTensor())\n",
    "    train_data_loader = DataLoader(train, shuffle = True, batch_size = 60_000)\n",
    "    test_data_loader = DataLoader(test, shuffle = True, batch_size = 10_000)\n",
    "elif DATASET == \"CIFAR10\":\n",
    "    train = CIFAR10('.', train=True, download=True, transform=ToTensor())\n",
    "    test = CIFAR10('.', train=False, download=True, transform=ToTensor())\n",
    "    train_data_loader = DataLoader(train, shuffle = True, batch_size = 50_000)\n",
    "    test_data_loader = DataLoader(test, shuffle = True, batch_size = 10_000)\n",
    "\n",
    "\n",
    "X_train, y_train = next(iter(train_data_loader))\n",
    "X_train = X_train.detach().cpu().numpy()\n",
    "y_train = y_train.detach().cpu().numpy()\n",
    "\n",
    "X_test, y_test = next(iter(test_data_loader))\n",
    "X_test = X_test.detach().cpu().numpy()\n",
    "y_test = y_test.detach().cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9537453a",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "27f454c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(60_000, 1, 28, 28)\n",
    "X_test = X_test.reshape(10_000, 1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2ac0a665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create initial labelled data\n",
    "# Take INITIAL_LABELLED_PER_CLASS samples from each digit\n",
    "initial_labelled_idx = np.array([],dtype=np.int64)\n",
    "for i in range(N_LABELS):\n",
    "    idx = np.random.choice(np.where(y_train==i)[0], size=INITIAL_LABEL_PER_CLASS, replace=False)\n",
    "    initial_labelled_idx = np.concatenate((initial_labelled_idx, idx))\n",
    "\n",
    "X_train_labelled_initial = X_train[initial_labelled_idx]\n",
    "y_train_labelled_initial = y_train[initial_labelled_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9dc03dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pool of unlabelled data\n",
    "X_train_unlabelled = np.delete(X_train, initial_labelled_idx, axis = 0)\n",
    "y_train_unlabelled = np.delete(y_train, initial_labelled_idx, axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a499c75",
   "metadata": {},
   "source": [
    "### Query Strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d81f0dc",
   "metadata": {},
   "source": [
    "#### Random (Uniform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "301a3d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniform(learner, X, n_instances = 1):\n",
    "    query_idx = np.random.choice(range(len(X)), size = n_instances, replace = False)\n",
    "    return query_idx, X[query_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ead77e",
   "metadata": {},
   "source": [
    "#### Bald"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "48e2dc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bald(learner, X, n_instances=1, T=100):\n",
    "    random_subset = np.random.choice(range(len(X)), size=2000, replace=False)\n",
    "    with torch.no_grad():\n",
    "        outputs = np.stack([torch.softmax(learner.estimator.forward(X[random_subset], training=True),dim=-1).cpu().numpy()\n",
    "                            for t in range(100)])\n",
    "    pc = outputs.mean(axis=0)\n",
    "    H   = (-pc*np.log(pc + 1e-10)).sum(axis=-1)\n",
    "    E_H = - np.mean(np.sum(outputs * np.log(outputs + 1e-10), axis=-1), axis=0)  # [batch size]\n",
    "    acquisition = H - E_H\n",
    "    idx = (-acquisition).argsort()[:n_instances]\n",
    "    query_idx = random_subset[idx]\n",
    "    return query_idx, X[query_idx]    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6640132",
   "metadata": {},
   "source": [
    "### Active Learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b42c881a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "query_strategies = {'random':{'function':uniform,\n",
    "                                'classifier': None,\n",
    "                                'learner': None,\n",
    "                                'performance_history': None},\n",
    "                    'bald':{'function':bald,\n",
    "                                'classifier': None,\n",
    "                                'learner': None,\n",
    "                                'performance_history': None},\n",
    "                    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8db2c23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def active_learning_procedure(query_strategy,\n",
    "                              X_test,\n",
    "                              y_test,\n",
    "                              X_pool,\n",
    "                              y_pool,\n",
    "                              X_initial,\n",
    "                              y_initial,\n",
    "                              estimator,\n",
    "                              n_queries=1000,\n",
    "                              n_instances=1,\n",
    "                              query_strategy_label=''):\n",
    "    learner = ActiveLearner(estimator=estimator,\n",
    "                            X_training=X_initial,\n",
    "                            y_training=y_initial,\n",
    "                            query_strategy=query_strategy,\n",
    "                           )\n",
    "    perf_hist = [learner.score(X_test, y_test)]\n",
    "    for index in range(n_queries):\n",
    "        query_idx, query_instance = learner.query(X_pool, n_instances)\n",
    "        learner.teach(X_pool[query_idx], y_pool[query_idx])\n",
    "        X_pool = np.delete(X_pool, query_idx, axis=0)\n",
    "        y_pool = np.delete(y_pool, query_idx, axis=0)\n",
    "        model_accuracy = learner.score(X_test, y_test)\n",
    "        print('{q}Accuracy after query {n}: {acc:0.4f}'.format(q=f'[{query_strategy_label}] ', n=index + 1, acc=model_accuracy))\n",
    "        perf_hist.append(model_accuracy)\n",
    "\n",
    "    # Save after-query labelled and unlabelled data\n",
    "    torch.save(learner.X_training, f'{BASE_DIR}/saved_data/{DATASET}_X_train_labelled_{query_strategy_label}_{N_LABELS*INITIAL_LABEL_PER_CLASS}_{SEED}.pt')\n",
    "    torch.save(learner.y_training, f'{BASE_DIR}/saved_data/{DATASET}_y_train_labelled_{query_strategy_label}_{N_LABELS*INITIAL_LABEL_PER_CLASS}_{SEED}.pt')\n",
    "\n",
    "    torch.save(X_pool, f'{BASE_DIR}/saved_data/{DATASET}_X_train_unlabelled_{query_strategy_label}_{N_LABELS*INITIAL_LABEL_PER_CLASS}_{SEED}.pt')\n",
    "    torch.save(y_pool, f'{BASE_DIR}/saved_data/{DATASET}_y_train_unlabelled_{query_strategy_label}_{N_LABELS*INITIAL_LABEL_PER_CLASS}_{SEED}.pt')\n",
    "\n",
    "    return learner, perf_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8dba7250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[random] Accuracy after query 1: 0.7912\n",
      "[random] Accuracy after query 2: 0.8118\n",
      "[random] Accuracy after query 3: 0.7779\n",
      "[random] Accuracy after query 4: 0.7864\n",
      "[random] Accuracy after query 5: 0.7963\n",
      "[random] Accuracy after query 6: 0.8013\n",
      "[random] Accuracy after query 7: 0.8041\n",
      "[random] Accuracy after query 8: 0.8045\n",
      "[random] Accuracy after query 9: 0.8026\n",
      "[random] Accuracy after query 10: 0.8163\n",
      "[random] Accuracy after query 11: 0.8234\n",
      "[random] Accuracy after query 12: 0.8142\n",
      "[random] Accuracy after query 13: 0.8151\n",
      "[random] Accuracy after query 14: 0.8318\n",
      "[random] Accuracy after query 15: 0.8252\n",
      "[random] Accuracy after query 16: 0.8050\n",
      "[random] Accuracy after query 17: 0.8232\n",
      "[random] Accuracy after query 18: 0.8098\n",
      "[random] Accuracy after query 19: 0.8044\n",
      "[random] Accuracy after query 20: 0.8009\n",
      "[random] Accuracy after query 21: 0.8110\n",
      "[random] Accuracy after query 22: 0.8313\n",
      "[random] Accuracy after query 23: 0.8278\n",
      "[random] Accuracy after query 24: 0.8264\n",
      "[random] Accuracy after query 25: 0.8418\n",
      "[random] Accuracy after query 26: 0.8416\n",
      "[random] Accuracy after query 27: 0.8273\n",
      "[random] Accuracy after query 28: 0.8256\n",
      "[random] Accuracy after query 29: 0.8461\n",
      "[random] Accuracy after query 30: 0.8384\n",
      "[random] Accuracy after query 31: 0.8341\n",
      "[random] Accuracy after query 32: 0.8411\n",
      "[random] Accuracy after query 33: 0.8369\n",
      "[random] Accuracy after query 34: 0.8150\n",
      "[random] Accuracy after query 35: 0.8347\n",
      "[random] Accuracy after query 36: 0.8323\n",
      "[random] Accuracy after query 37: 0.8362\n",
      "[random] Accuracy after query 38: 0.8318\n",
      "[random] Accuracy after query 39: 0.8346\n",
      "[random] Accuracy after query 40: 0.8365\n",
      "[random] Accuracy after query 41: 0.8420\n",
      "[random] Accuracy after query 42: 0.8282\n",
      "[random] Accuracy after query 43: 0.8420\n",
      "[random] Accuracy after query 44: 0.8327\n",
      "[random] Accuracy after query 45: 0.8226\n",
      "[random] Accuracy after query 46: 0.8499\n",
      "[random] Accuracy after query 47: 0.8256\n",
      "[random] Accuracy after query 48: 0.8379\n",
      "[random] Accuracy after query 49: 0.8335\n",
      "[random] Accuracy after query 50: 0.8332\n",
      "[random] Accuracy after query 51: 0.8202\n",
      "[random] Accuracy after query 52: 0.8399\n",
      "[random] Accuracy after query 53: 0.8244\n",
      "[random] Accuracy after query 54: 0.8267\n",
      "[random] Accuracy after query 55: 0.8526\n",
      "[random] Accuracy after query 56: 0.8397\n",
      "[random] Accuracy after query 57: 0.8462\n",
      "[random] Accuracy after query 58: 0.8492\n",
      "[random] Accuracy after query 59: 0.8418\n",
      "[random] Accuracy after query 60: 0.8399\n",
      "[random] Accuracy after query 61: 0.8468\n",
      "[random] Accuracy after query 62: 0.8594\n",
      "[random] Accuracy after query 63: 0.8414\n",
      "[random] Accuracy after query 64: 0.8416\n",
      "[random] Accuracy after query 65: 0.8417\n",
      "[random] Accuracy after query 66: 0.8341\n",
      "[random] Accuracy after query 67: 0.8523\n",
      "[random] Accuracy after query 68: 0.8577\n",
      "[random] Accuracy after query 69: 0.8597\n",
      "[random] Accuracy after query 70: 0.8489\n",
      "[random] Accuracy after query 71: 0.8359\n",
      "[random] Accuracy after query 72: 0.8521\n",
      "[random] Accuracy after query 73: 0.8536\n",
      "[random] Accuracy after query 74: 0.8666\n",
      "[random] Accuracy after query 75: 0.8361\n",
      "[random] Accuracy after query 76: 0.8577\n",
      "[random] Accuracy after query 77: 0.8559\n",
      "[random] Accuracy after query 78: 0.8507\n",
      "[random] Accuracy after query 79: 0.8468\n",
      "[random] Accuracy after query 80: 0.8486\n",
      "[random] Accuracy after query 81: 0.8516\n",
      "[random] Accuracy after query 82: 0.8647\n",
      "[random] Accuracy after query 83: 0.8696\n",
      "[random] Accuracy after query 84: 0.8476\n",
      "[random] Accuracy after query 85: 0.8550\n",
      "[random] Accuracy after query 86: 0.8461\n",
      "[random] Accuracy after query 87: 0.8472\n",
      "[random] Accuracy after query 88: 0.8495\n",
      "[random] Accuracy after query 89: 0.8753\n",
      "[random] Accuracy after query 90: 0.8525\n",
      "[random] Accuracy after query 91: 0.8615\n",
      "[random] Accuracy after query 92: 0.8718\n",
      "[random] Accuracy after query 93: 0.8643\n",
      "[random] Accuracy after query 94: 0.8675\n",
      "[random] Accuracy after query 95: 0.8585\n",
      "[random] Accuracy after query 96: 0.8559\n",
      "[random] Accuracy after query 97: 0.8588\n",
      "[random] Accuracy after query 98: 0.8739\n",
      "[random] Accuracy after query 99: 0.8726\n",
      "[random] Accuracy after query 100: 0.8721\n",
      "[random] Accuracy after query 101: 0.8572\n",
      "[random] Accuracy after query 102: 0.8650\n",
      "[random] Accuracy after query 103: 0.8735\n",
      "[random] Accuracy after query 104: 0.8729\n",
      "[random] Accuracy after query 105: 0.8638\n",
      "[random] Accuracy after query 106: 0.8831\n",
      "[random] Accuracy after query 107: 0.8804\n",
      "[random] Accuracy after query 108: 0.8774\n",
      "[random] Accuracy after query 109: 0.8686\n",
      "[random] Accuracy after query 110: 0.8742\n",
      "[random] Accuracy after query 111: 0.8645\n",
      "[random] Accuracy after query 112: 0.8712\n",
      "[random] Accuracy after query 113: 0.8496\n",
      "[random] Accuracy after query 114: 0.8662\n",
      "[random] Accuracy after query 115: 0.8816\n",
      "[random] Accuracy after query 116: 0.8676\n",
      "[random] Accuracy after query 117: 0.8663\n",
      "[random] Accuracy after query 118: 0.8571\n",
      "[random] Accuracy after query 119: 0.8749\n",
      "[random] Accuracy after query 120: 0.8678\n",
      "[random] Accuracy after query 121: 0.8742\n",
      "[random] Accuracy after query 122: 0.8849\n",
      "[random] Accuracy after query 123: 0.8643\n",
      "[random] Accuracy after query 124: 0.8659\n",
      "[random] Accuracy after query 125: 0.8822\n",
      "[random] Accuracy after query 126: 0.8782\n",
      "[random] Accuracy after query 127: 0.8739\n",
      "[random] Accuracy after query 128: 0.8662\n",
      "[random] Accuracy after query 129: 0.8703\n",
      "[random] Accuracy after query 130: 0.8634\n",
      "[random] Accuracy after query 131: 0.8741\n",
      "[random] Accuracy after query 132: 0.8886\n",
      "[random] Accuracy after query 133: 0.8708\n",
      "[random] Accuracy after query 134: 0.8608\n",
      "[random] Accuracy after query 135: 0.8660\n",
      "[random] Accuracy after query 136: 0.8730\n",
      "[random] Accuracy after query 137: 0.8757\n",
      "[random] Accuracy after query 138: 0.8877\n",
      "[random] Accuracy after query 139: 0.8707\n",
      "[random] Accuracy after query 140: 0.8814\n",
      "[random] Accuracy after query 141: 0.8754\n",
      "[random] Accuracy after query 142: 0.8704\n",
      "[random] Accuracy after query 143: 0.8788\n",
      "[random] Accuracy after query 144: 0.8727\n",
      "[random] Accuracy after query 145: 0.8752\n",
      "[random] Accuracy after query 146: 0.8838\n",
      "[random] Accuracy after query 147: 0.8749\n",
      "[random] Accuracy after query 148: 0.8788\n",
      "[random] Accuracy after query 149: 0.8920\n",
      "[random] Accuracy after query 150: 0.8796\n",
      "[random] Accuracy after query 151: 0.8799\n",
      "[random] Accuracy after query 152: 0.8740\n",
      "[random] Accuracy after query 153: 0.8745\n",
      "[random] Accuracy after query 154: 0.8789\n",
      "[random] Accuracy after query 155: 0.8753\n",
      "[random] Accuracy after query 156: 0.8814\n",
      "[random] Accuracy after query 157: 0.8923\n",
      "[random] Accuracy after query 158: 0.8864\n",
      "[random] Accuracy after query 159: 0.8844\n",
      "[random] Accuracy after query 160: 0.8835\n",
      "[random] Accuracy after query 161: 0.8840\n",
      "[random] Accuracy after query 162: 0.8953\n",
      "[random] Accuracy after query 163: 0.8859\n",
      "[random] Accuracy after query 164: 0.8723\n",
      "[random] Accuracy after query 165: 0.8788\n",
      "[random] Accuracy after query 166: 0.8795\n",
      "[random] Accuracy after query 167: 0.8672\n",
      "[random] Accuracy after query 168: 0.8987\n",
      "[random] Accuracy after query 169: 0.8824\n",
      "[random] Accuracy after query 170: 0.8796\n",
      "[random] Accuracy after query 171: 0.8832\n",
      "[random] Accuracy after query 172: 0.8896\n",
      "[random] Accuracy after query 173: 0.8839\n",
      "[random] Accuracy after query 174: 0.8915\n",
      "[random] Accuracy after query 175: 0.8914\n",
      "[random] Accuracy after query 176: 0.8898\n",
      "[random] Accuracy after query 177: 0.8884\n",
      "[random] Accuracy after query 178: 0.8769\n",
      "[random] Accuracy after query 179: 0.8917\n",
      "[random] Accuracy after query 180: 0.9013\n",
      "[random] Accuracy after query 181: 0.8793\n",
      "[random] Accuracy after query 182: 0.8889\n",
      "[random] Accuracy after query 183: 0.8830\n",
      "[random] Accuracy after query 184: 0.8986\n",
      "[random] Accuracy after query 185: 0.9022\n",
      "[random] Accuracy after query 186: 0.9005\n",
      "[random] Accuracy after query 187: 0.8980\n",
      "[random] Accuracy after query 188: 0.8921\n",
      "[random] Accuracy after query 189: 0.8982\n",
      "[random] Accuracy after query 190: 0.9012\n",
      "[random] Accuracy after query 191: 0.9063\n",
      "[random] Accuracy after query 192: 0.9057\n",
      "[random] Accuracy after query 193: 0.9040\n",
      "[random] Accuracy after query 194: 0.9000\n",
      "[random] Accuracy after query 195: 0.8983\n",
      "[random] Accuracy after query 196: 0.8954\n",
      "[random] Accuracy after query 197: 0.9004\n",
      "[random] Accuracy after query 198: 0.9069\n",
      "[random] Accuracy after query 199: 0.9088\n",
      "[random] Accuracy after query 200: 0.9111\n",
      "[random] Accuracy after query 201: 0.9040\n",
      "[random] Accuracy after query 202: 0.9039\n",
      "[random] Accuracy after query 203: 0.9031\n",
      "[random] Accuracy after query 204: 0.9059\n",
      "[random] Accuracy after query 205: 0.8992\n",
      "[random] Accuracy after query 206: 0.9072\n",
      "[random] Accuracy after query 207: 0.9022\n",
      "[random] Accuracy after query 208: 0.9052\n",
      "[random] Accuracy after query 209: 0.9067\n",
      "[random] Accuracy after query 210: 0.8986\n",
      "[random] Accuracy after query 211: 0.9065\n",
      "[random] Accuracy after query 212: 0.9015\n",
      "[random] Accuracy after query 213: 0.9111\n",
      "[random] Accuracy after query 214: 0.8949\n",
      "[random] Accuracy after query 215: 0.8992\n",
      "[random] Accuracy after query 216: 0.9077\n",
      "[random] Accuracy after query 217: 0.9020\n",
      "[random] Accuracy after query 218: 0.9057\n",
      "[random] Accuracy after query 219: 0.9040\n",
      "[random] Accuracy after query 220: 0.9070\n",
      "[random] Accuracy after query 221: 0.9023\n",
      "[random] Accuracy after query 222: 0.9152\n",
      "[random] Accuracy after query 223: 0.9052\n",
      "[random] Accuracy after query 224: 0.9151\n",
      "[random] Accuracy after query 225: 0.9131\n",
      "[random] Accuracy after query 226: 0.9055\n",
      "[random] Accuracy after query 227: 0.9001\n",
      "[random] Accuracy after query 228: 0.9129\n",
      "[random] Accuracy after query 229: 0.9175\n",
      "[random] Accuracy after query 230: 0.9128\n",
      "[random] Accuracy after query 231: 0.9149\n",
      "[random] Accuracy after query 232: 0.9028\n",
      "[random] Accuracy after query 233: 0.9180\n",
      "[random] Accuracy after query 234: 0.9108\n",
      "[random] Accuracy after query 235: 0.9026\n",
      "[random] Accuracy after query 236: 0.9161\n",
      "[random] Accuracy after query 237: 0.9053\n",
      "[random] Accuracy after query 238: 0.9151\n",
      "[random] Accuracy after query 239: 0.9118\n",
      "[random] Accuracy after query 240: 0.9126\n",
      "[random] Accuracy after query 241: 0.9122\n",
      "[random] Accuracy after query 242: 0.9036\n",
      "[random] Accuracy after query 243: 0.9066\n",
      "[random] Accuracy after query 244: 0.9072\n",
      "[random] Accuracy after query 245: 0.9153\n",
      "[random] Accuracy after query 246: 0.8967\n",
      "[random] Accuracy after query 247: 0.9181\n",
      "[random] Accuracy after query 248: 0.9124\n",
      "[random] Accuracy after query 249: 0.9025\n",
      "[random] Accuracy after query 250: 0.9135\n",
      "[random] Accuracy after query 251: 0.9117\n",
      "[random] Accuracy after query 252: 0.9131\n",
      "[random] Accuracy after query 253: 0.9046\n",
      "[random] Accuracy after query 254: 0.9154\n",
      "[random] Accuracy after query 255: 0.9153\n",
      "[random] Accuracy after query 256: 0.9081\n",
      "[random] Accuracy after query 257: 0.9130\n",
      "[random] Accuracy after query 258: 0.8942\n",
      "[random] Accuracy after query 259: 0.9002\n",
      "[random] Accuracy after query 260: 0.9103\n",
      "[random] Accuracy after query 261: 0.9072\n",
      "[random] Accuracy after query 262: 0.9184\n",
      "[random] Accuracy after query 263: 0.9130\n",
      "[random] Accuracy after query 264: 0.9083\n",
      "[random] Accuracy after query 265: 0.9096\n",
      "[random] Accuracy after query 266: 0.9138\n",
      "[random] Accuracy after query 267: 0.9072\n",
      "[random] Accuracy after query 268: 0.9118\n",
      "[random] Accuracy after query 269: 0.9215\n",
      "[random] Accuracy after query 270: 0.9028\n",
      "[random] Accuracy after query 271: 0.9119\n",
      "[random] Accuracy after query 272: 0.9044\n",
      "[random] Accuracy after query 273: 0.9070\n",
      "[random] Accuracy after query 274: 0.9020\n",
      "[random] Accuracy after query 275: 0.9089\n",
      "[random] Accuracy after query 276: 0.9179\n",
      "[random] Accuracy after query 277: 0.9073\n",
      "[random] Accuracy after query 278: 0.9173\n",
      "[random] Accuracy after query 279: 0.9094\n",
      "[random] Accuracy after query 280: 0.9054\n",
      "[random] Accuracy after query 281: 0.9195\n",
      "[random] Accuracy after query 282: 0.9081\n",
      "[random] Accuracy after query 283: 0.9175\n",
      "[random] Accuracy after query 284: 0.9131\n",
      "[random] Accuracy after query 285: 0.9100\n",
      "[random] Accuracy after query 286: 0.9184\n",
      "[random] Accuracy after query 287: 0.9173\n",
      "[random] Accuracy after query 288: 0.9232\n",
      "[random] Accuracy after query 289: 0.9224\n",
      "[random] Accuracy after query 290: 0.9129\n",
      "[random] Accuracy after query 291: 0.9148\n",
      "[random] Accuracy after query 292: 0.9130\n",
      "[random] Accuracy after query 293: 0.9248\n",
      "[random] Accuracy after query 294: 0.9164\n",
      "[random] Accuracy after query 295: 0.9187\n",
      "[random] Accuracy after query 296: 0.9126\n",
      "[random] Accuracy after query 297: 0.9153\n",
      "[random] Accuracy after query 298: 0.9180\n",
      "[random] Accuracy after query 299: 0.9123\n",
      "[random] Accuracy after query 300: 0.9141\n",
      "[random] Accuracy after query 301: 0.9182\n",
      "[random] Accuracy after query 302: 0.9141\n",
      "[random] Accuracy after query 303: 0.9268\n",
      "[random] Accuracy after query 304: 0.9166\n",
      "[random] Accuracy after query 305: 0.9117\n",
      "[random] Accuracy after query 306: 0.9174\n",
      "[random] Accuracy after query 307: 0.9166\n",
      "[random] Accuracy after query 308: 0.9228\n",
      "[random] Accuracy after query 309: 0.9184\n",
      "[random] Accuracy after query 310: 0.9257\n",
      "[random] Accuracy after query 311: 0.9161\n",
      "[random] Accuracy after query 312: 0.9336\n",
      "[random] Accuracy after query 313: 0.9181\n",
      "[random] Accuracy after query 314: 0.9119\n",
      "[random] Accuracy after query 315: 0.9275\n",
      "[random] Accuracy after query 316: 0.9182\n",
      "[random] Accuracy after query 317: 0.9185\n",
      "[random] Accuracy after query 318: 0.9280\n",
      "[random] Accuracy after query 319: 0.9247\n",
      "[random] Accuracy after query 320: 0.9262\n",
      "[random] Accuracy after query 321: 0.9220\n",
      "[random] Accuracy after query 322: 0.9274\n",
      "[random] Accuracy after query 323: 0.9242\n",
      "[random] Accuracy after query 324: 0.9273\n",
      "[random] Accuracy after query 325: 0.9186\n",
      "[random] Accuracy after query 326: 0.9256\n",
      "[random] Accuracy after query 327: 0.9242\n",
      "[random] Accuracy after query 328: 0.9287\n",
      "[random] Accuracy after query 329: 0.9292\n",
      "[random] Accuracy after query 330: 0.9223\n",
      "[random] Accuracy after query 331: 0.9249\n",
      "[random] Accuracy after query 332: 0.9236\n",
      "[random] Accuracy after query 333: 0.9261\n",
      "[random] Accuracy after query 334: 0.9267\n",
      "[random] Accuracy after query 335: 0.9254\n",
      "[random] Accuracy after query 336: 0.9283\n",
      "[random] Accuracy after query 337: 0.9172\n",
      "[random] Accuracy after query 338: 0.9274\n",
      "[random] Accuracy after query 339: 0.9324\n",
      "[random] Accuracy after query 340: 0.9252\n",
      "[random] Accuracy after query 341: 0.9206\n",
      "[random] Accuracy after query 342: 0.9358\n",
      "[random] Accuracy after query 343: 0.9262\n",
      "[random] Accuracy after query 344: 0.9288\n",
      "[random] Accuracy after query 345: 0.9231\n",
      "[random] Accuracy after query 346: 0.9172\n",
      "[random] Accuracy after query 347: 0.9289\n",
      "[random] Accuracy after query 348: 0.9328\n",
      "[random] Accuracy after query 349: 0.9238\n",
      "[random] Accuracy after query 350: 0.9369\n",
      "[random] Accuracy after query 351: 0.9205\n",
      "[random] Accuracy after query 352: 0.9314\n",
      "[random] Accuracy after query 353: 0.9279\n",
      "[random] Accuracy after query 354: 0.9261\n",
      "[random] Accuracy after query 355: 0.9291\n",
      "[random] Accuracy after query 356: 0.9253\n",
      "[random] Accuracy after query 357: 0.9267\n",
      "[random] Accuracy after query 358: 0.9293\n",
      "[random] Accuracy after query 359: 0.9287\n",
      "[random] Accuracy after query 360: 0.9270\n",
      "[random] Accuracy after query 361: 0.9257\n",
      "[random] Accuracy after query 362: 0.9284\n",
      "[random] Accuracy after query 363: 0.9303\n",
      "[random] Accuracy after query 364: 0.9291\n",
      "[random] Accuracy after query 365: 0.9267\n",
      "[random] Accuracy after query 366: 0.9296\n",
      "[random] Accuracy after query 367: 0.9305\n",
      "[random] Accuracy after query 368: 0.9316\n",
      "[random] Accuracy after query 369: 0.9249\n",
      "[random] Accuracy after query 370: 0.9259\n",
      "[random] Accuracy after query 371: 0.9267\n",
      "[random] Accuracy after query 372: 0.9365\n",
      "[random] Accuracy after query 373: 0.9294\n",
      "[random] Accuracy after query 374: 0.9327\n",
      "[random] Accuracy after query 375: 0.9298\n",
      "[random] Accuracy after query 376: 0.9336\n",
      "[random] Accuracy after query 377: 0.9315\n",
      "[random] Accuracy after query 378: 0.9313\n",
      "[random] Accuracy after query 379: 0.9314\n",
      "[random] Accuracy after query 380: 0.9290\n",
      "[random] Accuracy after query 381: 0.9377\n",
      "[random] Accuracy after query 382: 0.9245\n",
      "[random] Accuracy after query 383: 0.9286\n",
      "[random] Accuracy after query 384: 0.9223\n",
      "[random] Accuracy after query 385: 0.9326\n",
      "[random] Accuracy after query 386: 0.9257\n",
      "[random] Accuracy after query 387: 0.9315\n",
      "[random] Accuracy after query 388: 0.9253\n",
      "[random] Accuracy after query 389: 0.9315\n",
      "[random] Accuracy after query 390: 0.9318\n",
      "[random] Accuracy after query 391: 0.9305\n",
      "[random] Accuracy after query 392: 0.9310\n",
      "[random] Accuracy after query 393: 0.9334\n",
      "[random] Accuracy after query 394: 0.9306\n",
      "[random] Accuracy after query 395: 0.9318\n",
      "[random] Accuracy after query 396: 0.9275\n",
      "[random] Accuracy after query 397: 0.9328\n",
      "[random] Accuracy after query 398: 0.9252\n",
      "[random] Accuracy after query 399: 0.9328\n",
      "[random] Accuracy after query 400: 0.9283\n",
      "[random] Accuracy after query 401: 0.9296\n",
      "[random] Accuracy after query 402: 0.9320\n",
      "[random] Accuracy after query 403: 0.9296\n",
      "[random] Accuracy after query 404: 0.9349\n",
      "[random] Accuracy after query 405: 0.9299\n",
      "[random] Accuracy after query 406: 0.9282\n",
      "[random] Accuracy after query 407: 0.9282\n",
      "[random] Accuracy after query 408: 0.9319\n",
      "[random] Accuracy after query 409: 0.9365\n",
      "[random] Accuracy after query 410: 0.9282\n",
      "[random] Accuracy after query 411: 0.9379\n",
      "[random] Accuracy after query 412: 0.9279\n",
      "[random] Accuracy after query 413: 0.9187\n",
      "[random] Accuracy after query 414: 0.9323\n",
      "[random] Accuracy after query 415: 0.9326\n",
      "[random] Accuracy after query 416: 0.9336\n",
      "[random] Accuracy after query 417: 0.9353\n",
      "[random] Accuracy after query 418: 0.9315\n",
      "[random] Accuracy after query 419: 0.9314\n",
      "[random] Accuracy after query 420: 0.9307\n",
      "[random] Accuracy after query 421: 0.9304\n",
      "[random] Accuracy after query 422: 0.9273\n",
      "[random] Accuracy after query 423: 0.9342\n",
      "[random] Accuracy after query 424: 0.9350\n",
      "[random] Accuracy after query 425: 0.9300\n",
      "[random] Accuracy after query 426: 0.9302\n",
      "[random] Accuracy after query 427: 0.9317\n",
      "[random] Accuracy after query 428: 0.9274\n",
      "[random] Accuracy after query 429: 0.9360\n",
      "[random] Accuracy after query 430: 0.9261\n",
      "[random] Accuracy after query 431: 0.9286\n",
      "[random] Accuracy after query 432: 0.9351\n",
      "[random] Accuracy after query 433: 0.9408\n",
      "[random] Accuracy after query 434: 0.9354\n",
      "[random] Accuracy after query 435: 0.9319\n",
      "[random] Accuracy after query 436: 0.9345\n",
      "[random] Accuracy after query 437: 0.9347\n",
      "[random] Accuracy after query 438: 0.9359\n",
      "[random] Accuracy after query 439: 0.9301\n",
      "[random] Accuracy after query 440: 0.9358\n",
      "[random] Accuracy after query 441: 0.9370\n",
      "[random] Accuracy after query 442: 0.9376\n",
      "[random] Accuracy after query 443: 0.9328\n",
      "[random] Accuracy after query 444: 0.9353\n",
      "[random] Accuracy after query 445: 0.9357\n",
      "[random] Accuracy after query 446: 0.9365\n",
      "[random] Accuracy after query 447: 0.9316\n",
      "[random] Accuracy after query 448: 0.9324\n",
      "[random] Accuracy after query 449: 0.9335\n",
      "[random] Accuracy after query 450: 0.9372\n",
      "[random] Accuracy after query 451: 0.9353\n",
      "[random] Accuracy after query 452: 0.9327\n",
      "[random] Accuracy after query 453: 0.9393\n",
      "[random] Accuracy after query 454: 0.9353\n",
      "[random] Accuracy after query 455: 0.9335\n",
      "[random] Accuracy after query 456: 0.9373\n",
      "[random] Accuracy after query 457: 0.9409\n",
      "[random] Accuracy after query 458: 0.9381\n",
      "[random] Accuracy after query 459: 0.9370\n",
      "[random] Accuracy after query 460: 0.9380\n",
      "[random] Accuracy after query 461: 0.9353\n",
      "[random] Accuracy after query 462: 0.9363\n",
      "[random] Accuracy after query 463: 0.9396\n",
      "[random] Accuracy after query 464: 0.9377\n",
      "[random] Accuracy after query 465: 0.9370\n",
      "[random] Accuracy after query 466: 0.9349\n",
      "[random] Accuracy after query 467: 0.9388\n",
      "[random] Accuracy after query 468: 0.9419\n",
      "[random] Accuracy after query 469: 0.9385\n",
      "[random] Accuracy after query 470: 0.9368\n",
      "[random] Accuracy after query 471: 0.9319\n",
      "[random] Accuracy after query 472: 0.9357\n",
      "[random] Accuracy after query 473: 0.9377\n",
      "[random] Accuracy after query 474: 0.9371\n",
      "[random] Accuracy after query 475: 0.9365\n",
      "[random] Accuracy after query 476: 0.9283\n",
      "[random] Accuracy after query 477: 0.9405\n",
      "[random] Accuracy after query 478: 0.9419\n",
      "[random] Accuracy after query 479: 0.9369\n",
      "[random] Accuracy after query 480: 0.9362\n",
      "[random] Accuracy after query 481: 0.9400\n",
      "[random] Accuracy after query 482: 0.9437\n",
      "[random] Accuracy after query 483: 0.9419\n",
      "[random] Accuracy after query 484: 0.9362\n",
      "[random] Accuracy after query 485: 0.9361\n",
      "[random] Accuracy after query 486: 0.9349\n",
      "[random] Accuracy after query 487: 0.9409\n",
      "[random] Accuracy after query 488: 0.9347\n",
      "[random] Accuracy after query 489: 0.9364\n",
      "[random] Accuracy after query 490: 0.9346\n",
      "[random] Accuracy after query 491: 0.9464\n",
      "[random] Accuracy after query 492: 0.9356\n",
      "[random] Accuracy after query 493: 0.9391\n",
      "[random] Accuracy after query 494: 0.9416\n",
      "[random] Accuracy after query 495: 0.9379\n",
      "[random] Accuracy after query 496: 0.9303\n",
      "[random] Accuracy after query 497: 0.9393\n",
      "[random] Accuracy after query 498: 0.9415\n",
      "[random] Accuracy after query 499: 0.9368\n",
      "[random] Accuracy after query 500: 0.9336\n",
      "[random] Accuracy after query 501: 0.9331\n",
      "[random] Accuracy after query 502: 0.9354\n",
      "[random] Accuracy after query 503: 0.9331\n",
      "[random] Accuracy after query 504: 0.9409\n",
      "[random] Accuracy after query 505: 0.9399\n",
      "[random] Accuracy after query 506: 0.9390\n",
      "[random] Accuracy after query 507: 0.9347\n",
      "[random] Accuracy after query 508: 0.9377\n",
      "[random] Accuracy after query 509: 0.9369\n",
      "[random] Accuracy after query 510: 0.9362\n",
      "[random] Accuracy after query 511: 0.9395\n",
      "[random] Accuracy after query 512: 0.9443\n",
      "[random] Accuracy after query 513: 0.9366\n",
      "[random] Accuracy after query 514: 0.9374\n",
      "[random] Accuracy after query 515: 0.9399\n",
      "[random] Accuracy after query 516: 0.9328\n",
      "[random] Accuracy after query 517: 0.9361\n",
      "[random] Accuracy after query 518: 0.9400\n",
      "[random] Accuracy after query 519: 0.9477\n",
      "[random] Accuracy after query 520: 0.9364\n",
      "[random] Accuracy after query 521: 0.9404\n",
      "[random] Accuracy after query 522: 0.9431\n",
      "[random] Accuracy after query 523: 0.9356\n",
      "[random] Accuracy after query 524: 0.9361\n",
      "[random] Accuracy after query 525: 0.9414\n",
      "[random] Accuracy after query 526: 0.9425\n",
      "[random] Accuracy after query 527: 0.9337\n",
      "[random] Accuracy after query 528: 0.9437\n",
      "[random] Accuracy after query 529: 0.9423\n",
      "[random] Accuracy after query 530: 0.9337\n",
      "[random] Accuracy after query 531: 0.9322\n",
      "[random] Accuracy after query 532: 0.9448\n",
      "[random] Accuracy after query 533: 0.9423\n",
      "[random] Accuracy after query 534: 0.9400\n",
      "[random] Accuracy after query 535: 0.9409\n",
      "[random] Accuracy after query 536: 0.9410\n",
      "[random] Accuracy after query 537: 0.9378\n",
      "[random] Accuracy after query 538: 0.9326\n",
      "[random] Accuracy after query 539: 0.9311\n",
      "[random] Accuracy after query 540: 0.9353\n",
      "[random] Accuracy after query 541: 0.9412\n",
      "[random] Accuracy after query 542: 0.9368\n",
      "[random] Accuracy after query 543: 0.9376\n",
      "[random] Accuracy after query 544: 0.9261\n",
      "[random] Accuracy after query 545: 0.9383\n",
      "[random] Accuracy after query 546: 0.9276\n",
      "[random] Accuracy after query 547: 0.9406\n",
      "[random] Accuracy after query 548: 0.9323\n",
      "[random] Accuracy after query 549: 0.9399\n",
      "[random] Accuracy after query 550: 0.9369\n",
      "[random] Accuracy after query 551: 0.9341\n",
      "[random] Accuracy after query 552: 0.9352\n",
      "[random] Accuracy after query 553: 0.9429\n",
      "[random] Accuracy after query 554: 0.9424\n",
      "[random] Accuracy after query 555: 0.9363\n",
      "[random] Accuracy after query 556: 0.9391\n",
      "[random] Accuracy after query 557: 0.9392\n",
      "[random] Accuracy after query 558: 0.9454\n",
      "[random] Accuracy after query 559: 0.9322\n",
      "[random] Accuracy after query 560: 0.9369\n",
      "[random] Accuracy after query 561: 0.9384\n",
      "[random] Accuracy after query 562: 0.9419\n",
      "[random] Accuracy after query 563: 0.9400\n",
      "[random] Accuracy after query 564: 0.9394\n",
      "[random] Accuracy after query 565: 0.9434\n",
      "[random] Accuracy after query 566: 0.9386\n",
      "[random] Accuracy after query 567: 0.9378\n",
      "[random] Accuracy after query 568: 0.9399\n",
      "[random] Accuracy after query 569: 0.9414\n",
      "[random] Accuracy after query 570: 0.9433\n",
      "[random] Accuracy after query 571: 0.9403\n",
      "[random] Accuracy after query 572: 0.9367\n",
      "[random] Accuracy after query 573: 0.9407\n",
      "[random] Accuracy after query 574: 0.9390\n",
      "[random] Accuracy after query 575: 0.9414\n",
      "[random] Accuracy after query 576: 0.9400\n",
      "[random] Accuracy after query 577: 0.9375\n",
      "[random] Accuracy after query 578: 0.9387\n",
      "[random] Accuracy after query 579: 0.9434\n",
      "[random] Accuracy after query 580: 0.9327\n",
      "[random] Accuracy after query 581: 0.9340\n",
      "[random] Accuracy after query 582: 0.9423\n",
      "[random] Accuracy after query 583: 0.9396\n",
      "[random] Accuracy after query 584: 0.9372\n",
      "[random] Accuracy after query 585: 0.9383\n",
      "[random] Accuracy after query 586: 0.9418\n",
      "[random] Accuracy after query 587: 0.9412\n",
      "[random] Accuracy after query 588: 0.9385\n",
      "[random] Accuracy after query 589: 0.9432\n",
      "[random] Accuracy after query 590: 0.9424\n",
      "[random] Accuracy after query 591: 0.9364\n",
      "[random] Accuracy after query 592: 0.9343\n",
      "[random] Accuracy after query 593: 0.9316\n",
      "[random] Accuracy after query 594: 0.9392\n",
      "[random] Accuracy after query 595: 0.9357\n",
      "[random] Accuracy after query 596: 0.9413\n",
      "[random] Accuracy after query 597: 0.9386\n",
      "[random] Accuracy after query 598: 0.9455\n",
      "[random] Accuracy after query 599: 0.9375\n",
      "[random] Accuracy after query 600: 0.9383\n",
      "[random] Accuracy after query 601: 0.9400\n",
      "[random] Accuracy after query 602: 0.9392\n",
      "[random] Accuracy after query 603: 0.9410\n",
      "[random] Accuracy after query 604: 0.9399\n",
      "[random] Accuracy after query 605: 0.9387\n",
      "[random] Accuracy after query 606: 0.9378\n",
      "[random] Accuracy after query 607: 0.9358\n",
      "[random] Accuracy after query 608: 0.9441\n",
      "[random] Accuracy after query 609: 0.9401\n",
      "[random] Accuracy after query 610: 0.9444\n",
      "[random] Accuracy after query 611: 0.9441\n",
      "[random] Accuracy after query 612: 0.9349\n",
      "[random] Accuracy after query 613: 0.9461\n",
      "[random] Accuracy after query 614: 0.9414\n",
      "[random] Accuracy after query 615: 0.9409\n",
      "[random] Accuracy after query 616: 0.9343\n",
      "[random] Accuracy after query 617: 0.9378\n",
      "[random] Accuracy after query 618: 0.9385\n",
      "[random] Accuracy after query 619: 0.9340\n",
      "[random] Accuracy after query 620: 0.9383\n",
      "[random] Accuracy after query 621: 0.9371\n",
      "[random] Accuracy after query 622: 0.9417\n",
      "[random] Accuracy after query 623: 0.9437\n",
      "[random] Accuracy after query 624: 0.9418\n",
      "[random] Accuracy after query 625: 0.9367\n",
      "[random] Accuracy after query 626: 0.9427\n",
      "[random] Accuracy after query 627: 0.9359\n",
      "[random] Accuracy after query 628: 0.9443\n",
      "[random] Accuracy after query 629: 0.9425\n",
      "[random] Accuracy after query 630: 0.9437\n",
      "[random] Accuracy after query 631: 0.9384\n",
      "[random] Accuracy after query 632: 0.9385\n",
      "[random] Accuracy after query 633: 0.9415\n",
      "[random] Accuracy after query 634: 0.9376\n",
      "[random] Accuracy after query 635: 0.9406\n",
      "[random] Accuracy after query 636: 0.9396\n",
      "[random] Accuracy after query 637: 0.9398\n",
      "[random] Accuracy after query 638: 0.9360\n",
      "[random] Accuracy after query 639: 0.9400\n",
      "[random] Accuracy after query 640: 0.9416\n",
      "[random] Accuracy after query 641: 0.9395\n",
      "[random] Accuracy after query 642: 0.9375\n",
      "[random] Accuracy after query 643: 0.9462\n",
      "[random] Accuracy after query 644: 0.9410\n",
      "[random] Accuracy after query 645: 0.9390\n",
      "[random] Accuracy after query 646: 0.9385\n",
      "[random] Accuracy after query 647: 0.9461\n",
      "[random] Accuracy after query 648: 0.9387\n",
      "[random] Accuracy after query 649: 0.9433\n",
      "[random] Accuracy after query 650: 0.9494\n",
      "[random] Accuracy after query 651: 0.9438\n",
      "[random] Accuracy after query 652: 0.9428\n",
      "[random] Accuracy after query 653: 0.9448\n",
      "[random] Accuracy after query 654: 0.9435\n",
      "[random] Accuracy after query 655: 0.9464\n",
      "[random] Accuracy after query 656: 0.9406\n",
      "[random] Accuracy after query 657: 0.9457\n",
      "[random] Accuracy after query 658: 0.9401\n",
      "[random] Accuracy after query 659: 0.9381\n",
      "[random] Accuracy after query 660: 0.9429\n",
      "[random] Accuracy after query 661: 0.9448\n",
      "[random] Accuracy after query 662: 0.9424\n",
      "[random] Accuracy after query 663: 0.9381\n",
      "[random] Accuracy after query 664: 0.9451\n",
      "[random] Accuracy after query 665: 0.9423\n",
      "[random] Accuracy after query 666: 0.9442\n",
      "[random] Accuracy after query 667: 0.9428\n",
      "[random] Accuracy after query 668: 0.9401\n",
      "[random] Accuracy after query 669: 0.9382\n",
      "[random] Accuracy after query 670: 0.9419\n",
      "[random] Accuracy after query 671: 0.9401\n",
      "[random] Accuracy after query 672: 0.9439\n",
      "[random] Accuracy after query 673: 0.9427\n",
      "[random] Accuracy after query 674: 0.9385\n",
      "[random] Accuracy after query 675: 0.9412\n",
      "[random] Accuracy after query 676: 0.9440\n",
      "[random] Accuracy after query 677: 0.9439\n",
      "[random] Accuracy after query 678: 0.9462\n",
      "[random] Accuracy after query 679: 0.9452\n",
      "[random] Accuracy after query 680: 0.9408\n",
      "[random] Accuracy after query 681: 0.9398\n",
      "[random] Accuracy after query 682: 0.9458\n",
      "[random] Accuracy after query 683: 0.9446\n",
      "[random] Accuracy after query 684: 0.9445\n",
      "[random] Accuracy after query 685: 0.9406\n",
      "[random] Accuracy after query 686: 0.9445\n",
      "[random] Accuracy after query 687: 0.9436\n",
      "[random] Accuracy after query 688: 0.9454\n",
      "[random] Accuracy after query 689: 0.9428\n",
      "[random] Accuracy after query 690: 0.9431\n",
      "[random] Accuracy after query 691: 0.9441\n",
      "[random] Accuracy after query 692: 0.9466\n",
      "[random] Accuracy after query 693: 0.9436\n",
      "[random] Accuracy after query 694: 0.9445\n",
      "[random] Accuracy after query 695: 0.9438\n",
      "[random] Accuracy after query 696: 0.9449\n",
      "[random] Accuracy after query 697: 0.9430\n",
      "[random] Accuracy after query 698: 0.9450\n",
      "[random] Accuracy after query 699: 0.9389\n",
      "[random] Accuracy after query 700: 0.9419\n",
      "[random] Accuracy after query 701: 0.9457\n",
      "[random] Accuracy after query 702: 0.9485\n",
      "[random] Accuracy after query 703: 0.9423\n",
      "[random] Accuracy after query 704: 0.9457\n",
      "[random] Accuracy after query 705: 0.9430\n",
      "[random] Accuracy after query 706: 0.9460\n",
      "[random] Accuracy after query 707: 0.9489\n",
      "[random] Accuracy after query 708: 0.9437\n",
      "[random] Accuracy after query 709: 0.9468\n",
      "[random] Accuracy after query 710: 0.9421\n",
      "[random] Accuracy after query 711: 0.9442\n",
      "[random] Accuracy after query 712: 0.9423\n",
      "[random] Accuracy after query 713: 0.9437\n",
      "[random] Accuracy after query 714: 0.9464\n",
      "[random] Accuracy after query 715: 0.9468\n",
      "[random] Accuracy after query 716: 0.9451\n",
      "[random] Accuracy after query 717: 0.9418\n",
      "[random] Accuracy after query 718: 0.9474\n",
      "[random] Accuracy after query 719: 0.9444\n",
      "[random] Accuracy after query 720: 0.9435\n",
      "[random] Accuracy after query 721: 0.9468\n",
      "[random] Accuracy after query 722: 0.9421\n",
      "[random] Accuracy after query 723: 0.9448\n",
      "[random] Accuracy after query 724: 0.9431\n",
      "[random] Accuracy after query 725: 0.9433\n",
      "[random] Accuracy after query 726: 0.9389\n",
      "[random] Accuracy after query 727: 0.9441\n",
      "[random] Accuracy after query 728: 0.9419\n",
      "[random] Accuracy after query 729: 0.9413\n",
      "[random] Accuracy after query 730: 0.9433\n",
      "[random] Accuracy after query 731: 0.9447\n",
      "[random] Accuracy after query 732: 0.9437\n",
      "[random] Accuracy after query 733: 0.9409\n",
      "[random] Accuracy after query 734: 0.9445\n",
      "[random] Accuracy after query 735: 0.9425\n",
      "[random] Accuracy after query 736: 0.9451\n",
      "[random] Accuracy after query 737: 0.9393\n",
      "[random] Accuracy after query 738: 0.9391\n",
      "[random] Accuracy after query 739: 0.9402\n",
      "[random] Accuracy after query 740: 0.9449\n",
      "[random] Accuracy after query 741: 0.9396\n",
      "[random] Accuracy after query 742: 0.9496\n",
      "[random] Accuracy after query 743: 0.9429\n",
      "[random] Accuracy after query 744: 0.9438\n",
      "[random] Accuracy after query 745: 0.9442\n",
      "[random] Accuracy after query 746: 0.9458\n",
      "[random] Accuracy after query 747: 0.9442\n",
      "[random] Accuracy after query 748: 0.9494\n",
      "[random] Accuracy after query 749: 0.9481\n",
      "[random] Accuracy after query 750: 0.9479\n",
      "[random] Accuracy after query 751: 0.9466\n",
      "[random] Accuracy after query 752: 0.9519\n",
      "[random] Accuracy after query 753: 0.9397\n",
      "[random] Accuracy after query 754: 0.9484\n",
      "[random] Accuracy after query 755: 0.9488\n",
      "[random] Accuracy after query 756: 0.9498\n",
      "[random] Accuracy after query 757: 0.9497\n",
      "[random] Accuracy after query 758: 0.9447\n",
      "[random] Accuracy after query 759: 0.9458\n",
      "[random] Accuracy after query 760: 0.9408\n",
      "[random] Accuracy after query 761: 0.9470\n",
      "[random] Accuracy after query 762: 0.9407\n",
      "[random] Accuracy after query 763: 0.9473\n",
      "[random] Accuracy after query 764: 0.9449\n",
      "[random] Accuracy after query 765: 0.9484\n",
      "[random] Accuracy after query 766: 0.9457\n",
      "[random] Accuracy after query 767: 0.9468\n",
      "[random] Accuracy after query 768: 0.9479\n",
      "[random] Accuracy after query 769: 0.9472\n",
      "[random] Accuracy after query 770: 0.9481\n",
      "[random] Accuracy after query 771: 0.9467\n",
      "[random] Accuracy after query 772: 0.9411\n",
      "[random] Accuracy after query 773: 0.9449\n",
      "[random] Accuracy after query 774: 0.9448\n",
      "[random] Accuracy after query 775: 0.9455\n",
      "[random] Accuracy after query 776: 0.9453\n",
      "[random] Accuracy after query 777: 0.9440\n",
      "[random] Accuracy after query 778: 0.9429\n",
      "[random] Accuracy after query 779: 0.9445\n",
      "[random] Accuracy after query 780: 0.9456\n",
      "[random] Accuracy after query 781: 0.9475\n",
      "[random] Accuracy after query 782: 0.9446\n",
      "[random] Accuracy after query 783: 0.9473\n",
      "[random] Accuracy after query 784: 0.9479\n",
      "[random] Accuracy after query 785: 0.9492\n",
      "[random] Accuracy after query 786: 0.9426\n",
      "[random] Accuracy after query 787: 0.9484\n",
      "[random] Accuracy after query 788: 0.9469\n",
      "[random] Accuracy after query 789: 0.9492\n",
      "[random] Accuracy after query 790: 0.9477\n",
      "[random] Accuracy after query 791: 0.9479\n",
      "[random] Accuracy after query 792: 0.9417\n",
      "[random] Accuracy after query 793: 0.9441\n",
      "[random] Accuracy after query 794: 0.9454\n",
      "[random] Accuracy after query 795: 0.9438\n",
      "[random] Accuracy after query 796: 0.9452\n",
      "[random] Accuracy after query 797: 0.9497\n",
      "[random] Accuracy after query 798: 0.9432\n",
      "[random] Accuracy after query 799: 0.9473\n",
      "[random] Accuracy after query 800: 0.9501\n",
      "[random] Accuracy after query 801: 0.9488\n",
      "[random] Accuracy after query 802: 0.9433\n",
      "[random] Accuracy after query 803: 0.9463\n",
      "[random] Accuracy after query 804: 0.9449\n",
      "[random] Accuracy after query 805: 0.9448\n",
      "[random] Accuracy after query 806: 0.9407\n",
      "[random] Accuracy after query 807: 0.9448\n",
      "[random] Accuracy after query 808: 0.9477\n",
      "[random] Accuracy after query 809: 0.9402\n",
      "[random] Accuracy after query 810: 0.9442\n",
      "[random] Accuracy after query 811: 0.9503\n",
      "[random] Accuracy after query 812: 0.9473\n",
      "[random] Accuracy after query 813: 0.9496\n",
      "[random] Accuracy after query 814: 0.9500\n",
      "[random] Accuracy after query 815: 0.9463\n",
      "[random] Accuracy after query 816: 0.9513\n",
      "[random] Accuracy after query 817: 0.9511\n",
      "[random] Accuracy after query 818: 0.9495\n",
      "[random] Accuracy after query 819: 0.9500\n",
      "[random] Accuracy after query 820: 0.9491\n",
      "[random] Accuracy after query 821: 0.9479\n",
      "[random] Accuracy after query 822: 0.9502\n",
      "[random] Accuracy after query 823: 0.9492\n",
      "[random] Accuracy after query 824: 0.9477\n",
      "[random] Accuracy after query 825: 0.9513\n",
      "[random] Accuracy after query 826: 0.9496\n",
      "[random] Accuracy after query 827: 0.9484\n",
      "[random] Accuracy after query 828: 0.9512\n",
      "[random] Accuracy after query 829: 0.9449\n",
      "[random] Accuracy after query 830: 0.9478\n",
      "[random] Accuracy after query 831: 0.9468\n",
      "[random] Accuracy after query 832: 0.9504\n",
      "[random] Accuracy after query 833: 0.9475\n",
      "[random] Accuracy after query 834: 0.9464\n",
      "[random] Accuracy after query 835: 0.9468\n",
      "[random] Accuracy after query 836: 0.9509\n",
      "[random] Accuracy after query 837: 0.9444\n",
      "[random] Accuracy after query 838: 0.9542\n",
      "[random] Accuracy after query 839: 0.9517\n",
      "[random] Accuracy after query 840: 0.9492\n",
      "[random] Accuracy after query 841: 0.9481\n",
      "[random] Accuracy after query 842: 0.9479\n",
      "[random] Accuracy after query 843: 0.9484\n",
      "[random] Accuracy after query 844: 0.9524\n",
      "[random] Accuracy after query 845: 0.9501\n",
      "[random] Accuracy after query 846: 0.9463\n",
      "[random] Accuracy after query 847: 0.9475\n",
      "[random] Accuracy after query 848: 0.9534\n",
      "[random] Accuracy after query 849: 0.9506\n",
      "[random] Accuracy after query 850: 0.9511\n",
      "[random] Accuracy after query 851: 0.9466\n",
      "[random] Accuracy after query 852: 0.9452\n",
      "[random] Accuracy after query 853: 0.9494\n",
      "[random] Accuracy after query 854: 0.9473\n",
      "[random] Accuracy after query 855: 0.9490\n",
      "[random] Accuracy after query 856: 0.9496\n",
      "[random] Accuracy after query 857: 0.9537\n",
      "[random] Accuracy after query 858: 0.9523\n",
      "[random] Accuracy after query 859: 0.9502\n",
      "[random] Accuracy after query 860: 0.9460\n",
      "[random] Accuracy after query 861: 0.9486\n",
      "[random] Accuracy after query 862: 0.9547\n",
      "[random] Accuracy after query 863: 0.9478\n",
      "[random] Accuracy after query 864: 0.9516\n",
      "[random] Accuracy after query 865: 0.9455\n",
      "[random] Accuracy after query 866: 0.9442\n",
      "[random] Accuracy after query 867: 0.9517\n",
      "[random] Accuracy after query 868: 0.9470\n",
      "[random] Accuracy after query 869: 0.9493\n",
      "[random] Accuracy after query 870: 0.9524\n",
      "[random] Accuracy after query 871: 0.9504\n",
      "[random] Accuracy after query 872: 0.9533\n",
      "[random] Accuracy after query 873: 0.9423\n",
      "[random] Accuracy after query 874: 0.9486\n",
      "[random] Accuracy after query 875: 0.9523\n",
      "[random] Accuracy after query 876: 0.9496\n",
      "[random] Accuracy after query 877: 0.9514\n",
      "[random] Accuracy after query 878: 0.9515\n",
      "[random] Accuracy after query 879: 0.9461\n",
      "[random] Accuracy after query 880: 0.9486\n",
      "[random] Accuracy after query 881: 0.9520\n",
      "[random] Accuracy after query 882: 0.9510\n",
      "[random] Accuracy after query 883: 0.9487\n",
      "[random] Accuracy after query 884: 0.9532\n",
      "[random] Accuracy after query 885: 0.9532\n",
      "[random] Accuracy after query 886: 0.9484\n",
      "[random] Accuracy after query 887: 0.9538\n",
      "[random] Accuracy after query 888: 0.9511\n",
      "[random] Accuracy after query 889: 0.9530\n",
      "[random] Accuracy after query 890: 0.9546\n",
      "[random] Accuracy after query 891: 0.9421\n",
      "[random] Accuracy after query 892: 0.9552\n",
      "[random] Accuracy after query 893: 0.9552\n",
      "[random] Accuracy after query 894: 0.9496\n",
      "[random] Accuracy after query 895: 0.9505\n",
      "[random] Accuracy after query 896: 0.9517\n",
      "[random] Accuracy after query 897: 0.9558\n",
      "[random] Accuracy after query 898: 0.9538\n",
      "[random] Accuracy after query 899: 0.9516\n",
      "[random] Accuracy after query 900: 0.9469\n",
      "[random] Accuracy after query 901: 0.9521\n",
      "[random] Accuracy after query 902: 0.9511\n",
      "[random] Accuracy after query 903: 0.9549\n",
      "[random] Accuracy after query 904: 0.9558\n",
      "[random] Accuracy after query 905: 0.9519\n",
      "[random] Accuracy after query 906: 0.9494\n",
      "[random] Accuracy after query 907: 0.9545\n",
      "[random] Accuracy after query 908: 0.9534\n",
      "[random] Accuracy after query 909: 0.9516\n",
      "[random] Accuracy after query 910: 0.9493\n",
      "[random] Accuracy after query 911: 0.9493\n",
      "[random] Accuracy after query 912: 0.9516\n",
      "[random] Accuracy after query 913: 0.9549\n",
      "[random] Accuracy after query 914: 0.9534\n",
      "[random] Accuracy after query 915: 0.9539\n",
      "[random] Accuracy after query 916: 0.9558\n",
      "[random] Accuracy after query 917: 0.9554\n",
      "[random] Accuracy after query 918: 0.9554\n",
      "[random] Accuracy after query 919: 0.9538\n",
      "[random] Accuracy after query 920: 0.9509\n",
      "[random] Accuracy after query 921: 0.9512\n",
      "[random] Accuracy after query 922: 0.9484\n",
      "[random] Accuracy after query 923: 0.9525\n",
      "[random] Accuracy after query 924: 0.9587\n",
      "[random] Accuracy after query 925: 0.9510\n",
      "[random] Accuracy after query 926: 0.9496\n",
      "[random] Accuracy after query 927: 0.9533\n",
      "[random] Accuracy after query 928: 0.9499\n",
      "[random] Accuracy after query 929: 0.9476\n",
      "[random] Accuracy after query 930: 0.9533\n",
      "[random] Accuracy after query 931: 0.9521\n",
      "[random] Accuracy after query 932: 0.9540\n",
      "[random] Accuracy after query 933: 0.9478\n",
      "[random] Accuracy after query 934: 0.9480\n",
      "[random] Accuracy after query 935: 0.9542\n",
      "[random] Accuracy after query 936: 0.9501\n",
      "[random] Accuracy after query 937: 0.9554\n",
      "[random] Accuracy after query 938: 0.9470\n",
      "[random] Accuracy after query 939: 0.9537\n",
      "[random] Accuracy after query 940: 0.9512\n",
      "[random] Accuracy after query 941: 0.9548\n",
      "[random] Accuracy after query 942: 0.9497\n",
      "[random] Accuracy after query 943: 0.9534\n",
      "[random] Accuracy after query 944: 0.9551\n",
      "[random] Accuracy after query 945: 0.9498\n",
      "[random] Accuracy after query 946: 0.9521\n",
      "[random] Accuracy after query 947: 0.9561\n",
      "[random] Accuracy after query 948: 0.9535\n",
      "[random] Accuracy after query 949: 0.9547\n",
      "[random] Accuracy after query 950: 0.9497\n",
      "[random] Accuracy after query 951: 0.9551\n",
      "[random] Accuracy after query 952: 0.9531\n",
      "[random] Accuracy after query 953: 0.9550\n",
      "[random] Accuracy after query 954: 0.9499\n",
      "[random] Accuracy after query 955: 0.9519\n",
      "[random] Accuracy after query 956: 0.9554\n",
      "[random] Accuracy after query 957: 0.9544\n",
      "[random] Accuracy after query 958: 0.9503\n",
      "[random] Accuracy after query 959: 0.9496\n",
      "[random] Accuracy after query 960: 0.9499\n",
      "[random] Accuracy after query 961: 0.9531\n",
      "[random] Accuracy after query 962: 0.9510\n",
      "[random] Accuracy after query 963: 0.9606\n",
      "[random] Accuracy after query 964: 0.9509\n",
      "[random] Accuracy after query 965: 0.9557\n",
      "[random] Accuracy after query 966: 0.9509\n",
      "[random] Accuracy after query 967: 0.9560\n",
      "[random] Accuracy after query 968: 0.9535\n",
      "[random] Accuracy after query 969: 0.9475\n",
      "[random] Accuracy after query 970: 0.9571\n",
      "[random] Accuracy after query 971: 0.9521\n",
      "[random] Accuracy after query 972: 0.9526\n",
      "[random] Accuracy after query 973: 0.9557\n",
      "[random] Accuracy after query 974: 0.9548\n",
      "[random] Accuracy after query 975: 0.9552\n",
      "[random] Accuracy after query 976: 0.9565\n",
      "[random] Accuracy after query 977: 0.9526\n",
      "[random] Accuracy after query 978: 0.9548\n",
      "[random] Accuracy after query 979: 0.9516\n",
      "[random] Accuracy after query 980: 0.9550\n",
      "[random] Accuracy after query 981: 0.9542\n",
      "[random] Accuracy after query 982: 0.9496\n",
      "[random] Accuracy after query 983: 0.9560\n",
      "[random] Accuracy after query 984: 0.9542\n",
      "[random] Accuracy after query 985: 0.9464\n",
      "[random] Accuracy after query 986: 0.9585\n",
      "[random] Accuracy after query 987: 0.9525\n",
      "[random] Accuracy after query 988: 0.9558\n",
      "[random] Accuracy after query 989: 0.9503\n",
      "[random] Accuracy after query 990: 0.9557\n",
      "[random] Accuracy after query 991: 0.9542\n",
      "[random] Accuracy after query 992: 0.9551\n",
      "[random] Accuracy after query 993: 0.9517\n",
      "[random] Accuracy after query 994: 0.9560\n",
      "[random] Accuracy after query 995: 0.9595\n",
      "[random] Accuracy after query 996: 0.9533\n",
      "[random] Accuracy after query 997: 0.9556\n",
      "[random] Accuracy after query 998: 0.9563\n",
      "[random] Accuracy after query 999: 0.9571\n",
      "[random] Accuracy after query 1000: 0.9542\n",
      "[bald] Accuracy after query 1: 0.7983\n",
      "[bald] Accuracy after query 2: 0.8047\n",
      "[bald] Accuracy after query 3: 0.8048\n",
      "[bald] Accuracy after query 4: 0.7970\n",
      "[bald] Accuracy after query 5: 0.8220\n",
      "[bald] Accuracy after query 6: 0.8362\n",
      "[bald] Accuracy after query 7: 0.8232\n",
      "[bald] Accuracy after query 8: 0.8352\n",
      "[bald] Accuracy after query 9: 0.8184\n",
      "[bald] Accuracy after query 10: 0.8210\n",
      "[bald] Accuracy after query 11: 0.8361\n",
      "[bald] Accuracy after query 12: 0.8301\n",
      "[bald] Accuracy after query 13: 0.8307\n",
      "[bald] Accuracy after query 14: 0.8445\n",
      "[bald] Accuracy after query 15: 0.8337\n",
      "[bald] Accuracy after query 16: 0.8371\n",
      "[bald] Accuracy after query 17: 0.8509\n",
      "[bald] Accuracy after query 18: 0.8436\n",
      "[bald] Accuracy after query 19: 0.8397\n",
      "[bald] Accuracy after query 20: 0.8429\n",
      "[bald] Accuracy after query 21: 0.8438\n",
      "[bald] Accuracy after query 22: 0.8558\n",
      "[bald] Accuracy after query 23: 0.8392\n",
      "[bald] Accuracy after query 24: 0.8550\n",
      "[bald] Accuracy after query 25: 0.8489\n",
      "[bald] Accuracy after query 26: 0.8335\n",
      "[bald] Accuracy after query 27: 0.8414\n",
      "[bald] Accuracy after query 28: 0.8489\n",
      "[bald] Accuracy after query 29: 0.8668\n",
      "[bald] Accuracy after query 30: 0.8362\n",
      "[bald] Accuracy after query 31: 0.8403\n",
      "[bald] Accuracy after query 32: 0.8417\n",
      "[bald] Accuracy after query 33: 0.8119\n",
      "[bald] Accuracy after query 34: 0.8580\n",
      "[bald] Accuracy after query 35: 0.8489\n",
      "[bald] Accuracy after query 36: 0.8317\n",
      "[bald] Accuracy after query 37: 0.8519\n",
      "[bald] Accuracy after query 38: 0.8569\n",
      "[bald] Accuracy after query 39: 0.8582\n",
      "[bald] Accuracy after query 40: 0.8508\n",
      "[bald] Accuracy after query 41: 0.8780\n",
      "[bald] Accuracy after query 42: 0.8624\n",
      "[bald] Accuracy after query 43: 0.8620\n",
      "[bald] Accuracy after query 44: 0.8584\n",
      "[bald] Accuracy after query 45: 0.8738\n",
      "[bald] Accuracy after query 46: 0.8756\n",
      "[bald] Accuracy after query 47: 0.8759\n",
      "[bald] Accuracy after query 48: 0.8580\n",
      "[bald] Accuracy after query 49: 0.8757\n",
      "[bald] Accuracy after query 50: 0.8624\n",
      "[bald] Accuracy after query 51: 0.8937\n",
      "[bald] Accuracy after query 52: 0.8784\n",
      "[bald] Accuracy after query 53: 0.8741\n",
      "[bald] Accuracy after query 54: 0.8718\n",
      "[bald] Accuracy after query 55: 0.8784\n",
      "[bald] Accuracy after query 56: 0.8918\n",
      "[bald] Accuracy after query 57: 0.8890\n",
      "[bald] Accuracy after query 58: 0.8963\n",
      "[bald] Accuracy after query 59: 0.8807\n",
      "[bald] Accuracy after query 60: 0.9042\n",
      "[bald] Accuracy after query 61: 0.8995\n",
      "[bald] Accuracy after query 62: 0.8955\n",
      "[bald] Accuracy after query 63: 0.9018\n",
      "[bald] Accuracy after query 64: 0.8746\n",
      "[bald] Accuracy after query 65: 0.8945\n",
      "[bald] Accuracy after query 66: 0.8942\n",
      "[bald] Accuracy after query 67: 0.8808\n",
      "[bald] Accuracy after query 68: 0.8959\n",
      "[bald] Accuracy after query 69: 0.9009\n",
      "[bald] Accuracy after query 70: 0.8965\n",
      "[bald] Accuracy after query 71: 0.9039\n",
      "[bald] Accuracy after query 72: 0.8936\n",
      "[bald] Accuracy after query 73: 0.8949\n",
      "[bald] Accuracy after query 74: 0.8920\n",
      "[bald] Accuracy after query 75: 0.8926\n",
      "[bald] Accuracy after query 76: 0.8790\n",
      "[bald] Accuracy after query 77: 0.8860\n",
      "[bald] Accuracy after query 78: 0.8930\n",
      "[bald] Accuracy after query 79: 0.8921\n",
      "[bald] Accuracy after query 80: 0.8997\n",
      "[bald] Accuracy after query 81: 0.8924\n",
      "[bald] Accuracy after query 82: 0.9124\n",
      "[bald] Accuracy after query 83: 0.8947\n",
      "[bald] Accuracy after query 84: 0.9036\n",
      "[bald] Accuracy after query 85: 0.9060\n",
      "[bald] Accuracy after query 86: 0.9030\n",
      "[bald] Accuracy after query 87: 0.8964\n",
      "[bald] Accuracy after query 88: 0.8929\n",
      "[bald] Accuracy after query 89: 0.8909\n",
      "[bald] Accuracy after query 90: 0.9047\n",
      "[bald] Accuracy after query 91: 0.9060\n",
      "[bald] Accuracy after query 92: 0.8870\n",
      "[bald] Accuracy after query 93: 0.9099\n",
      "[bald] Accuracy after query 94: 0.9082\n",
      "[bald] Accuracy after query 95: 0.9077\n",
      "[bald] Accuracy after query 96: 0.8937\n",
      "[bald] Accuracy after query 97: 0.9118\n",
      "[bald] Accuracy after query 98: 0.9083\n",
      "[bald] Accuracy after query 99: 0.8853\n",
      "[bald] Accuracy after query 100: 0.9010\n",
      "[bald] Accuracy after query 101: 0.9160\n",
      "[bald] Accuracy after query 102: 0.9235\n",
      "[bald] Accuracy after query 103: 0.9053\n",
      "[bald] Accuracy after query 104: 0.9048\n",
      "[bald] Accuracy after query 105: 0.9178\n",
      "[bald] Accuracy after query 106: 0.9016\n",
      "[bald] Accuracy after query 107: 0.9065\n",
      "[bald] Accuracy after query 108: 0.9089\n",
      "[bald] Accuracy after query 109: 0.9139\n",
      "[bald] Accuracy after query 110: 0.9138\n",
      "[bald] Accuracy after query 111: 0.9216\n",
      "[bald] Accuracy after query 112: 0.9067\n",
      "[bald] Accuracy after query 113: 0.9025\n",
      "[bald] Accuracy after query 114: 0.9182\n",
      "[bald] Accuracy after query 115: 0.9019\n",
      "[bald] Accuracy after query 116: 0.9076\n",
      "[bald] Accuracy after query 117: 0.9122\n",
      "[bald] Accuracy after query 118: 0.9081\n",
      "[bald] Accuracy after query 119: 0.9209\n",
      "[bald] Accuracy after query 120: 0.9031\n",
      "[bald] Accuracy after query 121: 0.9058\n",
      "[bald] Accuracy after query 122: 0.9212\n",
      "[bald] Accuracy after query 123: 0.9053\n",
      "[bald] Accuracy after query 124: 0.9179\n",
      "[bald] Accuracy after query 125: 0.9225\n",
      "[bald] Accuracy after query 126: 0.9226\n",
      "[bald] Accuracy after query 127: 0.9138\n",
      "[bald] Accuracy after query 128: 0.9142\n",
      "[bald] Accuracy after query 129: 0.9121\n",
      "[bald] Accuracy after query 130: 0.9149\n",
      "[bald] Accuracy after query 131: 0.9235\n",
      "[bald] Accuracy after query 132: 0.9166\n",
      "[bald] Accuracy after query 133: 0.9174\n",
      "[bald] Accuracy after query 134: 0.9095\n",
      "[bald] Accuracy after query 135: 0.9269\n",
      "[bald] Accuracy after query 136: 0.9133\n",
      "[bald] Accuracy after query 137: 0.9088\n",
      "[bald] Accuracy after query 138: 0.9088\n",
      "[bald] Accuracy after query 139: 0.9196\n",
      "[bald] Accuracy after query 140: 0.9167\n",
      "[bald] Accuracy after query 141: 0.9159\n",
      "[bald] Accuracy after query 142: 0.9172\n",
      "[bald] Accuracy after query 143: 0.9205\n",
      "[bald] Accuracy after query 144: 0.9176\n",
      "[bald] Accuracy after query 145: 0.9081\n",
      "[bald] Accuracy after query 146: 0.9089\n",
      "[bald] Accuracy after query 147: 0.9182\n",
      "[bald] Accuracy after query 148: 0.9188\n",
      "[bald] Accuracy after query 149: 0.9216\n",
      "[bald] Accuracy after query 150: 0.9086\n",
      "[bald] Accuracy after query 151: 0.9172\n",
      "[bald] Accuracy after query 152: 0.9195\n",
      "[bald] Accuracy after query 153: 0.9221\n",
      "[bald] Accuracy after query 154: 0.9226\n",
      "[bald] Accuracy after query 155: 0.9192\n",
      "[bald] Accuracy after query 156: 0.9140\n",
      "[bald] Accuracy after query 157: 0.9065\n",
      "[bald] Accuracy after query 158: 0.9162\n",
      "[bald] Accuracy after query 159: 0.9189\n",
      "[bald] Accuracy after query 160: 0.9090\n",
      "[bald] Accuracy after query 161: 0.9029\n",
      "[bald] Accuracy after query 162: 0.9250\n",
      "[bald] Accuracy after query 163: 0.9232\n",
      "[bald] Accuracy after query 164: 0.9244\n",
      "[bald] Accuracy after query 165: 0.9122\n",
      "[bald] Accuracy after query 166: 0.9192\n",
      "[bald] Accuracy after query 167: 0.9129\n",
      "[bald] Accuracy after query 168: 0.9116\n",
      "[bald] Accuracy after query 169: 0.9190\n",
      "[bald] Accuracy after query 170: 0.9123\n",
      "[bald] Accuracy after query 171: 0.9117\n",
      "[bald] Accuracy after query 172: 0.9051\n",
      "[bald] Accuracy after query 173: 0.9184\n",
      "[bald] Accuracy after query 174: 0.9179\n",
      "[bald] Accuracy after query 175: 0.9189\n",
      "[bald] Accuracy after query 176: 0.9280\n",
      "[bald] Accuracy after query 177: 0.9223\n",
      "[bald] Accuracy after query 178: 0.9111\n",
      "[bald] Accuracy after query 179: 0.9224\n",
      "[bald] Accuracy after query 180: 0.9323\n",
      "[bald] Accuracy after query 181: 0.9313\n",
      "[bald] Accuracy after query 182: 0.9294\n",
      "[bald] Accuracy after query 183: 0.9226\n",
      "[bald] Accuracy after query 184: 0.9283\n",
      "[bald] Accuracy after query 185: 0.9297\n",
      "[bald] Accuracy after query 186: 0.9349\n",
      "[bald] Accuracy after query 187: 0.9236\n",
      "[bald] Accuracy after query 188: 0.9191\n",
      "[bald] Accuracy after query 189: 0.9368\n",
      "[bald] Accuracy after query 190: 0.9374\n",
      "[bald] Accuracy after query 191: 0.9313\n",
      "[bald] Accuracy after query 192: 0.9304\n",
      "[bald] Accuracy after query 193: 0.9167\n",
      "[bald] Accuracy after query 194: 0.9328\n",
      "[bald] Accuracy after query 195: 0.9269\n",
      "[bald] Accuracy after query 196: 0.9412\n",
      "[bald] Accuracy after query 197: 0.9313\n",
      "[bald] Accuracy after query 198: 0.9198\n",
      "[bald] Accuracy after query 199: 0.9226\n",
      "[bald] Accuracy after query 200: 0.9310\n",
      "[bald] Accuracy after query 201: 0.9326\n",
      "[bald] Accuracy after query 202: 0.9319\n",
      "[bald] Accuracy after query 203: 0.9436\n",
      "[bald] Accuracy after query 204: 0.9394\n",
      "[bald] Accuracy after query 205: 0.9410\n",
      "[bald] Accuracy after query 206: 0.9397\n",
      "[bald] Accuracy after query 207: 0.9345\n",
      "[bald] Accuracy after query 208: 0.9341\n",
      "[bald] Accuracy after query 209: 0.9387\n",
      "[bald] Accuracy after query 210: 0.9419\n",
      "[bald] Accuracy after query 211: 0.9398\n",
      "[bald] Accuracy after query 212: 0.9318\n",
      "[bald] Accuracy after query 213: 0.9383\n",
      "[bald] Accuracy after query 214: 0.9385\n",
      "[bald] Accuracy after query 215: 0.9380\n",
      "[bald] Accuracy after query 216: 0.9342\n",
      "[bald] Accuracy after query 217: 0.9403\n",
      "[bald] Accuracy after query 218: 0.9402\n",
      "[bald] Accuracy after query 219: 0.9445\n",
      "[bald] Accuracy after query 220: 0.9396\n",
      "[bald] Accuracy after query 221: 0.9475\n",
      "[bald] Accuracy after query 222: 0.9394\n",
      "[bald] Accuracy after query 223: 0.9435\n",
      "[bald] Accuracy after query 224: 0.9402\n",
      "[bald] Accuracy after query 225: 0.9437\n",
      "[bald] Accuracy after query 226: 0.9388\n",
      "[bald] Accuracy after query 227: 0.9470\n",
      "[bald] Accuracy after query 228: 0.9372\n",
      "[bald] Accuracy after query 229: 0.9456\n",
      "[bald] Accuracy after query 230: 0.9415\n",
      "[bald] Accuracy after query 231: 0.9425\n",
      "[bald] Accuracy after query 232: 0.9472\n",
      "[bald] Accuracy after query 233: 0.9363\n",
      "[bald] Accuracy after query 234: 0.9464\n",
      "[bald] Accuracy after query 235: 0.9445\n",
      "[bald] Accuracy after query 236: 0.9459\n",
      "[bald] Accuracy after query 237: 0.9433\n",
      "[bald] Accuracy after query 238: 0.9402\n",
      "[bald] Accuracy after query 239: 0.9414\n",
      "[bald] Accuracy after query 240: 0.9497\n",
      "[bald] Accuracy after query 241: 0.9420\n",
      "[bald] Accuracy after query 242: 0.9466\n",
      "[bald] Accuracy after query 243: 0.9450\n",
      "[bald] Accuracy after query 244: 0.9496\n",
      "[bald] Accuracy after query 245: 0.9444\n",
      "[bald] Accuracy after query 246: 0.9447\n",
      "[bald] Accuracy after query 247: 0.9499\n",
      "[bald] Accuracy after query 248: 0.9515\n",
      "[bald] Accuracy after query 249: 0.9529\n",
      "[bald] Accuracy after query 250: 0.9479\n",
      "[bald] Accuracy after query 251: 0.9476\n",
      "[bald] Accuracy after query 252: 0.9523\n",
      "[bald] Accuracy after query 253: 0.9498\n",
      "[bald] Accuracy after query 254: 0.9409\n",
      "[bald] Accuracy after query 255: 0.9507\n",
      "[bald] Accuracy after query 256: 0.9480\n",
      "[bald] Accuracy after query 257: 0.9493\n",
      "[bald] Accuracy after query 258: 0.9475\n",
      "[bald] Accuracy after query 259: 0.9491\n",
      "[bald] Accuracy after query 260: 0.9516\n",
      "[bald] Accuracy after query 261: 0.9546\n",
      "[bald] Accuracy after query 262: 0.9496\n",
      "[bald] Accuracy after query 263: 0.9540\n",
      "[bald] Accuracy after query 264: 0.9502\n",
      "[bald] Accuracy after query 265: 0.9491\n",
      "[bald] Accuracy after query 266: 0.9536\n",
      "[bald] Accuracy after query 267: 0.9520\n",
      "[bald] Accuracy after query 268: 0.9513\n",
      "[bald] Accuracy after query 269: 0.9474\n",
      "[bald] Accuracy after query 270: 0.9506\n",
      "[bald] Accuracy after query 271: 0.9527\n",
      "[bald] Accuracy after query 272: 0.9519\n",
      "[bald] Accuracy after query 273: 0.9504\n",
      "[bald] Accuracy after query 274: 0.9495\n",
      "[bald] Accuracy after query 275: 0.9512\n",
      "[bald] Accuracy after query 276: 0.9521\n",
      "[bald] Accuracy after query 277: 0.9530\n",
      "[bald] Accuracy after query 278: 0.9547\n",
      "[bald] Accuracy after query 279: 0.9474\n",
      "[bald] Accuracy after query 280: 0.9478\n",
      "[bald] Accuracy after query 281: 0.9561\n",
      "[bald] Accuracy after query 282: 0.9527\n",
      "[bald] Accuracy after query 283: 0.9507\n",
      "[bald] Accuracy after query 284: 0.9545\n",
      "[bald] Accuracy after query 285: 0.9546\n",
      "[bald] Accuracy after query 286: 0.9370\n",
      "[bald] Accuracy after query 287: 0.9478\n",
      "[bald] Accuracy after query 288: 0.9459\n",
      "[bald] Accuracy after query 289: 0.9479\n",
      "[bald] Accuracy after query 290: 0.9492\n",
      "[bald] Accuracy after query 291: 0.9567\n",
      "[bald] Accuracy after query 292: 0.9519\n",
      "[bald] Accuracy after query 293: 0.9569\n",
      "[bald] Accuracy after query 294: 0.9427\n",
      "[bald] Accuracy after query 295: 0.9564\n",
      "[bald] Accuracy after query 296: 0.9485\n",
      "[bald] Accuracy after query 297: 0.9527\n",
      "[bald] Accuracy after query 298: 0.9542\n",
      "[bald] Accuracy after query 299: 0.9521\n",
      "[bald] Accuracy after query 300: 0.9468\n",
      "[bald] Accuracy after query 301: 0.9544\n",
      "[bald] Accuracy after query 302: 0.9511\n",
      "[bald] Accuracy after query 303: 0.9545\n",
      "[bald] Accuracy after query 304: 0.9545\n",
      "[bald] Accuracy after query 305: 0.9510\n",
      "[bald] Accuracy after query 306: 0.9553\n",
      "[bald] Accuracy after query 307: 0.9503\n",
      "[bald] Accuracy after query 308: 0.9485\n",
      "[bald] Accuracy after query 309: 0.9554\n",
      "[bald] Accuracy after query 310: 0.9601\n",
      "[bald] Accuracy after query 311: 0.9503\n",
      "[bald] Accuracy after query 312: 0.9481\n",
      "[bald] Accuracy after query 313: 0.9476\n",
      "[bald] Accuracy after query 314: 0.9555\n",
      "[bald] Accuracy after query 315: 0.9521\n",
      "[bald] Accuracy after query 316: 0.9590\n",
      "[bald] Accuracy after query 317: 0.9510\n",
      "[bald] Accuracy after query 318: 0.9547\n",
      "[bald] Accuracy after query 319: 0.9617\n",
      "[bald] Accuracy after query 320: 0.9547\n",
      "[bald] Accuracy after query 321: 0.9608\n",
      "[bald] Accuracy after query 322: 0.9608\n",
      "[bald] Accuracy after query 323: 0.9558\n",
      "[bald] Accuracy after query 324: 0.9596\n",
      "[bald] Accuracy after query 325: 0.9518\n",
      "[bald] Accuracy after query 326: 0.9542\n",
      "[bald] Accuracy after query 327: 0.9519\n",
      "[bald] Accuracy after query 328: 0.9550\n",
      "[bald] Accuracy after query 329: 0.9573\n",
      "[bald] Accuracy after query 330: 0.9597\n",
      "[bald] Accuracy after query 331: 0.9593\n",
      "[bald] Accuracy after query 332: 0.9544\n",
      "[bald] Accuracy after query 333: 0.9560\n",
      "[bald] Accuracy after query 334: 0.9526\n",
      "[bald] Accuracy after query 335: 0.9585\n",
      "[bald] Accuracy after query 336: 0.9537\n",
      "[bald] Accuracy after query 337: 0.9587\n",
      "[bald] Accuracy after query 338: 0.9562\n",
      "[bald] Accuracy after query 339: 0.9513\n",
      "[bald] Accuracy after query 340: 0.9547\n",
      "[bald] Accuracy after query 341: 0.9553\n",
      "[bald] Accuracy after query 342: 0.9567\n",
      "[bald] Accuracy after query 343: 0.9578\n",
      "[bald] Accuracy after query 344: 0.9587\n",
      "[bald] Accuracy after query 345: 0.9545\n",
      "[bald] Accuracy after query 346: 0.9540\n",
      "[bald] Accuracy after query 347: 0.9531\n",
      "[bald] Accuracy after query 348: 0.9534\n",
      "[bald] Accuracy after query 349: 0.9607\n",
      "[bald] Accuracy after query 350: 0.9523\n",
      "[bald] Accuracy after query 351: 0.9588\n",
      "[bald] Accuracy after query 352: 0.9622\n",
      "[bald] Accuracy after query 353: 0.9603\n",
      "[bald] Accuracy after query 354: 0.9573\n",
      "[bald] Accuracy after query 355: 0.9640\n",
      "[bald] Accuracy after query 356: 0.9623\n",
      "[bald] Accuracy after query 357: 0.9598\n",
      "[bald] Accuracy after query 358: 0.9601\n",
      "[bald] Accuracy after query 359: 0.9585\n",
      "[bald] Accuracy after query 360: 0.9627\n",
      "[bald] Accuracy after query 361: 0.9649\n",
      "[bald] Accuracy after query 362: 0.9564\n",
      "[bald] Accuracy after query 363: 0.9621\n",
      "[bald] Accuracy after query 364: 0.9589\n",
      "[bald] Accuracy after query 365: 0.9583\n",
      "[bald] Accuracy after query 366: 0.9626\n",
      "[bald] Accuracy after query 367: 0.9652\n",
      "[bald] Accuracy after query 368: 0.9596\n",
      "[bald] Accuracy after query 369: 0.9614\n",
      "[bald] Accuracy after query 370: 0.9560\n",
      "[bald] Accuracy after query 371: 0.9623\n",
      "[bald] Accuracy after query 372: 0.9634\n",
      "[bald] Accuracy after query 373: 0.9653\n",
      "[bald] Accuracy after query 374: 0.9574\n",
      "[bald] Accuracy after query 375: 0.9551\n",
      "[bald] Accuracy after query 376: 0.9640\n",
      "[bald] Accuracy after query 377: 0.9667\n",
      "[bald] Accuracy after query 378: 0.9589\n",
      "[bald] Accuracy after query 379: 0.9625\n",
      "[bald] Accuracy after query 380: 0.9636\n",
      "[bald] Accuracy after query 381: 0.9608\n",
      "[bald] Accuracy after query 382: 0.9602\n",
      "[bald] Accuracy after query 383: 0.9611\n",
      "[bald] Accuracy after query 384: 0.9560\n",
      "[bald] Accuracy after query 385: 0.9666\n",
      "[bald] Accuracy after query 386: 0.9625\n",
      "[bald] Accuracy after query 387: 0.9607\n",
      "[bald] Accuracy after query 388: 0.9612\n",
      "[bald] Accuracy after query 389: 0.9625\n",
      "[bald] Accuracy after query 390: 0.9631\n",
      "[bald] Accuracy after query 391: 0.9646\n",
      "[bald] Accuracy after query 392: 0.9688\n",
      "[bald] Accuracy after query 393: 0.9615\n",
      "[bald] Accuracy after query 394: 0.9651\n",
      "[bald] Accuracy after query 395: 0.9607\n",
      "[bald] Accuracy after query 396: 0.9663\n",
      "[bald] Accuracy after query 397: 0.9650\n",
      "[bald] Accuracy after query 398: 0.9613\n",
      "[bald] Accuracy after query 399: 0.9604\n",
      "[bald] Accuracy after query 400: 0.9671\n",
      "[bald] Accuracy after query 401: 0.9644\n",
      "[bald] Accuracy after query 402: 0.9625\n",
      "[bald] Accuracy after query 403: 0.9656\n",
      "[bald] Accuracy after query 404: 0.9626\n",
      "[bald] Accuracy after query 405: 0.9620\n",
      "[bald] Accuracy after query 406: 0.9636\n",
      "[bald] Accuracy after query 407: 0.9641\n",
      "[bald] Accuracy after query 408: 0.9650\n",
      "[bald] Accuracy after query 409: 0.9636\n",
      "[bald] Accuracy after query 410: 0.9670\n",
      "[bald] Accuracy after query 411: 0.9619\n",
      "[bald] Accuracy after query 412: 0.9614\n",
      "[bald] Accuracy after query 413: 0.9622\n",
      "[bald] Accuracy after query 414: 0.9657\n",
      "[bald] Accuracy after query 415: 0.9658\n",
      "[bald] Accuracy after query 416: 0.9622\n",
      "[bald] Accuracy after query 417: 0.9646\n",
      "[bald] Accuracy after query 418: 0.9651\n",
      "[bald] Accuracy after query 419: 0.9588\n",
      "[bald] Accuracy after query 420: 0.9649\n",
      "[bald] Accuracy after query 421: 0.9626\n",
      "[bald] Accuracy after query 422: 0.9699\n",
      "[bald] Accuracy after query 423: 0.9627\n",
      "[bald] Accuracy after query 424: 0.9553\n",
      "[bald] Accuracy after query 425: 0.9684\n",
      "[bald] Accuracy after query 426: 0.9621\n",
      "[bald] Accuracy after query 427: 0.9631\n",
      "[bald] Accuracy after query 428: 0.9656\n",
      "[bald] Accuracy after query 429: 0.9660\n",
      "[bald] Accuracy after query 430: 0.9686\n",
      "[bald] Accuracy after query 431: 0.9611\n",
      "[bald] Accuracy after query 432: 0.9633\n",
      "[bald] Accuracy after query 433: 0.9654\n",
      "[bald] Accuracy after query 434: 0.9675\n",
      "[bald] Accuracy after query 435: 0.9668\n",
      "[bald] Accuracy after query 436: 0.9634\n",
      "[bald] Accuracy after query 437: 0.9644\n",
      "[bald] Accuracy after query 438: 0.9654\n",
      "[bald] Accuracy after query 439: 0.9633\n",
      "[bald] Accuracy after query 440: 0.9622\n",
      "[bald] Accuracy after query 441: 0.9614\n",
      "[bald] Accuracy after query 442: 0.9637\n",
      "[bald] Accuracy after query 443: 0.9638\n",
      "[bald] Accuracy after query 444: 0.9640\n",
      "[bald] Accuracy after query 445: 0.9684\n",
      "[bald] Accuracy after query 446: 0.9656\n",
      "[bald] Accuracy after query 447: 0.9601\n",
      "[bald] Accuracy after query 448: 0.9625\n",
      "[bald] Accuracy after query 449: 0.9654\n",
      "[bald] Accuracy after query 450: 0.9677\n",
      "[bald] Accuracy after query 451: 0.9582\n",
      "[bald] Accuracy after query 452: 0.9651\n",
      "[bald] Accuracy after query 453: 0.9687\n",
      "[bald] Accuracy after query 454: 0.9710\n",
      "[bald] Accuracy after query 455: 0.9691\n",
      "[bald] Accuracy after query 456: 0.9635\n",
      "[bald] Accuracy after query 457: 0.9671\n",
      "[bald] Accuracy after query 458: 0.9668\n",
      "[bald] Accuracy after query 459: 0.9651\n",
      "[bald] Accuracy after query 460: 0.9618\n",
      "[bald] Accuracy after query 461: 0.9668\n",
      "[bald] Accuracy after query 462: 0.9655\n",
      "[bald] Accuracy after query 463: 0.9705\n",
      "[bald] Accuracy after query 464: 0.9640\n",
      "[bald] Accuracy after query 465: 0.9700\n",
      "[bald] Accuracy after query 466: 0.9680\n",
      "[bald] Accuracy after query 467: 0.9664\n",
      "[bald] Accuracy after query 468: 0.9663\n",
      "[bald] Accuracy after query 469: 0.9657\n",
      "[bald] Accuracy after query 470: 0.9683\n",
      "[bald] Accuracy after query 471: 0.9662\n",
      "[bald] Accuracy after query 472: 0.9690\n",
      "[bald] Accuracy after query 473: 0.9661\n",
      "[bald] Accuracy after query 474: 0.9644\n",
      "[bald] Accuracy after query 475: 0.9687\n",
      "[bald] Accuracy after query 476: 0.9691\n",
      "[bald] Accuracy after query 477: 0.9670\n",
      "[bald] Accuracy after query 478: 0.9684\n",
      "[bald] Accuracy after query 479: 0.9649\n",
      "[bald] Accuracy after query 480: 0.9696\n",
      "[bald] Accuracy after query 481: 0.9679\n",
      "[bald] Accuracy after query 482: 0.9676\n",
      "[bald] Accuracy after query 483: 0.9661\n",
      "[bald] Accuracy after query 484: 0.9702\n",
      "[bald] Accuracy after query 485: 0.9673\n",
      "[bald] Accuracy after query 486: 0.9657\n",
      "[bald] Accuracy after query 487: 0.9689\n",
      "[bald] Accuracy after query 488: 0.9658\n",
      "[bald] Accuracy after query 489: 0.9691\n",
      "[bald] Accuracy after query 490: 0.9669\n",
      "[bald] Accuracy after query 491: 0.9716\n",
      "[bald] Accuracy after query 492: 0.9728\n",
      "[bald] Accuracy after query 493: 0.9722\n",
      "[bald] Accuracy after query 494: 0.9703\n",
      "[bald] Accuracy after query 495: 0.9724\n",
      "[bald] Accuracy after query 496: 0.9711\n",
      "[bald] Accuracy after query 497: 0.9673\n",
      "[bald] Accuracy after query 498: 0.9723\n",
      "[bald] Accuracy after query 499: 0.9713\n",
      "[bald] Accuracy after query 500: 0.9736\n",
      "[bald] Accuracy after query 501: 0.9702\n",
      "[bald] Accuracy after query 502: 0.9718\n",
      "[bald] Accuracy after query 503: 0.9713\n",
      "[bald] Accuracy after query 504: 0.9714\n",
      "[bald] Accuracy after query 505: 0.9694\n",
      "[bald] Accuracy after query 506: 0.9714\n",
      "[bald] Accuracy after query 507: 0.9720\n",
      "[bald] Accuracy after query 508: 0.9738\n",
      "[bald] Accuracy after query 509: 0.9687\n",
      "[bald] Accuracy after query 510: 0.9724\n",
      "[bald] Accuracy after query 511: 0.9708\n",
      "[bald] Accuracy after query 512: 0.9733\n",
      "[bald] Accuracy after query 513: 0.9740\n",
      "[bald] Accuracy after query 514: 0.9752\n",
      "[bald] Accuracy after query 515: 0.9705\n",
      "[bald] Accuracy after query 516: 0.9718\n",
      "[bald] Accuracy after query 517: 0.9711\n",
      "[bald] Accuracy after query 518: 0.9751\n",
      "[bald] Accuracy after query 519: 0.9731\n",
      "[bald] Accuracy after query 520: 0.9688\n",
      "[bald] Accuracy after query 521: 0.9710\n",
      "[bald] Accuracy after query 522: 0.9703\n",
      "[bald] Accuracy after query 523: 0.9709\n",
      "[bald] Accuracy after query 524: 0.9701\n",
      "[bald] Accuracy after query 525: 0.9689\n",
      "[bald] Accuracy after query 526: 0.9729\n",
      "[bald] Accuracy after query 527: 0.9745\n",
      "[bald] Accuracy after query 528: 0.9725\n",
      "[bald] Accuracy after query 529: 0.9731\n",
      "[bald] Accuracy after query 530: 0.9740\n",
      "[bald] Accuracy after query 531: 0.9726\n",
      "[bald] Accuracy after query 532: 0.9720\n",
      "[bald] Accuracy after query 533: 0.9745\n",
      "[bald] Accuracy after query 534: 0.9710\n",
      "[bald] Accuracy after query 535: 0.9678\n",
      "[bald] Accuracy after query 536: 0.9727\n",
      "[bald] Accuracy after query 537: 0.9692\n",
      "[bald] Accuracy after query 538: 0.9754\n",
      "[bald] Accuracy after query 539: 0.9731\n",
      "[bald] Accuracy after query 540: 0.9733\n",
      "[bald] Accuracy after query 541: 0.9750\n",
      "[bald] Accuracy after query 542: 0.9723\n",
      "[bald] Accuracy after query 543: 0.9725\n",
      "[bald] Accuracy after query 544: 0.9743\n",
      "[bald] Accuracy after query 545: 0.9738\n",
      "[bald] Accuracy after query 546: 0.9753\n",
      "[bald] Accuracy after query 547: 0.9750\n",
      "[bald] Accuracy after query 548: 0.9732\n",
      "[bald] Accuracy after query 549: 0.9702\n",
      "[bald] Accuracy after query 550: 0.9749\n",
      "[bald] Accuracy after query 551: 0.9716\n",
      "[bald] Accuracy after query 552: 0.9739\n",
      "[bald] Accuracy after query 553: 0.9728\n",
      "[bald] Accuracy after query 554: 0.9758\n",
      "[bald] Accuracy after query 555: 0.9745\n",
      "[bald] Accuracy after query 556: 0.9746\n",
      "[bald] Accuracy after query 557: 0.9724\n",
      "[bald] Accuracy after query 558: 0.9739\n",
      "[bald] Accuracy after query 559: 0.9699\n",
      "[bald] Accuracy after query 560: 0.9704\n",
      "[bald] Accuracy after query 561: 0.9756\n",
      "[bald] Accuracy after query 562: 0.9722\n",
      "[bald] Accuracy after query 563: 0.9748\n",
      "[bald] Accuracy after query 564: 0.9714\n",
      "[bald] Accuracy after query 565: 0.9738\n",
      "[bald] Accuracy after query 566: 0.9739\n",
      "[bald] Accuracy after query 567: 0.9750\n",
      "[bald] Accuracy after query 568: 0.9709\n",
      "[bald] Accuracy after query 569: 0.9737\n",
      "[bald] Accuracy after query 570: 0.9724\n",
      "[bald] Accuracy after query 571: 0.9727\n",
      "[bald] Accuracy after query 572: 0.9752\n",
      "[bald] Accuracy after query 573: 0.9738\n",
      "[bald] Accuracy after query 574: 0.9741\n",
      "[bald] Accuracy after query 575: 0.9732\n",
      "[bald] Accuracy after query 576: 0.9769\n",
      "[bald] Accuracy after query 577: 0.9753\n",
      "[bald] Accuracy after query 578: 0.9745\n",
      "[bald] Accuracy after query 579: 0.9732\n",
      "[bald] Accuracy after query 580: 0.9760\n",
      "[bald] Accuracy after query 581: 0.9700\n",
      "[bald] Accuracy after query 582: 0.9736\n",
      "[bald] Accuracy after query 583: 0.9731\n",
      "[bald] Accuracy after query 584: 0.9743\n",
      "[bald] Accuracy after query 585: 0.9768\n",
      "[bald] Accuracy after query 586: 0.9769\n",
      "[bald] Accuracy after query 587: 0.9727\n",
      "[bald] Accuracy after query 588: 0.9750\n",
      "[bald] Accuracy after query 589: 0.9735\n",
      "[bald] Accuracy after query 590: 0.9762\n",
      "[bald] Accuracy after query 591: 0.9730\n",
      "[bald] Accuracy after query 592: 0.9767\n",
      "[bald] Accuracy after query 593: 0.9733\n",
      "[bald] Accuracy after query 594: 0.9738\n",
      "[bald] Accuracy after query 595: 0.9727\n",
      "[bald] Accuracy after query 596: 0.9742\n",
      "[bald] Accuracy after query 597: 0.9724\n",
      "[bald] Accuracy after query 598: 0.9774\n",
      "[bald] Accuracy after query 599: 0.9743\n",
      "[bald] Accuracy after query 600: 0.9771\n",
      "[bald] Accuracy after query 601: 0.9727\n",
      "[bald] Accuracy after query 602: 0.9733\n",
      "[bald] Accuracy after query 603: 0.9710\n",
      "[bald] Accuracy after query 604: 0.9745\n",
      "[bald] Accuracy after query 605: 0.9749\n",
      "[bald] Accuracy after query 606: 0.9750\n",
      "[bald] Accuracy after query 607: 0.9781\n",
      "[bald] Accuracy after query 608: 0.9776\n",
      "[bald] Accuracy after query 609: 0.9758\n",
      "[bald] Accuracy after query 610: 0.9735\n",
      "[bald] Accuracy after query 611: 0.9726\n",
      "[bald] Accuracy after query 612: 0.9768\n",
      "[bald] Accuracy after query 613: 0.9744\n",
      "[bald] Accuracy after query 614: 0.9776\n",
      "[bald] Accuracy after query 615: 0.9759\n",
      "[bald] Accuracy after query 616: 0.9717\n",
      "[bald] Accuracy after query 617: 0.9760\n",
      "[bald] Accuracy after query 618: 0.9772\n",
      "[bald] Accuracy after query 619: 0.9745\n",
      "[bald] Accuracy after query 620: 0.9743\n",
      "[bald] Accuracy after query 621: 0.9767\n",
      "[bald] Accuracy after query 622: 0.9771\n",
      "[bald] Accuracy after query 623: 0.9750\n",
      "[bald] Accuracy after query 624: 0.9771\n",
      "[bald] Accuracy after query 625: 0.9779\n",
      "[bald] Accuracy after query 626: 0.9760\n",
      "[bald] Accuracy after query 627: 0.9768\n",
      "[bald] Accuracy after query 628: 0.9743\n",
      "[bald] Accuracy after query 629: 0.9777\n",
      "[bald] Accuracy after query 630: 0.9769\n",
      "[bald] Accuracy after query 631: 0.9748\n",
      "[bald] Accuracy after query 632: 0.9786\n",
      "[bald] Accuracy after query 633: 0.9744\n",
      "[bald] Accuracy after query 634: 0.9776\n",
      "[bald] Accuracy after query 635: 0.9766\n",
      "[bald] Accuracy after query 636: 0.9757\n",
      "[bald] Accuracy after query 637: 0.9759\n",
      "[bald] Accuracy after query 638: 0.9712\n",
      "[bald] Accuracy after query 639: 0.9758\n",
      "[bald] Accuracy after query 640: 0.9777\n",
      "[bald] Accuracy after query 641: 0.9767\n",
      "[bald] Accuracy after query 642: 0.9766\n",
      "[bald] Accuracy after query 643: 0.9771\n",
      "[bald] Accuracy after query 644: 0.9749\n",
      "[bald] Accuracy after query 645: 0.9765\n",
      "[bald] Accuracy after query 646: 0.9768\n",
      "[bald] Accuracy after query 647: 0.9784\n",
      "[bald] Accuracy after query 648: 0.9768\n",
      "[bald] Accuracy after query 649: 0.9758\n",
      "[bald] Accuracy after query 650: 0.9767\n",
      "[bald] Accuracy after query 651: 0.9787\n",
      "[bald] Accuracy after query 652: 0.9786\n",
      "[bald] Accuracy after query 653: 0.9794\n",
      "[bald] Accuracy after query 654: 0.9760\n",
      "[bald] Accuracy after query 655: 0.9773\n",
      "[bald] Accuracy after query 656: 0.9784\n",
      "[bald] Accuracy after query 657: 0.9756\n",
      "[bald] Accuracy after query 658: 0.9749\n",
      "[bald] Accuracy after query 659: 0.9787\n",
      "[bald] Accuracy after query 660: 0.9795\n",
      "[bald] Accuracy after query 661: 0.9742\n",
      "[bald] Accuracy after query 662: 0.9772\n",
      "[bald] Accuracy after query 663: 0.9783\n",
      "[bald] Accuracy after query 664: 0.9778\n",
      "[bald] Accuracy after query 665: 0.9759\n",
      "[bald] Accuracy after query 666: 0.9769\n",
      "[bald] Accuracy after query 667: 0.9786\n",
      "[bald] Accuracy after query 668: 0.9765\n",
      "[bald] Accuracy after query 669: 0.9775\n",
      "[bald] Accuracy after query 670: 0.9784\n",
      "[bald] Accuracy after query 671: 0.9721\n",
      "[bald] Accuracy after query 672: 0.9783\n",
      "[bald] Accuracy after query 673: 0.9771\n",
      "[bald] Accuracy after query 674: 0.9770\n",
      "[bald] Accuracy after query 675: 0.9794\n",
      "[bald] Accuracy after query 676: 0.9782\n",
      "[bald] Accuracy after query 677: 0.9783\n",
      "[bald] Accuracy after query 678: 0.9759\n",
      "[bald] Accuracy after query 679: 0.9754\n",
      "[bald] Accuracy after query 680: 0.9757\n",
      "[bald] Accuracy after query 681: 0.9753\n",
      "[bald] Accuracy after query 682: 0.9799\n",
      "[bald] Accuracy after query 683: 0.9802\n",
      "[bald] Accuracy after query 684: 0.9785\n",
      "[bald] Accuracy after query 685: 0.9749\n",
      "[bald] Accuracy after query 686: 0.9746\n",
      "[bald] Accuracy after query 687: 0.9782\n",
      "[bald] Accuracy after query 688: 0.9780\n",
      "[bald] Accuracy after query 689: 0.9768\n",
      "[bald] Accuracy after query 690: 0.9791\n",
      "[bald] Accuracy after query 691: 0.9771\n",
      "[bald] Accuracy after query 692: 0.9755\n",
      "[bald] Accuracy after query 693: 0.9791\n",
      "[bald] Accuracy after query 694: 0.9783\n",
      "[bald] Accuracy after query 695: 0.9783\n",
      "[bald] Accuracy after query 696: 0.9774\n",
      "[bald] Accuracy after query 697: 0.9773\n",
      "[bald] Accuracy after query 698: 0.9744\n",
      "[bald] Accuracy after query 699: 0.9771\n",
      "[bald] Accuracy after query 700: 0.9785\n",
      "[bald] Accuracy after query 701: 0.9776\n",
      "[bald] Accuracy after query 702: 0.9756\n",
      "[bald] Accuracy after query 703: 0.9794\n",
      "[bald] Accuracy after query 704: 0.9784\n",
      "[bald] Accuracy after query 705: 0.9772\n",
      "[bald] Accuracy after query 706: 0.9773\n",
      "[bald] Accuracy after query 707: 0.9765\n",
      "[bald] Accuracy after query 708: 0.9785\n",
      "[bald] Accuracy after query 709: 0.9780\n",
      "[bald] Accuracy after query 710: 0.9759\n",
      "[bald] Accuracy after query 711: 0.9783\n",
      "[bald] Accuracy after query 712: 0.9806\n",
      "[bald] Accuracy after query 713: 0.9750\n",
      "[bald] Accuracy after query 714: 0.9775\n",
      "[bald] Accuracy after query 715: 0.9769\n",
      "[bald] Accuracy after query 716: 0.9795\n",
      "[bald] Accuracy after query 717: 0.9804\n",
      "[bald] Accuracy after query 718: 0.9696\n",
      "[bald] Accuracy after query 719: 0.9776\n",
      "[bald] Accuracy after query 720: 0.9755\n",
      "[bald] Accuracy after query 721: 0.9769\n",
      "[bald] Accuracy after query 722: 0.9780\n",
      "[bald] Accuracy after query 723: 0.9771\n",
      "[bald] Accuracy after query 724: 0.9730\n",
      "[bald] Accuracy after query 725: 0.9774\n",
      "[bald] Accuracy after query 726: 0.9772\n",
      "[bald] Accuracy after query 727: 0.9791\n",
      "[bald] Accuracy after query 728: 0.9761\n",
      "[bald] Accuracy after query 729: 0.9809\n",
      "[bald] Accuracy after query 730: 0.9801\n",
      "[bald] Accuracy after query 731: 0.9768\n",
      "[bald] Accuracy after query 732: 0.9774\n",
      "[bald] Accuracy after query 733: 0.9785\n",
      "[bald] Accuracy after query 734: 0.9791\n",
      "[bald] Accuracy after query 735: 0.9788\n",
      "[bald] Accuracy after query 736: 0.9770\n",
      "[bald] Accuracy after query 737: 0.9771\n",
      "[bald] Accuracy after query 738: 0.9772\n",
      "[bald] Accuracy after query 739: 0.9809\n",
      "[bald] Accuracy after query 740: 0.9796\n",
      "[bald] Accuracy after query 741: 0.9789\n",
      "[bald] Accuracy after query 742: 0.9781\n",
      "[bald] Accuracy after query 743: 0.9785\n",
      "[bald] Accuracy after query 744: 0.9756\n",
      "[bald] Accuracy after query 745: 0.9788\n",
      "[bald] Accuracy after query 746: 0.9777\n",
      "[bald] Accuracy after query 747: 0.9765\n",
      "[bald] Accuracy after query 748: 0.9793\n",
      "[bald] Accuracy after query 749: 0.9787\n",
      "[bald] Accuracy after query 750: 0.9787\n",
      "[bald] Accuracy after query 751: 0.9769\n",
      "[bald] Accuracy after query 752: 0.9780\n",
      "[bald] Accuracy after query 753: 0.9767\n",
      "[bald] Accuracy after query 754: 0.9807\n",
      "[bald] Accuracy after query 755: 0.9799\n",
      "[bald] Accuracy after query 756: 0.9790\n",
      "[bald] Accuracy after query 757: 0.9789\n",
      "[bald] Accuracy after query 758: 0.9779\n",
      "[bald] Accuracy after query 759: 0.9781\n",
      "[bald] Accuracy after query 760: 0.9792\n",
      "[bald] Accuracy after query 761: 0.9789\n",
      "[bald] Accuracy after query 762: 0.9815\n",
      "[bald] Accuracy after query 763: 0.9784\n",
      "[bald] Accuracy after query 764: 0.9796\n",
      "[bald] Accuracy after query 765: 0.9773\n",
      "[bald] Accuracy after query 766: 0.9784\n",
      "[bald] Accuracy after query 767: 0.9767\n",
      "[bald] Accuracy after query 768: 0.9752\n",
      "[bald] Accuracy after query 769: 0.9797\n",
      "[bald] Accuracy after query 770: 0.9768\n",
      "[bald] Accuracy after query 771: 0.9802\n",
      "[bald] Accuracy after query 772: 0.9794\n",
      "[bald] Accuracy after query 773: 0.9778\n",
      "[bald] Accuracy after query 774: 0.9804\n",
      "[bald] Accuracy after query 775: 0.9795\n",
      "[bald] Accuracy after query 776: 0.9779\n",
      "[bald] Accuracy after query 777: 0.9795\n",
      "[bald] Accuracy after query 778: 0.9793\n",
      "[bald] Accuracy after query 779: 0.9777\n",
      "[bald] Accuracy after query 780: 0.9770\n",
      "[bald] Accuracy after query 781: 0.9765\n",
      "[bald] Accuracy after query 782: 0.9797\n",
      "[bald] Accuracy after query 783: 0.9780\n",
      "[bald] Accuracy after query 784: 0.9765\n",
      "[bald] Accuracy after query 785: 0.9784\n",
      "[bald] Accuracy after query 786: 0.9799\n",
      "[bald] Accuracy after query 787: 0.9787\n",
      "[bald] Accuracy after query 788: 0.9797\n",
      "[bald] Accuracy after query 789: 0.9777\n",
      "[bald] Accuracy after query 790: 0.9806\n",
      "[bald] Accuracy after query 791: 0.9795\n",
      "[bald] Accuracy after query 792: 0.9811\n",
      "[bald] Accuracy after query 793: 0.9792\n",
      "[bald] Accuracy after query 794: 0.9776\n",
      "[bald] Accuracy after query 795: 0.9797\n",
      "[bald] Accuracy after query 796: 0.9798\n",
      "[bald] Accuracy after query 797: 0.9755\n",
      "[bald] Accuracy after query 798: 0.9807\n",
      "[bald] Accuracy after query 799: 0.9792\n",
      "[bald] Accuracy after query 800: 0.9767\n",
      "[bald] Accuracy after query 801: 0.9774\n",
      "[bald] Accuracy after query 802: 0.9784\n",
      "[bald] Accuracy after query 803: 0.9793\n",
      "[bald] Accuracy after query 804: 0.9778\n",
      "[bald] Accuracy after query 805: 0.9783\n",
      "[bald] Accuracy after query 806: 0.9801\n",
      "[bald] Accuracy after query 807: 0.9767\n",
      "[bald] Accuracy after query 808: 0.9776\n",
      "[bald] Accuracy after query 809: 0.9802\n",
      "[bald] Accuracy after query 810: 0.9804\n",
      "[bald] Accuracy after query 811: 0.9800\n",
      "[bald] Accuracy after query 812: 0.9787\n",
      "[bald] Accuracy after query 813: 0.9788\n",
      "[bald] Accuracy after query 814: 0.9812\n",
      "[bald] Accuracy after query 815: 0.9779\n",
      "[bald] Accuracy after query 816: 0.9783\n",
      "[bald] Accuracy after query 817: 0.9818\n",
      "[bald] Accuracy after query 818: 0.9796\n",
      "[bald] Accuracy after query 819: 0.9796\n",
      "[bald] Accuracy after query 820: 0.9807\n",
      "[bald] Accuracy after query 821: 0.9811\n",
      "[bald] Accuracy after query 822: 0.9780\n",
      "[bald] Accuracy after query 823: 0.9786\n",
      "[bald] Accuracy after query 824: 0.9795\n",
      "[bald] Accuracy after query 825: 0.9791\n",
      "[bald] Accuracy after query 826: 0.9788\n",
      "[bald] Accuracy after query 827: 0.9790\n",
      "[bald] Accuracy after query 828: 0.9827\n",
      "[bald] Accuracy after query 829: 0.9809\n",
      "[bald] Accuracy after query 830: 0.9793\n",
      "[bald] Accuracy after query 831: 0.9798\n",
      "[bald] Accuracy after query 832: 0.9793\n",
      "[bald] Accuracy after query 833: 0.9804\n",
      "[bald] Accuracy after query 834: 0.9791\n",
      "[bald] Accuracy after query 835: 0.9779\n",
      "[bald] Accuracy after query 836: 0.9784\n",
      "[bald] Accuracy after query 837: 0.9818\n",
      "[bald] Accuracy after query 838: 0.9807\n",
      "[bald] Accuracy after query 839: 0.9813\n",
      "[bald] Accuracy after query 840: 0.9826\n",
      "[bald] Accuracy after query 841: 0.9810\n",
      "[bald] Accuracy after query 842: 0.9807\n",
      "[bald] Accuracy after query 843: 0.9759\n",
      "[bald] Accuracy after query 844: 0.9805\n",
      "[bald] Accuracy after query 845: 0.9800\n",
      "[bald] Accuracy after query 846: 0.9804\n",
      "[bald] Accuracy after query 847: 0.9810\n",
      "[bald] Accuracy after query 848: 0.9787\n",
      "[bald] Accuracy after query 849: 0.9802\n",
      "[bald] Accuracy after query 850: 0.9781\n",
      "[bald] Accuracy after query 851: 0.9783\n",
      "[bald] Accuracy after query 852: 0.9796\n",
      "[bald] Accuracy after query 853: 0.9822\n",
      "[bald] Accuracy after query 854: 0.9811\n",
      "[bald] Accuracy after query 855: 0.9790\n",
      "[bald] Accuracy after query 856: 0.9806\n",
      "[bald] Accuracy after query 857: 0.9804\n",
      "[bald] Accuracy after query 858: 0.9774\n",
      "[bald] Accuracy after query 859: 0.9793\n",
      "[bald] Accuracy after query 860: 0.9825\n",
      "[bald] Accuracy after query 861: 0.9792\n",
      "[bald] Accuracy after query 862: 0.9802\n",
      "[bald] Accuracy after query 863: 0.9799\n",
      "[bald] Accuracy after query 864: 0.9799\n",
      "[bald] Accuracy after query 865: 0.9816\n",
      "[bald] Accuracy after query 866: 0.9820\n",
      "[bald] Accuracy after query 867: 0.9820\n",
      "[bald] Accuracy after query 868: 0.9819\n",
      "[bald] Accuracy after query 869: 0.9819\n",
      "[bald] Accuracy after query 870: 0.9822\n",
      "[bald] Accuracy after query 871: 0.9821\n",
      "[bald] Accuracy after query 872: 0.9809\n",
      "[bald] Accuracy after query 873: 0.9802\n",
      "[bald] Accuracy after query 874: 0.9813\n",
      "[bald] Accuracy after query 875: 0.9824\n",
      "[bald] Accuracy after query 876: 0.9820\n",
      "[bald] Accuracy after query 877: 0.9793\n",
      "[bald] Accuracy after query 878: 0.9791\n",
      "[bald] Accuracy after query 879: 0.9830\n",
      "[bald] Accuracy after query 880: 0.9834\n",
      "[bald] Accuracy after query 881: 0.9812\n",
      "[bald] Accuracy after query 882: 0.9826\n",
      "[bald] Accuracy after query 883: 0.9777\n",
      "[bald] Accuracy after query 884: 0.9795\n",
      "[bald] Accuracy after query 885: 0.9822\n",
      "[bald] Accuracy after query 886: 0.9811\n",
      "[bald] Accuracy after query 887: 0.9827\n",
      "[bald] Accuracy after query 888: 0.9805\n",
      "[bald] Accuracy after query 889: 0.9806\n",
      "[bald] Accuracy after query 890: 0.9808\n",
      "[bald] Accuracy after query 891: 0.9802\n",
      "[bald] Accuracy after query 892: 0.9797\n",
      "[bald] Accuracy after query 893: 0.9839\n",
      "[bald] Accuracy after query 894: 0.9825\n",
      "[bald] Accuracy after query 895: 0.9795\n",
      "[bald] Accuracy after query 896: 0.9803\n",
      "[bald] Accuracy after query 897: 0.9813\n",
      "[bald] Accuracy after query 898: 0.9806\n",
      "[bald] Accuracy after query 899: 0.9825\n",
      "[bald] Accuracy after query 900: 0.9794\n",
      "[bald] Accuracy after query 901: 0.9784\n",
      "[bald] Accuracy after query 902: 0.9807\n",
      "[bald] Accuracy after query 903: 0.9815\n",
      "[bald] Accuracy after query 904: 0.9806\n",
      "[bald] Accuracy after query 905: 0.9815\n",
      "[bald] Accuracy after query 906: 0.9822\n",
      "[bald] Accuracy after query 907: 0.9801\n",
      "[bald] Accuracy after query 908: 0.9802\n",
      "[bald] Accuracy after query 909: 0.9814\n",
      "[bald] Accuracy after query 910: 0.9824\n",
      "[bald] Accuracy after query 911: 0.9798\n",
      "[bald] Accuracy after query 912: 0.9822\n",
      "[bald] Accuracy after query 913: 0.9804\n",
      "[bald] Accuracy after query 914: 0.9814\n",
      "[bald] Accuracy after query 915: 0.9810\n",
      "[bald] Accuracy after query 916: 0.9835\n",
      "[bald] Accuracy after query 917: 0.9817\n",
      "[bald] Accuracy after query 918: 0.9817\n",
      "[bald] Accuracy after query 919: 0.9828\n",
      "[bald] Accuracy after query 920: 0.9814\n",
      "[bald] Accuracy after query 921: 0.9805\n",
      "[bald] Accuracy after query 922: 0.9809\n",
      "[bald] Accuracy after query 923: 0.9810\n",
      "[bald] Accuracy after query 924: 0.9801\n",
      "[bald] Accuracy after query 925: 0.9809\n",
      "[bald] Accuracy after query 926: 0.9743\n",
      "[bald] Accuracy after query 927: 0.9803\n",
      "[bald] Accuracy after query 928: 0.9786\n",
      "[bald] Accuracy after query 929: 0.9789\n",
      "[bald] Accuracy after query 930: 0.9787\n",
      "[bald] Accuracy after query 931: 0.9811\n",
      "[bald] Accuracy after query 932: 0.9728\n",
      "[bald] Accuracy after query 933: 0.9787\n",
      "[bald] Accuracy after query 934: 0.9824\n",
      "[bald] Accuracy after query 935: 0.9795\n",
      "[bald] Accuracy after query 936: 0.9775\n",
      "[bald] Accuracy after query 937: 0.9791\n",
      "[bald] Accuracy after query 938: 0.9785\n",
      "[bald] Accuracy after query 939: 0.9804\n",
      "[bald] Accuracy after query 940: 0.9830\n",
      "[bald] Accuracy after query 941: 0.9809\n",
      "[bald] Accuracy after query 942: 0.9823\n",
      "[bald] Accuracy after query 943: 0.9813\n",
      "[bald] Accuracy after query 944: 0.9798\n",
      "[bald] Accuracy after query 945: 0.9778\n",
      "[bald] Accuracy after query 946: 0.9798\n",
      "[bald] Accuracy after query 947: 0.9806\n",
      "[bald] Accuracy after query 948: 0.9807\n",
      "[bald] Accuracy after query 949: 0.9804\n",
      "[bald] Accuracy after query 950: 0.9810\n",
      "[bald] Accuracy after query 951: 0.9808\n",
      "[bald] Accuracy after query 952: 0.9805\n",
      "[bald] Accuracy after query 953: 0.9802\n",
      "[bald] Accuracy after query 954: 0.9808\n",
      "[bald] Accuracy after query 955: 0.9807\n",
      "[bald] Accuracy after query 956: 0.9786\n",
      "[bald] Accuracy after query 957: 0.9804\n",
      "[bald] Accuracy after query 958: 0.9780\n",
      "[bald] Accuracy after query 959: 0.9829\n",
      "[bald] Accuracy after query 960: 0.9804\n",
      "[bald] Accuracy after query 961: 0.9793\n",
      "[bald] Accuracy after query 962: 0.9811\n",
      "[bald] Accuracy after query 963: 0.9811\n",
      "[bald] Accuracy after query 964: 0.9840\n",
      "[bald] Accuracy after query 965: 0.9787\n",
      "[bald] Accuracy after query 966: 0.9803\n",
      "[bald] Accuracy after query 967: 0.9822\n",
      "[bald] Accuracy after query 968: 0.9817\n",
      "[bald] Accuracy after query 969: 0.9811\n",
      "[bald] Accuracy after query 970: 0.9845\n",
      "[bald] Accuracy after query 971: 0.9792\n",
      "[bald] Accuracy after query 972: 0.9817\n",
      "[bald] Accuracy after query 973: 0.9822\n",
      "[bald] Accuracy after query 974: 0.9832\n",
      "[bald] Accuracy after query 975: 0.9796\n",
      "[bald] Accuracy after query 976: 0.9826\n",
      "[bald] Accuracy after query 977: 0.9818\n",
      "[bald] Accuracy after query 978: 0.9824\n",
      "[bald] Accuracy after query 979: 0.9814\n",
      "[bald] Accuracy after query 980: 0.9800\n",
      "[bald] Accuracy after query 981: 0.9829\n",
      "[bald] Accuracy after query 982: 0.9824\n",
      "[bald] Accuracy after query 983: 0.9814\n",
      "[bald] Accuracy after query 984: 0.9814\n",
      "[bald] Accuracy after query 985: 0.9824\n",
      "[bald] Accuracy after query 986: 0.9838\n",
      "[bald] Accuracy after query 987: 0.9788\n",
      "[bald] Accuracy after query 988: 0.9819\n",
      "[bald] Accuracy after query 989: 0.9807\n",
      "[bald] Accuracy after query 990: 0.9820\n",
      "[bald] Accuracy after query 991: 0.9824\n",
      "[bald] Accuracy after query 992: 0.9782\n",
      "[bald] Accuracy after query 993: 0.9809\n",
      "[bald] Accuracy after query 994: 0.9824\n",
      "[bald] Accuracy after query 995: 0.9822\n",
      "[bald] Accuracy after query 996: 0.9806\n",
      "[bald] Accuracy after query 997: 0.9822\n",
      "[bald] Accuracy after query 998: 0.9816\n",
      "[bald] Accuracy after query 999: 0.9834\n",
      "[bald] Accuracy after query 1000: 0.9821\n"
     ]
    }
   ],
   "source": [
    "for query_strategy_name, query_strategy in query_strategies.items():\n",
    "    query_strategy['classifier'] = NeuralNetClassifier(CNN,\n",
    "                                max_epochs=50,\n",
    "                                batch_size=128,\n",
    "                                lr=0.001,\n",
    "                                optimizer=torch.optim.Adam,\n",
    "                                criterion=torch.nn.CrossEntropyLoss,\n",
    "                                train_split=None,\n",
    "                                verbose=0,\n",
    "                                device=device)\n",
    "    query_strategy['learner'], query_strategy['performance_history'] = active_learning_procedure(query_strategy['function'],\n",
    "                                                X_test,\n",
    "                                                y_test,\n",
    "                                                X_train_unlabelled,\n",
    "                                                y_train_unlabelled,\n",
    "                                                X_train_labelled_initial,\n",
    "                                                y_train_labelled_initial,\n",
    "                                                query_strategy['classifier'],\n",
    "                                                query_strategy_label=query_strategy_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "69232167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save models and data\n",
    "performance_histories = {}\n",
    "for query_strategy_name, query_strategy in query_strategies.items():\n",
    "    # Save classifiers\n",
    "    query_strategy['classifier'].save_params(f_params=f'{BASE_DIR}/saved_models/{DATASET}_{query_strategy_name}_{N_LABELS*INITIAL_LABEL_PER_CLASS}_{SEED}.pkl')\n",
    "\n",
    "# Save initial labelled and unlabelled data\n",
    "X_train_labelled_initial = X_train[initial_labelled_idx]\n",
    "y_train_labelled_initial = y_train[initial_labelled_idx]\n",
    "torch.save(X_train_labelled_initial, f'{BASE_DIR}/saved_data/{DATASET}_X_train_labelled_{N_LABELS*INITIAL_LABEL_PER_CLASS}_{SEED}.pt')\n",
    "torch.save(y_train_labelled_initial, f'{BASE_DIR}/saved_data/{DATASET}_y_train_labelled_{N_LABELS*INITIAL_LABEL_PER_CLASS}_{SEED}.pt')\n",
    "torch.save(X_train_unlabelled, f'{BASE_DIR}/saved_data/{DATASET}_X_train_unlabelled_{N_LABELS*INITIAL_LABEL_PER_CLASS}_{SEED}.pt')\n",
    "torch.save(y_train_unlabelled, f'{BASE_DIR}/saved_data/{DATASET}_y_train_unlabelled_{N_LABELS*INITIAL_LABEL_PER_CLASS}_{SEED}.pt')\n",
    "\n",
    "# Save test data\n",
    "torch.save(X_test, f'{BASE_DIR}/saved_data/{DATASET}_X_test_{SEED}.pt')\n",
    "torch.save(y_test, f'{BASE_DIR}/saved_data/{DATASET}_y_test_{SEED}.pt')\n",
    "\n",
    "# Save performance histories (preprocessing)\n",
    "performance_histories = {query_strategy_name: query_strategy['performance_history'] for query_strategy_name, query_strategy in query_strategies.items()}\n",
    "pd.DataFrame(performance_histories).to_csv(f'{BASE_DIR}/saved_data/{DATASET}_active_learning_performance_histories_{N_LABELS*INITIAL_LABEL_PER_CLASS}_{SEED}.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b6654fe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f08049d0760>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot\n",
    "sns.set()\n",
    "# plt.plot(query_strategies['max_entropy']['performance_history'], label=\"max entropy\")\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "ax.yaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
    "\n",
    "# Major ticks every 20, minor ticks every 5\n",
    "major_ticks = np.arange(0, 1001, 100)\n",
    "ax.set_xticks(major_ticks)\n",
    "\n",
    "x_ticks = np.arange(0, 1001, 1)\n",
    "ax.plot(x_ticks, query_strategies['bald']['performance_history'], label=\"Bald\")\n",
    "ax.plot(x_ticks, query_strategies['random']['performance_history'], label=\"Random (Uniform)\")\n",
    "ax.set_ylim([0.8,1])\n",
    "\n",
    "ax.set_ylabel(\"Accuracy\")\n",
    "ax.set_xlabel(\"Number of acquired data points\")\n",
    "ax.set_title(\"Performance of Active Learning Algorithms\")\n",
    "ax.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5e79de",
   "metadata": {},
   "source": [
    "###  Semi-supervised Learning\n",
    "\n",
    "<img src=\"./images/dgm.png\" width=\"400px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e6f4f4",
   "metadata": {},
   "source": [
    "## Non-progressive Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "042cd798",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import DeepGenerativeModel\n",
    "from datautils import get_dataset\n",
    "from itertools import cycle\n",
    "from inference import SVI, ImportanceWeightedSampler\n",
    "from torch.autograd import Variable\n",
    "\n",
    "SSL_EPOCHS = 100\n",
    "\n",
    "def binary_cross_entropy(y_pred, y):\n",
    "    return -torch.sum(y * torch.log(y_pred + 1e-8) + (1 - y) * torch.log(1 - y_pred + 1e-8), dim=-1)\n",
    "\n",
    "\n",
    "x_dim = 784\n",
    "y_dim = 10\n",
    "z_dim = 32\n",
    "h_dim = [256, 128]\n",
    "\n",
    "SSL_metrics = {'random':{'train_loss_history':None,\n",
    "                                'train_accuracy_history': None,\n",
    "                                'test_loss_history': None,\n",
    "                                'test_accuracy_history': None},\n",
    "                    'bald':{'train_loss_history':None,\n",
    "                                'train_accuracy_history': None,\n",
    "                                'test_loss_history': None,\n",
    "                                'test_accuracy_history': None},\n",
    "                    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d2252dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_J_alpha(x, y, u, alpha, model):\n",
    "    # Calculate ELBOs\n",
    "    L = -elbo(x, y)\n",
    "    U = -elbo(u)\n",
    "\n",
    "    # Add auxiliary classification loss q(y|x)\n",
    "    logits = model.classify(x)\n",
    "    \n",
    "    # Regular cross entropy\n",
    "    classification_loss = -torch.sum(y * torch.log(logits + 1e-8), dim=1).mean()\n",
    "\n",
    "    J_alpha = L + alpha * classification_loss + U\n",
    "\n",
    "    return J_alpha, logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d45d84fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./saved_data/X_train_labelled_random_100.pt\n",
      "./saved_data/y_train_labelled_random_100.pt\n",
      "1100 1100\n",
      "./saved_data/X_train_unlabelled_random_100.pt\n",
      "./saved_data/y_train_unlabelled_random_100.pt\n",
      "58900 58900\n",
      "./saved_data/X_test.pt\n",
      "./saved_data/y_test.pt\n",
      "10000 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/ucl/dissertation/./semi-supervised/models/vae.py:114: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
      "  init.xavier_normal(m.weight.data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "[Train]\t J_a: 383.45, accuracy: 1.00\n",
      "[Test]\t J_a: 318.82, accuracy: 0.96\n",
      "Epoch: 1\n",
      "[Train]\t J_a: 305.47, accuracy: 1.00\n",
      "[Test]\t J_a: 298.15, accuracy: 0.96\n",
      "Epoch: 2\n",
      "[Train]\t J_a: 290.13, accuracy: 1.00\n",
      "[Test]\t J_a: 288.48, accuracy: 0.96\n",
      "Epoch: 3\n",
      "[Train]\t J_a: 282.67, accuracy: 1.00\n",
      "[Test]\t J_a: 283.41, accuracy: 0.96\n",
      "Epoch: 4\n",
      "[Train]\t J_a: 277.09, accuracy: 1.00\n",
      "[Test]\t J_a: 279.43, accuracy: 0.96\n",
      "Epoch: 5\n",
      "[Train]\t J_a: 271.95, accuracy: 1.00\n",
      "[Test]\t J_a: 276.53, accuracy: 0.96\n",
      "Epoch: 6\n",
      "[Train]\t J_a: 269.98, accuracy: 1.00\n",
      "[Test]\t J_a: 274.97, accuracy: 0.96\n",
      "Epoch: 7\n",
      "[Train]\t J_a: 267.24, accuracy: 1.00\n",
      "[Test]\t J_a: 273.49, accuracy: 0.96\n",
      "Epoch: 8\n",
      "[Train]\t J_a: 264.72, accuracy: 1.00\n",
      "[Test]\t J_a: 271.83, accuracy: 0.96\n",
      "Epoch: 9\n",
      "[Train]\t J_a: 263.43, accuracy: 1.00\n",
      "[Test]\t J_a: 271.09, accuracy: 0.96\n",
      "Epoch: 10\n",
      "[Train]\t J_a: 261.93, accuracy: 1.00\n",
      "[Test]\t J_a: 269.87, accuracy: 0.96\n",
      "Epoch: 11\n",
      "[Train]\t J_a: 260.31, accuracy: 1.00\n",
      "[Test]\t J_a: 269.58, accuracy: 0.96\n",
      "Epoch: 12\n",
      "[Train]\t J_a: 259.09, accuracy: 1.00\n",
      "[Test]\t J_a: 268.25, accuracy: 0.96\n",
      "Epoch: 13\n",
      "[Train]\t J_a: 259.19, accuracy: 1.00\n",
      "[Test]\t J_a: 268.40, accuracy: 0.96\n",
      "Epoch: 14\n",
      "[Train]\t J_a: 257.91, accuracy: 1.00\n",
      "[Test]\t J_a: 267.67, accuracy: 0.96\n",
      "Epoch: 15\n",
      "[Train]\t J_a: 256.85, accuracy: 1.00\n",
      "[Test]\t J_a: 267.41, accuracy: 0.96\n",
      "Epoch: 16\n",
      "[Train]\t J_a: 256.21, accuracy: 1.00\n",
      "[Test]\t J_a: 266.98, accuracy: 0.96\n",
      "Epoch: 17\n",
      "[Train]\t J_a: 256.08, accuracy: 1.00\n",
      "[Test]\t J_a: 266.43, accuracy: 0.96\n",
      "Epoch: 18\n",
      "[Train]\t J_a: 255.08, accuracy: 1.00\n",
      "[Test]\t J_a: 265.86, accuracy: 0.96\n",
      "Epoch: 19\n",
      "[Train]\t J_a: 254.45, accuracy: 1.00\n",
      "[Test]\t J_a: 266.08, accuracy: 0.96\n",
      "Epoch: 20\n",
      "[Train]\t J_a: 254.16, accuracy: 1.00\n",
      "[Test]\t J_a: 265.87, accuracy: 0.96\n",
      "Epoch: 21\n",
      "[Train]\t J_a: 253.75, accuracy: 1.00\n",
      "[Test]\t J_a: 265.52, accuracy: 0.96\n",
      "Epoch: 22\n",
      "[Train]\t J_a: 253.08, accuracy: 1.00\n",
      "[Test]\t J_a: 265.27, accuracy: 0.96\n",
      "Epoch: 23\n",
      "[Train]\t J_a: 252.68, accuracy: 1.00\n",
      "[Test]\t J_a: 264.74, accuracy: 0.96\n",
      "Epoch: 24\n",
      "[Train]\t J_a: 252.18, accuracy: 1.00\n",
      "[Test]\t J_a: 264.84, accuracy: 0.96\n",
      "Epoch: 25\n",
      "[Train]\t J_a: 252.04, accuracy: 1.00\n",
      "[Test]\t J_a: 265.19, accuracy: 0.96\n",
      "Epoch: 26\n",
      "[Train]\t J_a: 251.37, accuracy: 1.00\n",
      "[Test]\t J_a: 264.56, accuracy: 0.96\n",
      "Epoch: 27\n",
      "[Train]\t J_a: 251.85, accuracy: 1.00\n",
      "[Test]\t J_a: 264.55, accuracy: 0.96\n",
      "Epoch: 28\n",
      "[Train]\t J_a: 251.10, accuracy: 1.00\n",
      "[Test]\t J_a: 263.97, accuracy: 0.96\n",
      "Epoch: 29\n",
      "[Train]\t J_a: 251.06, accuracy: 1.00\n",
      "[Test]\t J_a: 264.72, accuracy: 0.96\n",
      "Epoch: 30\n",
      "[Train]\t J_a: 250.26, accuracy: 1.00\n",
      "[Test]\t J_a: 264.12, accuracy: 0.96\n",
      "Epoch: 31\n",
      "[Train]\t J_a: 250.19, accuracy: 1.00\n",
      "[Test]\t J_a: 263.69, accuracy: 0.96\n",
      "Epoch: 32\n",
      "[Train]\t J_a: 250.12, accuracy: 1.00\n",
      "[Test]\t J_a: 264.61, accuracy: 0.96\n",
      "Epoch: 33\n",
      "[Train]\t J_a: 249.86, accuracy: 1.00\n",
      "[Test]\t J_a: 263.83, accuracy: 0.96\n",
      "Epoch: 34\n",
      "[Train]\t J_a: 249.10, accuracy: 1.00\n",
      "[Test]\t J_a: 263.83, accuracy: 0.96\n",
      "Epoch: 35\n",
      "[Train]\t J_a: 249.15, accuracy: 1.00\n",
      "[Test]\t J_a: 263.84, accuracy: 0.96\n",
      "Epoch: 36\n",
      "[Train]\t J_a: 248.91, accuracy: 1.00\n",
      "[Test]\t J_a: 263.59, accuracy: 0.96\n",
      "Epoch: 37\n",
      "[Train]\t J_a: 249.44, accuracy: 1.00\n",
      "[Test]\t J_a: 263.92, accuracy: 0.96\n",
      "Epoch: 38\n",
      "[Train]\t J_a: 248.85, accuracy: 1.00\n",
      "[Test]\t J_a: 263.64, accuracy: 0.96\n",
      "Epoch: 39\n",
      "[Train]\t J_a: 248.47, accuracy: 1.00\n",
      "[Test]\t J_a: 263.63, accuracy: 0.96\n",
      "Epoch: 40\n",
      "[Train]\t J_a: 248.88, accuracy: 1.00\n",
      "[Test]\t J_a: 262.95, accuracy: 0.96\n",
      "Epoch: 41\n",
      "[Train]\t J_a: 248.02, accuracy: 1.00\n",
      "[Test]\t J_a: 263.67, accuracy: 0.96\n",
      "Epoch: 42\n",
      "[Train]\t J_a: 248.02, accuracy: 1.00\n",
      "[Test]\t J_a: 263.51, accuracy: 0.96\n",
      "Epoch: 43\n",
      "[Train]\t J_a: 247.63, accuracy: 1.00\n",
      "[Test]\t J_a: 263.31, accuracy: 0.96\n",
      "Epoch: 44\n",
      "[Train]\t J_a: 247.79, accuracy: 1.00\n",
      "[Test]\t J_a: 263.21, accuracy: 0.96\n",
      "Epoch: 45\n",
      "[Train]\t J_a: 247.29, accuracy: 1.00\n",
      "[Test]\t J_a: 262.71, accuracy: 0.96\n",
      "Epoch: 46\n",
      "[Train]\t J_a: 247.65, accuracy: 1.00\n",
      "[Test]\t J_a: 263.05, accuracy: 0.96\n",
      "Epoch: 47\n",
      "[Train]\t J_a: 247.64, accuracy: 1.00\n",
      "[Test]\t J_a: 263.55, accuracy: 0.96\n",
      "Epoch: 48\n",
      "[Train]\t J_a: 247.69, accuracy: 1.00\n",
      "[Test]\t J_a: 263.47, accuracy: 0.96\n",
      "Epoch: 49\n",
      "[Train]\t J_a: 246.87, accuracy: 1.00\n",
      "[Test]\t J_a: 263.05, accuracy: 0.96\n",
      "Epoch: 50\n",
      "[Train]\t J_a: 247.14, accuracy: 1.00\n",
      "[Test]\t J_a: 262.78, accuracy: 0.96\n",
      "Epoch: 51\n",
      "[Train]\t J_a: 246.74, accuracy: 1.00\n",
      "[Test]\t J_a: 263.01, accuracy: 0.96\n",
      "Epoch: 52\n",
      "[Train]\t J_a: 247.17, accuracy: 1.00\n",
      "[Test]\t J_a: 262.76, accuracy: 0.96\n",
      "Epoch: 53\n",
      "[Train]\t J_a: 246.39, accuracy: 1.00\n",
      "[Test]\t J_a: 263.01, accuracy: 0.96\n",
      "Epoch: 54\n",
      "[Train]\t J_a: 246.35, accuracy: 1.00\n",
      "[Test]\t J_a: 263.12, accuracy: 0.96\n",
      "Epoch: 55\n",
      "[Train]\t J_a: 246.43, accuracy: 1.00\n",
      "[Test]\t J_a: 262.54, accuracy: 0.96\n",
      "Epoch: 56\n",
      "[Train]\t J_a: 246.42, accuracy: 1.00\n",
      "[Test]\t J_a: 262.57, accuracy: 0.96\n",
      "Epoch: 57\n",
      "[Train]\t J_a: 245.90, accuracy: 1.00\n",
      "[Test]\t J_a: 262.49, accuracy: 0.96\n",
      "Epoch: 58\n",
      "[Train]\t J_a: 246.69, accuracy: 1.00\n",
      "[Test]\t J_a: 262.57, accuracy: 0.96\n",
      "Epoch: 59\n",
      "[Train]\t J_a: 245.95, accuracy: 1.00\n",
      "[Test]\t J_a: 262.90, accuracy: 0.96\n",
      "Epoch: 60\n",
      "[Train]\t J_a: 246.12, accuracy: 1.00\n",
      "[Test]\t J_a: 262.70, accuracy: 0.96\n",
      "Epoch: 61\n",
      "[Train]\t J_a: 246.05, accuracy: 1.00\n",
      "[Test]\t J_a: 262.26, accuracy: 0.96\n",
      "Epoch: 62\n",
      "[Train]\t J_a: 245.68, accuracy: 1.00\n",
      "[Test]\t J_a: 262.53, accuracy: 0.95\n",
      "Epoch: 63\n",
      "[Train]\t J_a: 245.52, accuracy: 1.00\n",
      "[Test]\t J_a: 261.99, accuracy: 0.96\n",
      "Epoch: 64\n",
      "[Train]\t J_a: 245.57, accuracy: 1.00\n",
      "[Test]\t J_a: 262.20, accuracy: 0.96\n",
      "Epoch: 65\n",
      "[Train]\t J_a: 245.97, accuracy: 1.00\n",
      "[Test]\t J_a: 262.47, accuracy: 0.96\n",
      "Epoch: 66\n",
      "[Train]\t J_a: 245.34, accuracy: 1.00\n",
      "[Test]\t J_a: 262.35, accuracy: 0.96\n",
      "Epoch: 67\n",
      "[Train]\t J_a: 245.35, accuracy: 1.00\n",
      "[Test]\t J_a: 262.28, accuracy: 0.96\n",
      "Epoch: 68\n",
      "[Train]\t J_a: 245.28, accuracy: 1.00\n",
      "[Test]\t J_a: 262.22, accuracy: 0.96\n",
      "Epoch: 69\n",
      "[Train]\t J_a: 245.09, accuracy: 1.00\n",
      "[Test]\t J_a: 262.45, accuracy: 0.96\n",
      "Epoch: 70\n",
      "[Train]\t J_a: 245.22, accuracy: 1.00\n",
      "[Test]\t J_a: 262.23, accuracy: 0.96\n",
      "Epoch: 71\n",
      "[Train]\t J_a: 245.36, accuracy: 1.00\n",
      "[Test]\t J_a: 262.10, accuracy: 0.96\n",
      "Epoch: 72\n",
      "[Train]\t J_a: 245.10, accuracy: 1.00\n",
      "[Test]\t J_a: 262.05, accuracy: 0.96\n",
      "Epoch: 73\n",
      "[Train]\t J_a: 245.44, accuracy: 1.00\n",
      "[Test]\t J_a: 262.21, accuracy: 0.96\n",
      "Epoch: 74\n",
      "[Train]\t J_a: 244.94, accuracy: 1.00\n",
      "[Test]\t J_a: 262.01, accuracy: 0.96\n",
      "Epoch: 75\n",
      "[Train]\t J_a: 244.83, accuracy: 1.00\n",
      "[Test]\t J_a: 262.17, accuracy: 0.96\n",
      "Epoch: 76\n",
      "[Train]\t J_a: 245.21, accuracy: 1.00\n",
      "[Test]\t J_a: 262.21, accuracy: 0.96\n",
      "Epoch: 77\n",
      "[Train]\t J_a: 244.98, accuracy: 1.00\n",
      "[Test]\t J_a: 262.11, accuracy: 0.96\n",
      "Epoch: 78\n",
      "[Train]\t J_a: 244.47, accuracy: 1.00\n",
      "[Test]\t J_a: 262.19, accuracy: 0.96\n",
      "Epoch: 79\n",
      "[Train]\t J_a: 245.10, accuracy: 1.00\n",
      "[Test]\t J_a: 261.63, accuracy: 0.96\n",
      "Epoch: 80\n",
      "[Train]\t J_a: 244.95, accuracy: 1.00\n",
      "[Test]\t J_a: 262.26, accuracy: 0.96\n",
      "Epoch: 81\n",
      "[Train]\t J_a: 244.87, accuracy: 1.00\n",
      "[Test]\t J_a: 262.11, accuracy: 0.96\n",
      "Epoch: 82\n",
      "[Train]\t J_a: 244.56, accuracy: 1.00\n",
      "[Test]\t J_a: 261.85, accuracy: 0.96\n",
      "Epoch: 83\n",
      "[Train]\t J_a: 244.89, accuracy: 1.00\n",
      "[Test]\t J_a: 262.14, accuracy: 0.96\n",
      "Epoch: 84\n",
      "[Train]\t J_a: 244.28, accuracy: 1.00\n",
      "[Test]\t J_a: 262.14, accuracy: 0.96\n",
      "Epoch: 85\n",
      "[Train]\t J_a: 244.38, accuracy: 1.00\n",
      "[Test]\t J_a: 261.91, accuracy: 0.96\n",
      "Epoch: 86\n",
      "[Train]\t J_a: 243.84, accuracy: 1.00\n",
      "[Test]\t J_a: 262.17, accuracy: 0.96\n",
      "Epoch: 87\n",
      "[Train]\t J_a: 243.95, accuracy: 1.00\n",
      "[Test]\t J_a: 261.88, accuracy: 0.96\n",
      "Epoch: 88\n",
      "[Train]\t J_a: 244.81, accuracy: 1.00\n",
      "[Test]\t J_a: 262.20, accuracy: 0.96\n",
      "Epoch: 89\n",
      "[Train]\t J_a: 244.33, accuracy: 1.00\n",
      "[Test]\t J_a: 261.62, accuracy: 0.96\n",
      "Epoch: 90\n",
      "[Train]\t J_a: 244.23, accuracy: 1.00\n",
      "[Test]\t J_a: 261.62, accuracy: 0.96\n",
      "Epoch: 91\n",
      "[Train]\t J_a: 244.79, accuracy: 1.00\n",
      "[Test]\t J_a: 261.84, accuracy: 0.96\n",
      "Epoch: 92\n",
      "[Train]\t J_a: 244.28, accuracy: 1.00\n",
      "[Test]\t J_a: 261.66, accuracy: 0.96\n",
      "Epoch: 93\n",
      "[Train]\t J_a: 244.02, accuracy: 1.00\n",
      "[Test]\t J_a: 261.68, accuracy: 0.96\n",
      "Epoch: 94\n",
      "[Train]\t J_a: 243.74, accuracy: 1.00\n",
      "[Test]\t J_a: 261.74, accuracy: 0.96\n",
      "Epoch: 95\n",
      "[Train]\t J_a: 243.61, accuracy: 1.00\n",
      "[Test]\t J_a: 262.22, accuracy: 0.96\n",
      "Epoch: 96\n",
      "[Train]\t J_a: 244.05, accuracy: 1.00\n",
      "[Test]\t J_a: 261.63, accuracy: 0.96\n",
      "Epoch: 97\n",
      "[Train]\t J_a: 244.20, accuracy: 1.00\n",
      "[Test]\t J_a: 262.20, accuracy: 0.96\n",
      "Epoch: 98\n",
      "[Train]\t J_a: 244.07, accuracy: 1.00\n",
      "[Test]\t J_a: 261.80, accuracy: 0.96\n",
      "Epoch: 99\n",
      "[Train]\t J_a: 244.04, accuracy: 1.00\n",
      "[Test]\t J_a: 261.80, accuracy: 0.96\n",
      "./saved_data/X_train_labelled_bald_100.pt\n",
      "./saved_data/y_train_labelled_bald_100.pt\n",
      "1100 1100\n",
      "./saved_data/X_train_unlabelled_bald_100.pt\n",
      "./saved_data/y_train_unlabelled_bald_100.pt\n",
      "58900 58900\n",
      "./saved_data/X_test.pt\n",
      "./saved_data/y_test.pt\n",
      "10000 10000\n",
      "Epoch: 0\n",
      "[Train]\t J_a: 401.58, accuracy: 0.99\n",
      "[Test]\t J_a: 320.72, accuracy: 0.97\n",
      "Epoch: 1\n",
      "[Train]\t J_a: 326.83, accuracy: 0.99\n",
      "[Test]\t J_a: 300.48, accuracy: 0.97\n",
      "Epoch: 2\n",
      "[Train]\t J_a: 313.10, accuracy: 0.99\n",
      "[Test]\t J_a: 292.62, accuracy: 0.97\n",
      "Epoch: 3\n",
      "[Train]\t J_a: 305.25, accuracy: 0.99\n",
      "[Test]\t J_a: 287.82, accuracy: 0.97\n",
      "Epoch: 4\n",
      "[Train]\t J_a: 299.64, accuracy: 0.99\n",
      "[Test]\t J_a: 284.60, accuracy: 0.97\n",
      "Epoch: 5\n",
      "[Train]\t J_a: 296.07, accuracy: 0.99\n",
      "[Test]\t J_a: 282.27, accuracy: 0.97\n",
      "Epoch: 6\n",
      "[Train]\t J_a: 293.44, accuracy: 0.99\n",
      "[Test]\t J_a: 280.24, accuracy: 0.97\n",
      "Epoch: 7\n",
      "[Train]\t J_a: 290.55, accuracy: 0.99\n",
      "[Test]\t J_a: 278.89, accuracy: 0.97\n",
      "Epoch: 8\n",
      "[Train]\t J_a: 288.80, accuracy: 1.00\n",
      "[Test]\t J_a: 277.48, accuracy: 0.97\n",
      "Epoch: 9\n",
      "[Train]\t J_a: 287.13, accuracy: 0.99\n",
      "[Test]\t J_a: 276.05, accuracy: 0.97\n",
      "Epoch: 10\n",
      "[Train]\t J_a: 285.44, accuracy: 0.99\n",
      "[Test]\t J_a: 275.37, accuracy: 0.97\n",
      "Epoch: 11\n",
      "[Train]\t J_a: 283.76, accuracy: 0.99\n",
      "[Test]\t J_a: 274.54, accuracy: 0.97\n",
      "Epoch: 12\n",
      "[Train]\t J_a: 282.09, accuracy: 0.99\n",
      "[Test]\t J_a: 273.74, accuracy: 0.97\n",
      "Epoch: 13\n",
      "[Train]\t J_a: 281.38, accuracy: 0.99\n",
      "[Test]\t J_a: 273.36, accuracy: 0.97\n",
      "Epoch: 14\n",
      "[Train]\t J_a: 279.74, accuracy: 0.99\n",
      "[Test]\t J_a: 273.13, accuracy: 0.97\n",
      "Epoch: 15\n",
      "[Train]\t J_a: 279.77, accuracy: 0.99\n",
      "[Test]\t J_a: 272.74, accuracy: 0.97\n",
      "Epoch: 16\n",
      "[Train]\t J_a: 278.49, accuracy: 0.99\n",
      "[Test]\t J_a: 271.78, accuracy: 0.97\n",
      "Epoch: 17\n",
      "[Train]\t J_a: 277.65, accuracy: 0.99\n",
      "[Test]\t J_a: 271.87, accuracy: 0.97\n",
      "Epoch: 18\n",
      "[Train]\t J_a: 277.16, accuracy: 0.99\n",
      "[Test]\t J_a: 271.30, accuracy: 0.97\n",
      "Epoch: 19\n",
      "[Train]\t J_a: 276.58, accuracy: 0.99\n",
      "[Test]\t J_a: 271.45, accuracy: 0.97\n",
      "Epoch: 20\n",
      "[Train]\t J_a: 275.59, accuracy: 0.99\n",
      "[Test]\t J_a: 271.14, accuracy: 0.97\n",
      "Epoch: 21\n",
      "[Train]\t J_a: 275.56, accuracy: 0.99\n",
      "[Test]\t J_a: 271.03, accuracy: 0.97\n",
      "Epoch: 22\n",
      "[Train]\t J_a: 274.18, accuracy: 0.99\n",
      "[Test]\t J_a: 270.65, accuracy: 0.97\n",
      "Epoch: 23\n",
      "[Train]\t J_a: 274.00, accuracy: 0.99\n",
      "[Test]\t J_a: 270.49, accuracy: 0.97\n",
      "Epoch: 24\n",
      "[Train]\t J_a: 273.86, accuracy: 0.99\n",
      "[Test]\t J_a: 270.15, accuracy: 0.97\n",
      "Epoch: 25\n",
      "[Train]\t J_a: 272.62, accuracy: 0.99\n",
      "[Test]\t J_a: 270.16, accuracy: 0.97\n",
      "Epoch: 26\n",
      "[Train]\t J_a: 272.96, accuracy: 0.99\n",
      "[Test]\t J_a: 269.67, accuracy: 0.97\n",
      "Epoch: 27\n",
      "[Train]\t J_a: 273.05, accuracy: 0.99\n",
      "[Test]\t J_a: 269.96, accuracy: 0.97\n",
      "Epoch: 28\n",
      "[Train]\t J_a: 271.93, accuracy: 0.99\n",
      "[Test]\t J_a: 269.38, accuracy: 0.97\n",
      "Epoch: 29\n",
      "[Train]\t J_a: 271.73, accuracy: 0.99\n",
      "[Test]\t J_a: 269.76, accuracy: 0.97\n",
      "Epoch: 30\n",
      "[Train]\t J_a: 271.72, accuracy: 0.99\n",
      "[Test]\t J_a: 269.90, accuracy: 0.97\n",
      "Epoch: 31\n",
      "[Train]\t J_a: 271.15, accuracy: 0.99\n",
      "[Test]\t J_a: 269.73, accuracy: 0.97\n",
      "Epoch: 32\n",
      "[Train]\t J_a: 270.78, accuracy: 0.99\n",
      "[Test]\t J_a: 269.84, accuracy: 0.97\n",
      "Epoch: 33\n",
      "[Train]\t J_a: 270.71, accuracy: 0.99\n",
      "[Test]\t J_a: 269.26, accuracy: 0.97\n",
      "Epoch: 34\n",
      "[Train]\t J_a: 270.14, accuracy: 0.99\n",
      "[Test]\t J_a: 269.16, accuracy: 0.97\n",
      "Epoch: 35\n",
      "[Train]\t J_a: 269.69, accuracy: 0.99\n",
      "[Test]\t J_a: 268.71, accuracy: 0.97\n",
      "Epoch: 36\n",
      "[Train]\t J_a: 269.45, accuracy: 0.99\n",
      "[Test]\t J_a: 268.39, accuracy: 0.97\n",
      "Epoch: 37\n",
      "[Train]\t J_a: 269.75, accuracy: 0.99\n",
      "[Test]\t J_a: 269.19, accuracy: 0.97\n",
      "Epoch: 38\n",
      "[Train]\t J_a: 269.17, accuracy: 0.99\n",
      "[Test]\t J_a: 268.66, accuracy: 0.97\n",
      "Epoch: 39\n",
      "[Train]\t J_a: 268.98, accuracy: 1.00\n",
      "[Test]\t J_a: 269.13, accuracy: 0.97\n",
      "Epoch: 40\n",
      "[Train]\t J_a: 269.05, accuracy: 0.99\n",
      "[Test]\t J_a: 269.03, accuracy: 0.97\n",
      "Epoch: 41\n",
      "[Train]\t J_a: 268.75, accuracy: 0.99\n",
      "[Test]\t J_a: 269.03, accuracy: 0.97\n",
      "Epoch: 42\n",
      "[Train]\t J_a: 268.42, accuracy: 0.99\n",
      "[Test]\t J_a: 268.57, accuracy: 0.97\n",
      "Epoch: 43\n",
      "[Train]\t J_a: 268.29, accuracy: 0.99\n",
      "[Test]\t J_a: 268.29, accuracy: 0.97\n",
      "Epoch: 44\n",
      "[Train]\t J_a: 267.63, accuracy: 0.99\n",
      "[Test]\t J_a: 268.42, accuracy: 0.97\n",
      "Epoch: 45\n",
      "[Train]\t J_a: 268.04, accuracy: 0.99\n",
      "[Test]\t J_a: 268.22, accuracy: 0.97\n",
      "Epoch: 46\n",
      "[Train]\t J_a: 267.07, accuracy: 0.99\n",
      "[Test]\t J_a: 268.74, accuracy: 0.97\n",
      "Epoch: 47\n",
      "[Train]\t J_a: 267.31, accuracy: 0.99\n",
      "[Test]\t J_a: 269.20, accuracy: 0.97\n",
      "Epoch: 48\n",
      "[Train]\t J_a: 267.16, accuracy: 0.99\n",
      "[Test]\t J_a: 267.98, accuracy: 0.97\n",
      "Epoch: 49\n",
      "[Train]\t J_a: 267.31, accuracy: 0.99\n",
      "[Test]\t J_a: 267.97, accuracy: 0.97\n",
      "Epoch: 50\n",
      "[Train]\t J_a: 266.98, accuracy: 1.00\n",
      "[Test]\t J_a: 268.56, accuracy: 0.97\n",
      "Epoch: 51\n",
      "[Train]\t J_a: 266.78, accuracy: 0.99\n",
      "[Test]\t J_a: 268.53, accuracy: 0.97\n",
      "Epoch: 52\n",
      "[Train]\t J_a: 267.00, accuracy: 0.99\n",
      "[Test]\t J_a: 267.84, accuracy: 0.97\n",
      "Epoch: 53\n",
      "[Train]\t J_a: 266.23, accuracy: 0.99\n",
      "[Test]\t J_a: 268.45, accuracy: 0.97\n",
      "Epoch: 54\n",
      "[Train]\t J_a: 266.40, accuracy: 0.99\n",
      "[Test]\t J_a: 268.02, accuracy: 0.97\n",
      "Epoch: 55\n",
      "[Train]\t J_a: 265.94, accuracy: 0.99\n",
      "[Test]\t J_a: 267.92, accuracy: 0.97\n",
      "Epoch: 56\n",
      "[Train]\t J_a: 266.02, accuracy: 0.99\n",
      "[Test]\t J_a: 267.97, accuracy: 0.97\n",
      "Epoch: 57\n",
      "[Train]\t J_a: 266.25, accuracy: 0.99\n",
      "[Test]\t J_a: 267.62, accuracy: 0.97\n",
      "Epoch: 58\n",
      "[Train]\t J_a: 265.93, accuracy: 0.99\n",
      "[Test]\t J_a: 267.86, accuracy: 0.97\n",
      "Epoch: 59\n",
      "[Train]\t J_a: 266.00, accuracy: 1.00\n",
      "[Test]\t J_a: 267.78, accuracy: 0.97\n",
      "Epoch: 60\n",
      "[Train]\t J_a: 265.93, accuracy: 0.99\n",
      "[Test]\t J_a: 267.71, accuracy: 0.97\n",
      "Epoch: 61\n",
      "[Train]\t J_a: 266.09, accuracy: 0.99\n",
      "[Test]\t J_a: 267.39, accuracy: 0.97\n",
      "Epoch: 62\n",
      "[Train]\t J_a: 265.21, accuracy: 0.99\n",
      "[Test]\t J_a: 267.45, accuracy: 0.97\n",
      "Epoch: 63\n",
      "[Train]\t J_a: 265.29, accuracy: 0.99\n",
      "[Test]\t J_a: 267.86, accuracy: 0.97\n",
      "Epoch: 64\n",
      "[Train]\t J_a: 265.38, accuracy: 0.98\n",
      "[Test]\t J_a: 267.77, accuracy: 0.97\n",
      "Epoch: 65\n",
      "[Train]\t J_a: 264.94, accuracy: 0.99\n",
      "[Test]\t J_a: 267.30, accuracy: 0.97\n",
      "Epoch: 66\n",
      "[Train]\t J_a: 265.20, accuracy: 0.99\n",
      "[Test]\t J_a: 267.58, accuracy: 0.97\n",
      "Epoch: 67\n",
      "[Train]\t J_a: 264.97, accuracy: 0.99\n",
      "[Test]\t J_a: 267.19, accuracy: 0.97\n",
      "Epoch: 68\n",
      "[Train]\t J_a: 264.69, accuracy: 0.99\n",
      "[Test]\t J_a: 267.80, accuracy: 0.97\n",
      "Epoch: 69\n",
      "[Train]\t J_a: 264.65, accuracy: 0.99\n",
      "[Test]\t J_a: 267.89, accuracy: 0.97\n",
      "Epoch: 70\n",
      "[Train]\t J_a: 265.26, accuracy: 0.99\n",
      "[Test]\t J_a: 267.91, accuracy: 0.97\n",
      "Epoch: 71\n",
      "[Train]\t J_a: 264.57, accuracy: 0.99\n",
      "[Test]\t J_a: 267.65, accuracy: 0.97\n",
      "Epoch: 72\n",
      "[Train]\t J_a: 264.82, accuracy: 0.99\n",
      "[Test]\t J_a: 267.49, accuracy: 0.97\n",
      "Epoch: 73\n",
      "[Train]\t J_a: 264.43, accuracy: 0.99\n",
      "[Test]\t J_a: 267.19, accuracy: 0.97\n",
      "Epoch: 74\n",
      "[Train]\t J_a: 264.89, accuracy: 0.99\n",
      "[Test]\t J_a: 267.50, accuracy: 0.97\n",
      "Epoch: 75\n",
      "[Train]\t J_a: 264.66, accuracy: 0.99\n",
      "[Test]\t J_a: 267.81, accuracy: 0.97\n",
      "Epoch: 76\n",
      "[Train]\t J_a: 264.62, accuracy: 0.99\n",
      "[Test]\t J_a: 267.75, accuracy: 0.97\n",
      "Epoch: 77\n",
      "[Train]\t J_a: 264.34, accuracy: 0.99\n",
      "[Test]\t J_a: 267.60, accuracy: 0.97\n",
      "Epoch: 78\n",
      "[Train]\t J_a: 264.47, accuracy: 0.99\n",
      "[Test]\t J_a: 267.56, accuracy: 0.97\n",
      "Epoch: 79\n",
      "[Train]\t J_a: 263.78, accuracy: 0.99\n",
      "[Test]\t J_a: 267.35, accuracy: 0.97\n",
      "Epoch: 80\n",
      "[Train]\t J_a: 263.52, accuracy: 0.99\n",
      "[Test]\t J_a: 267.35, accuracy: 0.97\n",
      "Epoch: 81\n",
      "[Train]\t J_a: 264.23, accuracy: 0.99\n",
      "[Test]\t J_a: 267.73, accuracy: 0.97\n",
      "Epoch: 82\n",
      "[Train]\t J_a: 264.22, accuracy: 0.99\n",
      "[Test]\t J_a: 267.73, accuracy: 0.97\n",
      "Epoch: 83\n",
      "[Train]\t J_a: 263.95, accuracy: 0.99\n",
      "[Test]\t J_a: 267.65, accuracy: 0.97\n",
      "Epoch: 84\n",
      "[Train]\t J_a: 263.76, accuracy: 0.99\n",
      "[Test]\t J_a: 267.46, accuracy: 0.97\n",
      "Epoch: 85\n",
      "[Train]\t J_a: 263.70, accuracy: 0.98\n",
      "[Test]\t J_a: 267.52, accuracy: 0.97\n",
      "Epoch: 86\n",
      "[Train]\t J_a: 263.31, accuracy: 0.99\n",
      "[Test]\t J_a: 267.15, accuracy: 0.97\n",
      "Epoch: 87\n",
      "[Train]\t J_a: 263.01, accuracy: 0.99\n",
      "[Test]\t J_a: 267.89, accuracy: 0.97\n",
      "Epoch: 88\n",
      "[Train]\t J_a: 263.15, accuracy: 0.99\n",
      "[Test]\t J_a: 267.86, accuracy: 0.97\n",
      "Epoch: 89\n",
      "[Train]\t J_a: 263.21, accuracy: 1.00\n",
      "[Test]\t J_a: 267.63, accuracy: 0.97\n",
      "Epoch: 90\n",
      "[Train]\t J_a: 263.33, accuracy: 0.99\n",
      "[Test]\t J_a: 267.54, accuracy: 0.97\n",
      "Epoch: 91\n",
      "[Train]\t J_a: 263.37, accuracy: 0.99\n",
      "[Test]\t J_a: 267.52, accuracy: 0.97\n",
      "Epoch: 92\n",
      "[Train]\t J_a: 263.37, accuracy: 0.99\n",
      "[Test]\t J_a: 267.08, accuracy: 0.97\n",
      "Epoch: 93\n",
      "[Train]\t J_a: 263.42, accuracy: 0.99\n",
      "[Test]\t J_a: 267.31, accuracy: 0.97\n",
      "Epoch: 94\n",
      "[Train]\t J_a: 263.08, accuracy: 0.99\n",
      "[Test]\t J_a: 267.24, accuracy: 0.97\n",
      "Epoch: 95\n",
      "[Train]\t J_a: 263.05, accuracy: 0.99\n",
      "[Test]\t J_a: 267.32, accuracy: 0.97\n",
      "Epoch: 96\n",
      "[Train]\t J_a: 263.12, accuracy: 0.99\n",
      "[Test]\t J_a: 267.21, accuracy: 0.97\n",
      "Epoch: 97\n",
      "[Train]\t J_a: 262.76, accuracy: 0.99\n",
      "[Test]\t J_a: 267.66, accuracy: 0.97\n",
      "Epoch: 98\n",
      "[Train]\t J_a: 262.94, accuracy: 0.99\n",
      "[Test]\t J_a: 267.09, accuracy: 0.97\n",
      "Epoch: 99\n",
      "[Train]\t J_a: 263.20, accuracy: 1.00\n",
      "[Test]\t J_a: 267.35, accuracy: 0.97\n"
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "for algorithm in SSL_metrics.keys():\n",
    "    # Only use INITIAL_LABEL_PER_CLASS labelled examples per class\n",
    "    # The rest of the data is unlabelled.\n",
    "    labelled, unlabelled, test = get_dataset(location=\"{BASE_DIR}/saved_data\", dataset = \"MNIST\", seed = 111, batch_size=64, labels_per_class=INITIAL_LABEL_PER_CLASS, algorithm=algorithm)\n",
    "\n",
    "    # Prepare the model and the optimizer\n",
    "    model = DeepGenerativeModel([x_dim, y_dim, z_dim, h_dim])\n",
    "\n",
    "    del model.classifier\n",
    "    model.classifier = query_strategies[algorithm]['classifier']\n",
    "    if cuda: model = model.cuda()\n",
    "    alpha = 0.1 * len(unlabelled) / len(labelled)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=3e-4, betas=(0.9, 0.999))\n",
    "\n",
    "    # Prepare a sampler and the elbo object\n",
    "    # You can use importance weighted samples [Burda, 2015] to get a better estimate\n",
    "    # on the log-likelihood.\n",
    "    sampler = ImportanceWeightedSampler(mc=1, iw=1)\n",
    "    elbo = SVI(model, likelihood=binary_cross_entropy, sampler=sampler)\n",
    "\n",
    "\n",
    "    SSL_train_loss_history = []\n",
    "    SSL_train_accuracy_history = []\n",
    "    SSL_test_loss_history = []\n",
    "    SSL_test_accuracy_history = []\n",
    "\n",
    "    for epoch in range(SSL_EPOCHS):\n",
    "        model.train()\n",
    "        total_loss, accuracy = (0, 0)\n",
    "        for (x, y), (u, _) in zip(cycle(labelled), unlabelled):\n",
    "            # Wrap in variables\n",
    "            x, y, u = Variable(x).cuda(device=0), Variable(y).cuda(device=0), Variable(u).cuda(device=0)\n",
    "\n",
    "            J_alpha, logits = calculate_J_alpha(x.reshape(-1, 784), y, u, alpha, model)\n",
    "\n",
    "            J_alpha.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            total_loss += J_alpha.data\n",
    "            accuracy += torch.mean((torch.max(logits, 1)[1].data == torch.max(y, 1)[1].data).float())\n",
    "            \n",
    "        if epoch % 1 == 0:\n",
    "            model.eval()\n",
    "            m = len(unlabelled)\n",
    "\n",
    "            train_loss = total_loss/m\n",
    "            train_accuracy = accuracy/m\n",
    "\n",
    "            SSL_train_loss_history.append(train_loss)\n",
    "            SSL_train_accuracy_history.append(train_accuracy)\n",
    "            print(\"Epoch: {}\".format(epoch))\n",
    "            print(\"[Train]\\t J_a: {:.2f}, accuracy: {:.2f}\".format(train_loss, train_accuracy))\n",
    "\n",
    "            total_loss, accuracy = (0, 0)\n",
    "            for x, y in test:\n",
    "                x, y = Variable(x).cuda(device=0), Variable(y).cuda(device=0)\n",
    "\n",
    "                J_alpha, logits = calculate_J_alpha(x.reshape(-1, 784), y, x.reshape(-1, 784), alpha, model)\n",
    "\n",
    "                total_loss += J_alpha.data\n",
    "\n",
    "                _, pred_idx = torch.max(logits, 1)\n",
    "                _, lab_idx = torch.max(y, 1)\n",
    "                accuracy += torch.mean((torch.max(logits, 1)[1].data == torch.max(y, 1)[1].data).float())\n",
    "\n",
    "            m = len(test)\n",
    "\n",
    "            test_loss = total_loss/m\n",
    "            test_accuracy = accuracy/m\n",
    "\n",
    "            SSL_test_loss_history.append(test_loss)\n",
    "            SSL_test_accuracy_history.append(test_accuracy)\n",
    "\n",
    "            print(\"[Test]\\t J_a: {:.2f}, accuracy: {:.2f}\".format(test_loss, test_accuracy))\n",
    "\n",
    "    SSL_metrics[algorithm]['train_loss_history'] = [x.item() for x in SSL_train_loss_history]\n",
    "    SSL_metrics[algorithm]['train_accuracy_history'] = [x.item() for x in SSL_train_accuracy_history]\n",
    "    SSL_metrics[algorithm]['test_loss_history'] = [x.item() for x in SSL_test_loss_history]\n",
    "    SSL_metrics[algorithm]['test_accuracy_history'] = [x.item() for x in SSL_test_accuracy_history]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "26f6f19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save performance histories\n",
    "# Test\n",
    "SSL_test_loss_histories = {f'{algorithm}_test_loss': val['test_loss_history'] for algorithm, val in SSL_metrics.items()}\n",
    "SSL_test_accuracy_histories = {f'{algorithm}_test_accuracy': val['test_accuracy_history'] for algorithm, val in SSL_metrics.items()}\n",
    "# Train\n",
    "SSL_train_loss_histories = {f'{algorithm}_train_loss': val['train_loss_history'] for algorithm, val in SSL_metrics.items()}\n",
    "SSL_train_accuracy_histories = {f'{algorithm}_train_accuracy': val['train_accuracy_history'] for algorithm, val in SSL_metrics.items()}\n",
    "\n",
    "# Save process\n",
    "pd.DataFrame(SSL_test_loss_histories).to_csv(f'{BASE_DIR}/saved_data/SSL_test_loss_histories_{N_LABELS*INITIAL_LABEL_PER_CLASS}.csv')\n",
    "pd.DataFrame(SSL_test_accuracy_histories).to_csv(f'{BASE_DIR}/saved_data/SSL_test_accuracy_histories_{N_LABELS*INITIAL_LABEL_PER_CLASS}.csv')\n",
    "pd.DataFrame(SSL_train_loss_histories).to_csv(f'{BASE_DIR}/saved_data/SSL_train_loss_histories_{N_LABELS*INITIAL_LABEL_PER_CLASS}.csv')\n",
    "pd.DataFrame(SSL_train_accuracy_histories).to_csv(f'{BASE_DIR}/saved_data/SSL_train_accuracy_histories_{N_LABELS*INITIAL_LABEL_PER_CLASS}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "599193ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the SSL Performance\n",
    "# Plot\n",
    "sns.set()\n",
    "\n",
    "\n",
    "# fig, (ax0, ax1) = plt.subplots(nrows=1, ncols=2, sharex=True,\n",
    "#                                     figsize=(16, 8))\n",
    "fig, (ax0) = plt.subplots(nrows=1, ncols=1, sharex=True,\n",
    "                                    figsize=(8, 6))\n",
    "\n",
    "\n",
    "# Set y axis format\n",
    "ax0.yaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
    "# Major ticks every 20, minor ticks every 5\n",
    "major_ticks = np.arange(0, SSL_EPOCHS+1,10)\n",
    "ax0.set_xticks(major_ticks)\n",
    "\n",
    "x_ticks = np.arange(0, SSL_EPOCHS,1)\n",
    "ax0.plot(x_ticks, SSL_test_accuracy_histories['random_test_accuracy'], label = 'random')\n",
    "ax0.plot(x_ticks, SSL_test_accuracy_histories['bald_test_accuracy'], label = 'bald')\n",
    "ax0.set_ylim([0.9,1])\n",
    "ax0.set_ylabel(\"Accuracy\")\n",
    "ax0.set_xlabel(\"Number of epoch\")\n",
    "ax0.legend()\n",
    "\n",
    "# # Set y axis format\n",
    "# ax1.yaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
    "# # Major ticks every 20, minor ticks every 5\n",
    "# major_ticks = np.arange(0, SSL_EPOCHS+1,10)\n",
    "# ax1.set_xticks(major_ticks)\n",
    "\n",
    "# x_ticks = np.arange(0, SSL_EPOCHS,1)\n",
    "# ax1.plot(x_ticks, SSL_test_loss_histories['random_test_loss'], label = 'random')\n",
    "# ax1.plot(x_ticks, SSL_test_loss_histories['bald_test_loss'], label = 'bald')\n",
    "# # ax1.set_ylim([0.8,1])\n",
    "# ax1.set_ylabel(\"Test Loss\")\n",
    "# ax1.set_xlabel(\"Number of epoch\")\n",
    "# ax1.legend()\n",
    "\n",
    "fig.suptitle(\"Performance of SSL\\n with the same AL Classifier\")\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c1de41",
   "metadata": {},
   "source": [
    "## Progressive Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21fecde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import DeepGenerativeModel\n",
    "from datautils import get_dataset\n",
    "from itertools import cycle\n",
    "from inference import SVI, ImportanceWeightedSampler\n",
    "from torch.autograd import Variable\n",
    "\n",
    "SSL_EPOCHS = 50\n",
    "\n",
    "def binary_cross_entropy(y_pred, y):\n",
    "    return -torch.sum(y * torch.log(y_pred + 1e-8) + (1 - y) * torch.log(1 - y_pred + 1e-8), dim=-1)\n",
    "\n",
    "\n",
    "x_dim = 784\n",
    "y_dim = 10\n",
    "z_dim = 32\n",
    "h_dim = [256, 128]\n",
    "\n",
    "SSL_metrics = {'random':{'train_loss_history':None,\n",
    "                                'train_accuracy_history': None,\n",
    "                                'test_loss_history': None,\n",
    "                                'test_accuracy_history': None},\n",
    "                    'bald':{'train_loss_history':None,\n",
    "                                'train_accuracy_history': None,\n",
    "                                'test_loss_history': None,\n",
    "                                'test_accuracy_history': None},\n",
    "                    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "707de6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_J_alpha(x, y, u, alpha, model):\n",
    "    # Calculate ELBOs\n",
    "    L = -elbo(x, y)\n",
    "    U = -elbo(u)\n",
    "\n",
    "    # Add auxiliary classification loss q(y|x)\n",
    "    logits = model.classify(x)\n",
    "    \n",
    "    # Regular cross entropy\n",
    "    classification_loss = -torch.sum(y * torch.log(logits + 1e-8), dim=1).mean()\n",
    "\n",
    "    J_alpha = L + alpha * classification_loss + U\n",
    "\n",
    "    return J_alpha, logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4d10300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./saved_data/MNIST_X_train_labelled_random_100_111.pt\n",
      "./saved_data/MNIST_y_train_labelled_random_100_111.pt\n",
      "100 100\n",
      "./saved_data/MNIST_X_train_unlabelled_random_100_111.pt\n",
      "./saved_data/MNIST_y_train_unlabelled_random_100_111.pt\n",
      "59900 59900\n",
      "./saved_data/MNIST_X_test_111.pt\n",
      "./saved_data/MNIST_y_test_111.pt\n",
      "10000 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/ucl/dissertation/./semi-supervised/models/vae.py:114: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
      "  init.xavier_normal(m.weight.data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 100\n",
      "Epoch: 0\n",
      "[Train]\t J_a: 367.24, accuracy: 0.97\n",
      "[Test]\t J_a: 367.60, accuracy: 0.7986\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 100\n",
      "Epoch: 1\n",
      "[Train]\t J_a: 271.52, accuracy: 1.00\n",
      "[Test]\t J_a: 350.32, accuracy: 0.8292\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 100\n",
      "Epoch: 2\n",
      "[Train]\t J_a: 248.49, accuracy: 1.00\n",
      "[Test]\t J_a: 340.52, accuracy: 0.8557\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 100\n",
      "Epoch: 3\n",
      "[Train]\t J_a: 235.58, accuracy: 1.00\n",
      "[Test]\t J_a: 336.82, accuracy: 0.8704\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 100\n",
      "Epoch: 4\n",
      "[Train]\t J_a: 227.29, accuracy: 1.00\n",
      "[Test]\t J_a: 331.63, accuracy: 0.8737\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 100\n",
      "Epoch: 5\n",
      "[Train]\t J_a: 220.83, accuracy: 1.00\n",
      "[Test]\t J_a: 335.12, accuracy: 0.8767\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 100\n",
      "Epoch: 6\n",
      "[Train]\t J_a: 214.93, accuracy: 1.00\n",
      "[Test]\t J_a: 324.50, accuracy: 0.8964\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 100\n",
      "Epoch: 7\n",
      "[Train]\t J_a: 211.08, accuracy: 1.00\n",
      "[Test]\t J_a: 320.96, accuracy: 0.9021\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 100\n",
      "Epoch: 8\n",
      "[Train]\t J_a: 208.05, accuracy: 1.00\n",
      "[Test]\t J_a: 320.77, accuracy: 0.9033\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 100\n",
      "Epoch: 9\n",
      "[Train]\t J_a: 204.56, accuracy: 1.00\n",
      "[Test]\t J_a: 319.92, accuracy: 0.9048\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 100\n",
      "Epoch: 10\n",
      "[Train]\t J_a: 202.80, accuracy: 1.00\n",
      "[Test]\t J_a: 322.02, accuracy: 0.9034\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 100\n",
      "Epoch: 11\n",
      "[Train]\t J_a: 200.25, accuracy: 1.00\n",
      "[Test]\t J_a: 319.16, accuracy: 0.9094\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 100\n",
      "Epoch: 12\n",
      "[Train]\t J_a: 198.49, accuracy: 1.00\n",
      "[Test]\t J_a: 320.38, accuracy: 0.9057\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 100\n",
      "Epoch: 13\n",
      "[Train]\t J_a: 197.49, accuracy: 1.00\n",
      "[Test]\t J_a: 315.08, accuracy: 0.9154\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 100\n",
      "Epoch: 14\n",
      "[Train]\t J_a: 195.99, accuracy: 1.00\n",
      "[Test]\t J_a: 310.92, accuracy: 0.9203\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 100\n",
      "Epoch: 15\n",
      "[Train]\t J_a: 193.16, accuracy: 1.00\n",
      "[Test]\t J_a: 310.76, accuracy: 0.9243\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 100\n",
      "Epoch: 16\n",
      "[Train]\t J_a: 192.20, accuracy: 1.00\n",
      "[Test]\t J_a: 311.35, accuracy: 0.9217\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 100\n",
      "Epoch: 17\n",
      "[Train]\t J_a: 190.79, accuracy: 1.00\n",
      "[Test]\t J_a: 307.47, accuracy: 0.9292\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 100\n",
      "Epoch: 18\n",
      "[Train]\t J_a: 189.46, accuracy: 1.00\n",
      "[Test]\t J_a: 305.50, accuracy: 0.9335\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 100\n",
      "Epoch: 19\n",
      "[Train]\t J_a: 188.30, accuracy: 1.00\n",
      "[Test]\t J_a: 307.68, accuracy: 0.9300\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 100\n",
      "Epoch: 20\n",
      "[Train]\t J_a: 187.60, accuracy: 1.00\n",
      "[Test]\t J_a: 302.04, accuracy: 0.9337\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 100\n",
      "Epoch: 21\n",
      "[Train]\t J_a: 186.78, accuracy: 1.00\n",
      "[Test]\t J_a: 304.67, accuracy: 0.9337\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 100\n",
      "Epoch: 22\n",
      "[Train]\t J_a: 185.75, accuracy: 1.00\n",
      "[Test]\t J_a: 302.90, accuracy: 0.9329\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 100\n",
      "Epoch: 23\n",
      "[Train]\t J_a: 184.51, accuracy: 1.00\n",
      "[Test]\t J_a: 307.14, accuracy: 0.9274\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 100\n",
      "Epoch: 24\n",
      "[Train]\t J_a: 183.95, accuracy: 1.00\n",
      "[Test]\t J_a: 303.25, accuracy: 0.9294\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 100\n",
      "Epoch: 25\n",
      "[Train]\t J_a: 182.46, accuracy: 1.00\n",
      "[Test]\t J_a: 301.22, accuracy: 0.9340\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 100\n",
      "Epoch: 26\n",
      "[Train]\t J_a: 182.73, accuracy: 1.00\n",
      "[Test]\t J_a: 295.40, accuracy: 0.9418\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 100\n",
      "Epoch: 27\n",
      "[Train]\t J_a: 182.32, accuracy: 1.00\n",
      "[Test]\t J_a: 298.33, accuracy: 0.9359\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 100\n",
      "Epoch: 28\n",
      "[Train]\t J_a: 180.71, accuracy: 1.00\n",
      "[Test]\t J_a: 297.95, accuracy: 0.9373\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 100\n",
      "Epoch: 29\n",
      "[Train]\t J_a: 180.22, accuracy: 1.00\n",
      "[Test]\t J_a: 295.68, accuracy: 0.9419\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 100\n",
      "Epoch: 30\n",
      "[Train]\t J_a: 181.06, accuracy: 1.00\n",
      "[Test]\t J_a: 296.47, accuracy: 0.9395\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 100\n",
      "Epoch: 31\n",
      "[Train]\t J_a: 180.00, accuracy: 1.00\n",
      "[Test]\t J_a: 296.09, accuracy: 0.9400\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 100\n",
      "Epoch: 32\n",
      "[Train]\t J_a: 179.31, accuracy: 1.00\n",
      "[Test]\t J_a: 294.96, accuracy: 0.9428\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 100\n",
      "Epoch: 33\n",
      "[Train]\t J_a: 178.82, accuracy: 1.00\n",
      "[Test]\t J_a: 294.70, accuracy: 0.9422\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 100\n",
      "Epoch: 34\n",
      "[Train]\t J_a: 178.55, accuracy: 1.00\n",
      "[Test]\t J_a: 294.64, accuracy: 0.9423\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 100\n",
      "Epoch: 35\n",
      "[Train]\t J_a: 177.60, accuracy: 1.00\n",
      "[Test]\t J_a: 293.27, accuracy: 0.9429\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 100\n",
      "Epoch: 36\n",
      "[Train]\t J_a: 178.00, accuracy: 1.00\n",
      "[Test]\t J_a: 291.72, accuracy: 0.9442\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 100\n",
      "Epoch: 37\n",
      "[Train]\t J_a: 177.51, accuracy: 1.00\n",
      "[Test]\t J_a: 292.11, accuracy: 0.9426\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 100\n",
      "Epoch: 38\n",
      "[Train]\t J_a: 177.29, accuracy: 1.00\n",
      "[Test]\t J_a: 292.15, accuracy: 0.9440\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 100\n",
      "Epoch: 39\n",
      "[Train]\t J_a: 177.31, accuracy: 1.00\n",
      "[Test]\t J_a: 294.27, accuracy: 0.9411\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 100\n",
      "Epoch: 40\n",
      "[Train]\t J_a: 175.30, accuracy: 1.00\n",
      "[Test]\t J_a: 293.26, accuracy: 0.9399\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 100\n",
      "Epoch: 41\n",
      "[Train]\t J_a: 175.92, accuracy: 1.00\n",
      "[Test]\t J_a: 290.94, accuracy: 0.9447\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 100\n",
      "Epoch: 42\n",
      "[Train]\t J_a: 175.73, accuracy: 1.00\n",
      "[Test]\t J_a: 290.61, accuracy: 0.9474\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 100\n",
      "Epoch: 43\n",
      "[Train]\t J_a: 175.77, accuracy: 1.00\n",
      "[Test]\t J_a: 292.65, accuracy: 0.9417\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 100\n",
      "Epoch: 44\n",
      "[Train]\t J_a: 175.53, accuracy: 1.00\n",
      "[Test]\t J_a: 290.32, accuracy: 0.9470\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 100\n",
      "Epoch: 45\n",
      "[Train]\t J_a: 175.64, accuracy: 1.00\n",
      "[Test]\t J_a: 292.51, accuracy: 0.9431\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 100\n",
      "Epoch: 46\n",
      "[Train]\t J_a: 175.32, accuracy: 1.00\n",
      "[Test]\t J_a: 293.03, accuracy: 0.9409\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 100\n",
      "Epoch: 47\n",
      "[Train]\t J_a: 175.21, accuracy: 1.00\n",
      "[Test]\t J_a: 291.44, accuracy: 0.9447\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 100\n",
      "Epoch: 48\n",
      "[Train]\t J_a: 175.14, accuracy: 1.00\n",
      "[Test]\t J_a: 290.80, accuracy: 0.9456\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 100\n",
      "Epoch: 49\n",
      "[Train]\t J_a: 173.93, accuracy: 1.00\n",
      "[Test]\t J_a: 295.24, accuracy: 0.9385\n",
      "./saved_data/MNIST_X_train_labelled_bald_100_111.pt\n",
      "./saved_data/MNIST_y_train_labelled_bald_100_111.pt\n",
      "100 100\n",
      "./saved_data/MNIST_X_train_unlabelled_bald_100_111.pt\n",
      "./saved_data/MNIST_y_train_unlabelled_bald_100_111.pt\n",
      "59900 59900\n",
      "./saved_data/MNIST_X_test_111.pt\n",
      "./saved_data/MNIST_y_test_111.pt\n",
      "10000 10000\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 100\n",
      "Epoch: 0\n",
      "[Train]\t J_a: 369.74, accuracy: 0.97\n",
      "[Test]\t J_a: 358.77, accuracy: 0.8120\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 100\n",
      "Epoch: 1\n",
      "[Train]\t J_a: 270.20, accuracy: 1.00\n",
      "[Test]\t J_a: 343.93, accuracy: 0.8454\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 100\n",
      "Epoch: 2\n",
      "[Train]\t J_a: 248.05, accuracy: 1.00\n",
      "[Test]\t J_a: 331.97, accuracy: 0.8707\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 100\n",
      "Epoch: 3\n",
      "[Train]\t J_a: 235.02, accuracy: 1.00\n",
      "[Test]\t J_a: 331.38, accuracy: 0.8766\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 100\n",
      "Epoch: 4\n",
      "[Train]\t J_a: 225.82, accuracy: 1.00\n",
      "[Test]\t J_a: 325.29, accuracy: 0.8949\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 100\n",
      "Epoch: 5\n",
      "[Train]\t J_a: 219.80, accuracy: 1.00\n",
      "[Test]\t J_a: 324.62, accuracy: 0.9001\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 100\n",
      "Epoch: 6\n",
      "[Train]\t J_a: 214.54, accuracy: 1.00\n",
      "[Test]\t J_a: 322.08, accuracy: 0.9048\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 100\n",
      "Epoch: 7\n",
      "[Train]\t J_a: 210.37, accuracy: 1.00\n",
      "[Test]\t J_a: 319.21, accuracy: 0.9080\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 100\n",
      "Epoch: 8\n",
      "[Train]\t J_a: 207.12, accuracy: 1.00\n",
      "[Test]\t J_a: 317.82, accuracy: 0.9078\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 100\n",
      "Epoch: 9\n",
      "[Train]\t J_a: 204.64, accuracy: 1.00\n",
      "[Test]\t J_a: 312.62, accuracy: 0.9164\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 100\n",
      "Epoch: 10\n",
      "[Train]\t J_a: 201.93, accuracy: 1.00\n",
      "[Test]\t J_a: 311.13, accuracy: 0.9206\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 100\n",
      "Epoch: 11\n",
      "[Train]\t J_a: 200.64, accuracy: 1.00\n",
      "[Test]\t J_a: 309.84, accuracy: 0.9276\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 100\n",
      "Epoch: 12\n",
      "[Train]\t J_a: 198.72, accuracy: 1.00\n",
      "[Test]\t J_a: 308.45, accuracy: 0.9266\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 100\n",
      "Epoch: 13\n",
      "[Train]\t J_a: 196.17, accuracy: 1.00\n",
      "[Test]\t J_a: 308.15, accuracy: 0.9272\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 100\n",
      "Epoch: 14\n",
      "[Train]\t J_a: 194.98, accuracy: 1.00\n",
      "[Test]\t J_a: 307.40, accuracy: 0.9284\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 100\n",
      "Epoch: 15\n",
      "[Train]\t J_a: 193.88, accuracy: 1.00\n",
      "[Test]\t J_a: 308.62, accuracy: 0.9272\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 100\n",
      "Epoch: 16\n",
      "[Train]\t J_a: 191.56, accuracy: 1.00\n",
      "[Test]\t J_a: 305.22, accuracy: 0.9353\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 100\n",
      "Epoch: 17\n",
      "[Train]\t J_a: 190.95, accuracy: 1.00\n",
      "[Test]\t J_a: 304.63, accuracy: 0.9335\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 100\n",
      "Epoch: 18\n",
      "[Train]\t J_a: 189.37, accuracy: 1.00\n",
      "[Test]\t J_a: 307.83, accuracy: 0.9285\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 100\n",
      "Epoch: 19\n",
      "[Train]\t J_a: 188.31, accuracy: 1.00\n",
      "[Test]\t J_a: 304.66, accuracy: 0.9334\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 100\n",
      "Epoch: 20\n",
      "[Train]\t J_a: 187.35, accuracy: 1.00\n",
      "[Test]\t J_a: 299.60, accuracy: 0.9403\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 100\n",
      "Epoch: 21\n",
      "[Train]\t J_a: 186.51, accuracy: 1.00\n",
      "[Test]\t J_a: 297.83, accuracy: 0.9400\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 100\n",
      "Epoch: 22\n",
      "[Train]\t J_a: 186.31, accuracy: 1.00\n",
      "[Test]\t J_a: 300.80, accuracy: 0.9396\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 100\n",
      "Epoch: 23\n",
      "[Train]\t J_a: 185.10, accuracy: 1.00\n",
      "[Test]\t J_a: 301.99, accuracy: 0.9383\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 100\n",
      "Epoch: 24\n",
      "[Train]\t J_a: 183.18, accuracy: 1.00\n",
      "[Test]\t J_a: 294.73, accuracy: 0.9446\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 100\n",
      "Epoch: 25\n",
      "[Train]\t J_a: 182.85, accuracy: 1.00\n",
      "[Test]\t J_a: 298.89, accuracy: 0.9405\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 100\n",
      "Epoch: 26\n",
      "[Train]\t J_a: 182.60, accuracy: 1.00\n",
      "[Test]\t J_a: 300.73, accuracy: 0.9361\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 100\n",
      "Epoch: 27\n",
      "[Train]\t J_a: 181.41, accuracy: 1.00\n",
      "[Test]\t J_a: 296.60, accuracy: 0.9419\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 100\n",
      "Epoch: 28\n",
      "[Train]\t J_a: 181.47, accuracy: 1.00\n",
      "[Test]\t J_a: 295.32, accuracy: 0.9460\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 100\n",
      "Epoch: 29\n",
      "[Train]\t J_a: 180.82, accuracy: 1.00\n",
      "[Test]\t J_a: 297.53, accuracy: 0.9396\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 100\n",
      "Epoch: 30\n",
      "[Train]\t J_a: 180.92, accuracy: 1.00\n",
      "[Test]\t J_a: 295.44, accuracy: 0.9423\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 100\n",
      "Epoch: 31\n",
      "[Train]\t J_a: 179.82, accuracy: 1.00\n",
      "[Test]\t J_a: 298.17, accuracy: 0.9394\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 100\n",
      "Epoch: 32\n",
      "[Train]\t J_a: 179.53, accuracy: 1.00\n",
      "[Test]\t J_a: 297.06, accuracy: 0.9412\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 100\n",
      "Epoch: 33\n",
      "[Train]\t J_a: 178.97, accuracy: 1.00\n",
      "[Test]\t J_a: 297.11, accuracy: 0.9395\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 100\n",
      "Epoch: 34\n",
      "[Train]\t J_a: 178.31, accuracy: 1.00\n",
      "[Test]\t J_a: 294.16, accuracy: 0.9419\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 100\n",
      "Epoch: 35\n",
      "[Train]\t J_a: 178.79, accuracy: 1.00\n",
      "[Test]\t J_a: 294.27, accuracy: 0.9423\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 100\n",
      "Epoch: 36\n",
      "[Train]\t J_a: 178.30, accuracy: 1.00\n",
      "[Test]\t J_a: 294.79, accuracy: 0.9430\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 100\n",
      "Epoch: 37\n",
      "[Train]\t J_a: 176.93, accuracy: 1.00\n",
      "[Test]\t J_a: 292.36, accuracy: 0.9467\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 100\n",
      "Epoch: 38\n",
      "[Train]\t J_a: 177.47, accuracy: 1.00\n",
      "[Test]\t J_a: 293.37, accuracy: 0.9437\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 100\n",
      "Epoch: 39\n",
      "[Train]\t J_a: 177.44, accuracy: 1.00\n",
      "[Test]\t J_a: 294.32, accuracy: 0.9411\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 100\n",
      "Epoch: 40\n",
      "[Train]\t J_a: 176.17, accuracy: 1.00\n",
      "[Test]\t J_a: 294.59, accuracy: 0.9376\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 100\n",
      "Epoch: 41\n",
      "[Train]\t J_a: 175.81, accuracy: 1.00\n",
      "[Test]\t J_a: 291.22, accuracy: 0.9465\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 100\n",
      "Epoch: 42\n",
      "[Train]\t J_a: 176.28, accuracy: 1.00\n",
      "[Test]\t J_a: 294.88, accuracy: 0.9436\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 100\n",
      "Epoch: 43\n",
      "[Train]\t J_a: 175.60, accuracy: 1.00\n",
      "[Test]\t J_a: 295.74, accuracy: 0.9409\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 100\n",
      "Epoch: 44\n",
      "[Train]\t J_a: 175.79, accuracy: 1.00\n",
      "[Test]\t J_a: 294.64, accuracy: 0.9422\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 100\n",
      "Epoch: 45\n",
      "[Train]\t J_a: 175.67, accuracy: 1.00\n",
      "[Test]\t J_a: 291.39, accuracy: 0.9472\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 100\n",
      "Epoch: 46\n",
      "[Train]\t J_a: 175.77, accuracy: 1.00\n",
      "[Test]\t J_a: 291.44, accuracy: 0.9451\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 100\n",
      "Epoch: 47\n",
      "[Train]\t J_a: 175.11, accuracy: 1.00\n",
      "[Test]\t J_a: 293.55, accuracy: 0.9420\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 100\n",
      "Epoch: 48\n",
      "[Train]\t J_a: 174.76, accuracy: 1.00\n",
      "[Test]\t J_a: 291.31, accuracy: 0.9456\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 100\n",
      "Epoch: 49\n",
      "[Train]\t J_a: 174.73, accuracy: 1.00\n",
      "[Test]\t J_a: 291.42, accuracy: 0.9459\n",
      "./saved_data/MNIST_X_train_labelled_random_100_111.pt\n",
      "./saved_data/MNIST_y_train_labelled_random_100_111.pt\n",
      "200 200\n",
      "./saved_data/MNIST_X_train_unlabelled_random_100_111.pt\n",
      "./saved_data/MNIST_y_train_unlabelled_random_100_111.pt\n",
      "59800 59800\n",
      "./saved_data/MNIST_X_test_111.pt\n",
      "./saved_data/MNIST_y_test_111.pt\n",
      "10000 10000\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 200\n",
      "Epoch: 0\n",
      "[Train]\t J_a: 370.33, accuracy: 0.95\n",
      "[Test]\t J_a: 334.67, accuracy: 0.8562\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 200\n",
      "Epoch: 1\n",
      "[Train]\t J_a: 280.66, accuracy: 1.00\n",
      "[Test]\t J_a: 310.94, accuracy: 0.8878\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 200\n",
      "Epoch: 2\n",
      "[Train]\t J_a: 263.96, accuracy: 1.00\n",
      "[Test]\t J_a: 303.08, accuracy: 0.8960\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 200\n",
      "Epoch: 3\n",
      "[Train]\t J_a: 250.11, accuracy: 1.00\n",
      "[Test]\t J_a: 301.41, accuracy: 0.8991\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 200\n",
      "Epoch: 4\n",
      "[Train]\t J_a: 243.19, accuracy: 1.00\n",
      "[Test]\t J_a: 293.95, accuracy: 0.9113\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 200\n",
      "Epoch: 5\n",
      "[Train]\t J_a: 235.80, accuracy: 1.00\n",
      "[Test]\t J_a: 290.76, accuracy: 0.9184\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 200\n",
      "Epoch: 6\n",
      "[Train]\t J_a: 231.02, accuracy: 1.00\n",
      "[Test]\t J_a: 291.93, accuracy: 0.9143\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 200\n",
      "Epoch: 7\n",
      "[Train]\t J_a: 227.16, accuracy: 1.00\n",
      "[Test]\t J_a: 291.56, accuracy: 0.9152\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 200\n",
      "Epoch: 8\n",
      "[Train]\t J_a: 223.67, accuracy: 1.00\n",
      "[Test]\t J_a: 286.50, accuracy: 0.9271\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 200\n",
      "Epoch: 9\n",
      "[Train]\t J_a: 221.59, accuracy: 1.00\n",
      "[Test]\t J_a: 286.73, accuracy: 0.9252\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 200\n",
      "Epoch: 10\n",
      "[Train]\t J_a: 219.07, accuracy: 1.00\n",
      "[Test]\t J_a: 285.64, accuracy: 0.9248\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 200\n",
      "Epoch: 11\n",
      "[Train]\t J_a: 218.58, accuracy: 1.00\n",
      "[Test]\t J_a: 284.23, accuracy: 0.9318\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 200\n",
      "Epoch: 12\n",
      "[Train]\t J_a: 214.49, accuracy: 1.00\n",
      "[Test]\t J_a: 284.05, accuracy: 0.9313\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 200\n",
      "Epoch: 13\n",
      "[Train]\t J_a: 214.20, accuracy: 1.00\n",
      "[Test]\t J_a: 285.09, accuracy: 0.9319\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 200\n",
      "Epoch: 14\n",
      "[Train]\t J_a: 212.55, accuracy: 1.00\n",
      "[Test]\t J_a: 282.81, accuracy: 0.9345\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 200\n",
      "Epoch: 15\n",
      "[Train]\t J_a: 211.18, accuracy: 1.00\n",
      "[Test]\t J_a: 283.20, accuracy: 0.9337\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 200\n",
      "Epoch: 16\n",
      "[Train]\t J_a: 209.87, accuracy: 1.00\n",
      "[Test]\t J_a: 280.19, accuracy: 0.9412\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 200\n",
      "Epoch: 17\n",
      "[Train]\t J_a: 209.44, accuracy: 1.00\n",
      "[Test]\t J_a: 282.48, accuracy: 0.9345\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 200\n",
      "Epoch: 18\n",
      "[Train]\t J_a: 208.05, accuracy: 1.00\n",
      "[Test]\t J_a: 282.77, accuracy: 0.9344\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 200\n",
      "Epoch: 19\n",
      "[Train]\t J_a: 208.09, accuracy: 1.00\n",
      "[Test]\t J_a: 283.36, accuracy: 0.9335\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 200\n",
      "Epoch: 20\n",
      "[Train]\t J_a: 206.76, accuracy: 1.00\n",
      "[Test]\t J_a: 281.78, accuracy: 0.9386\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 200\n",
      "Epoch: 21\n",
      "[Train]\t J_a: 206.20, accuracy: 1.00\n",
      "[Test]\t J_a: 280.79, accuracy: 0.9447\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 200\n",
      "Epoch: 22\n",
      "[Train]\t J_a: 205.72, accuracy: 1.00\n",
      "[Test]\t J_a: 282.24, accuracy: 0.9385\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 200\n",
      "Epoch: 23\n",
      "[Train]\t J_a: 204.65, accuracy: 1.00\n",
      "[Test]\t J_a: 279.28, accuracy: 0.9450\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 200\n",
      "Epoch: 24\n",
      "[Train]\t J_a: 203.72, accuracy: 1.00\n",
      "[Test]\t J_a: 279.02, accuracy: 0.9453\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 200\n",
      "Epoch: 25\n",
      "[Train]\t J_a: 202.97, accuracy: 1.00\n",
      "[Test]\t J_a: 280.15, accuracy: 0.9399\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 200\n",
      "Epoch: 26\n",
      "[Train]\t J_a: 203.32, accuracy: 1.00\n",
      "[Test]\t J_a: 281.90, accuracy: 0.9361\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 200\n",
      "Epoch: 27\n",
      "[Train]\t J_a: 202.24, accuracy: 1.00\n",
      "[Test]\t J_a: 279.68, accuracy: 0.9439\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 200\n",
      "Epoch: 28\n",
      "[Train]\t J_a: 202.50, accuracy: 1.00\n",
      "[Test]\t J_a: 280.55, accuracy: 0.9427\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 200\n",
      "Epoch: 29\n",
      "[Train]\t J_a: 202.47, accuracy: 1.00\n",
      "[Test]\t J_a: 280.50, accuracy: 0.9385\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 200\n",
      "Epoch: 30\n",
      "[Train]\t J_a: 201.23, accuracy: 1.00\n",
      "[Test]\t J_a: 279.78, accuracy: 0.9423\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 200\n",
      "Epoch: 31\n",
      "[Train]\t J_a: 200.60, accuracy: 1.00\n",
      "[Test]\t J_a: 277.77, accuracy: 0.9485\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 200\n",
      "Epoch: 32\n",
      "[Train]\t J_a: 199.73, accuracy: 1.00\n",
      "[Test]\t J_a: 281.19, accuracy: 0.9397\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 200\n",
      "Epoch: 33\n",
      "[Train]\t J_a: 199.03, accuracy: 1.00\n",
      "[Test]\t J_a: 278.85, accuracy: 0.9437\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 200\n",
      "Epoch: 34\n",
      "[Train]\t J_a: 198.52, accuracy: 1.00\n",
      "[Test]\t J_a: 280.34, accuracy: 0.9396\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 200\n",
      "Epoch: 35\n",
      "[Train]\t J_a: 198.77, accuracy: 1.00\n",
      "[Test]\t J_a: 281.58, accuracy: 0.9401\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 200\n",
      "Epoch: 36\n",
      "[Train]\t J_a: 198.09, accuracy: 1.00\n",
      "[Test]\t J_a: 279.07, accuracy: 0.9452\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 200\n",
      "Epoch: 37\n",
      "[Train]\t J_a: 199.57, accuracy: 1.00\n",
      "[Test]\t J_a: 278.52, accuracy: 0.9468\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 200\n",
      "Epoch: 38\n",
      "[Train]\t J_a: 198.78, accuracy: 1.00\n",
      "[Test]\t J_a: 279.66, accuracy: 0.9426\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 200\n",
      "Epoch: 39\n",
      "[Train]\t J_a: 197.16, accuracy: 1.00\n",
      "[Test]\t J_a: 279.28, accuracy: 0.9450\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 200\n",
      "Epoch: 40\n",
      "[Train]\t J_a: 197.40, accuracy: 1.00\n",
      "[Test]\t J_a: 278.76, accuracy: 0.9444\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 200\n",
      "Epoch: 41\n",
      "[Train]\t J_a: 196.68, accuracy: 1.00\n",
      "[Test]\t J_a: 279.17, accuracy: 0.9414\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 200\n",
      "Epoch: 42\n",
      "[Train]\t J_a: 197.34, accuracy: 1.00\n",
      "[Test]\t J_a: 278.91, accuracy: 0.9448\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 200\n",
      "Epoch: 43\n",
      "[Train]\t J_a: 197.00, accuracy: 1.00\n",
      "[Test]\t J_a: 278.27, accuracy: 0.9453\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 200\n",
      "Epoch: 44\n",
      "[Train]\t J_a: 195.97, accuracy: 1.00\n",
      "[Test]\t J_a: 277.32, accuracy: 0.9458\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 200\n",
      "Epoch: 45\n",
      "[Train]\t J_a: 196.72, accuracy: 1.00\n",
      "[Test]\t J_a: 276.56, accuracy: 0.9495\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 200\n",
      "Epoch: 46\n",
      "[Train]\t J_a: 195.59, accuracy: 1.00\n",
      "[Test]\t J_a: 277.32, accuracy: 0.9466\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 200\n",
      "Epoch: 47\n",
      "[Train]\t J_a: 194.41, accuracy: 1.00\n",
      "[Test]\t J_a: 276.64, accuracy: 0.9473\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 200\n",
      "Epoch: 48\n",
      "[Train]\t J_a: 195.14, accuracy: 1.00\n",
      "[Test]\t J_a: 277.86, accuracy: 0.9457\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 200\n",
      "Epoch: 49\n",
      "[Train]\t J_a: 195.37, accuracy: 1.00\n",
      "[Test]\t J_a: 277.33, accuracy: 0.9438\n",
      "./saved_data/MNIST_X_train_labelled_bald_100_111.pt\n",
      "./saved_data/MNIST_y_train_labelled_bald_100_111.pt\n",
      "200 200\n",
      "./saved_data/MNIST_X_train_unlabelled_bald_100_111.pt\n",
      "./saved_data/MNIST_y_train_unlabelled_bald_100_111.pt\n",
      "59800 59800\n",
      "./saved_data/MNIST_X_test_111.pt\n",
      "./saved_data/MNIST_y_test_111.pt\n",
      "10000 10000\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 200\n",
      "Epoch: 0\n",
      "[Train]\t J_a: 394.29, accuracy: 0.93\n",
      "[Test]\t J_a: 327.36, accuracy: 0.9065\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 200\n",
      "Epoch: 1\n",
      "[Train]\t J_a: 297.85, accuracy: 1.00\n",
      "[Test]\t J_a: 306.67, accuracy: 0.9179\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 200\n",
      "Epoch: 2\n",
      "[Train]\t J_a: 278.16, accuracy: 1.00\n",
      "[Test]\t J_a: 299.03, accuracy: 0.9221\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 200\n",
      "Epoch: 3\n",
      "[Train]\t J_a: 265.18, accuracy: 1.00\n",
      "[Test]\t J_a: 293.41, accuracy: 0.9329\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 200\n",
      "Epoch: 4\n",
      "[Train]\t J_a: 256.51, accuracy: 1.00\n",
      "[Test]\t J_a: 290.04, accuracy: 0.9309\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 200\n",
      "Epoch: 5\n",
      "[Train]\t J_a: 249.28, accuracy: 1.00\n",
      "[Test]\t J_a: 287.43, accuracy: 0.9350\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 200\n",
      "Epoch: 6\n",
      "[Train]\t J_a: 245.08, accuracy: 1.00\n",
      "[Test]\t J_a: 286.06, accuracy: 0.9422\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 200\n",
      "Epoch: 7\n",
      "[Train]\t J_a: 240.40, accuracy: 1.00\n",
      "[Test]\t J_a: 284.71, accuracy: 0.9407\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 200\n",
      "Epoch: 8\n",
      "[Train]\t J_a: 235.76, accuracy: 1.00\n",
      "[Test]\t J_a: 284.85, accuracy: 0.9408\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 200\n",
      "Epoch: 9\n",
      "[Train]\t J_a: 232.26, accuracy: 1.00\n",
      "[Test]\t J_a: 284.54, accuracy: 0.9325\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 200\n",
      "Epoch: 10\n",
      "[Train]\t J_a: 229.05, accuracy: 1.00\n",
      "[Test]\t J_a: 283.05, accuracy: 0.9429\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 200\n",
      "Epoch: 11\n",
      "[Train]\t J_a: 228.85, accuracy: 1.00\n",
      "[Test]\t J_a: 280.84, accuracy: 0.9479\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 200\n",
      "Epoch: 12\n",
      "[Train]\t J_a: 225.84, accuracy: 1.00\n",
      "[Test]\t J_a: 279.44, accuracy: 0.9475\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 200\n",
      "Epoch: 13\n",
      "[Train]\t J_a: 223.43, accuracy: 1.00\n",
      "[Test]\t J_a: 280.89, accuracy: 0.9516\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 200\n",
      "Epoch: 14\n",
      "[Train]\t J_a: 221.99, accuracy: 1.00\n",
      "[Test]\t J_a: 280.83, accuracy: 0.9505\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 200\n",
      "Epoch: 15\n",
      "[Train]\t J_a: 220.08, accuracy: 1.00\n",
      "[Test]\t J_a: 279.66, accuracy: 0.9503\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 200\n",
      "Epoch: 16\n",
      "[Train]\t J_a: 218.76, accuracy: 1.00\n",
      "[Test]\t J_a: 279.53, accuracy: 0.9521\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 200\n",
      "Epoch: 17\n",
      "[Train]\t J_a: 216.33, accuracy: 1.00\n",
      "[Test]\t J_a: 279.02, accuracy: 0.9534\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 200\n",
      "Epoch: 18\n",
      "[Train]\t J_a: 216.67, accuracy: 1.00\n",
      "[Test]\t J_a: 278.95, accuracy: 0.9554\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 200\n",
      "Epoch: 19\n",
      "[Train]\t J_a: 216.48, accuracy: 1.00\n",
      "[Test]\t J_a: 278.55, accuracy: 0.9541\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 200\n",
      "Epoch: 20\n",
      "[Train]\t J_a: 213.71, accuracy: 1.00\n",
      "[Test]\t J_a: 277.42, accuracy: 0.9529\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 200\n",
      "Epoch: 21\n",
      "[Train]\t J_a: 213.71, accuracy: 1.00\n",
      "[Test]\t J_a: 278.81, accuracy: 0.9523\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 200\n",
      "Epoch: 22\n",
      "[Train]\t J_a: 213.06, accuracy: 1.00\n",
      "[Test]\t J_a: 280.27, accuracy: 0.9488\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 200\n",
      "Epoch: 23\n",
      "[Train]\t J_a: 211.69, accuracy: 1.00\n",
      "[Test]\t J_a: 278.63, accuracy: 0.9528\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 200\n",
      "Epoch: 24\n",
      "[Train]\t J_a: 212.01, accuracy: 1.00\n",
      "[Test]\t J_a: 277.63, accuracy: 0.9559\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 200\n",
      "Epoch: 25\n",
      "[Train]\t J_a: 211.38, accuracy: 1.00\n",
      "[Test]\t J_a: 278.24, accuracy: 0.9552\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 200\n",
      "Epoch: 26\n",
      "[Train]\t J_a: 210.51, accuracy: 1.00\n",
      "[Test]\t J_a: 277.79, accuracy: 0.9545\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 200\n",
      "Epoch: 27\n",
      "[Train]\t J_a: 210.51, accuracy: 1.00\n",
      "[Test]\t J_a: 277.17, accuracy: 0.9552\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 200\n",
      "Epoch: 28\n",
      "[Train]\t J_a: 209.67, accuracy: 1.00\n",
      "[Test]\t J_a: 276.75, accuracy: 0.9589\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 200\n",
      "Epoch: 29\n",
      "[Train]\t J_a: 209.15, accuracy: 1.00\n",
      "[Test]\t J_a: 277.42, accuracy: 0.9565\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 200\n",
      "Epoch: 30\n",
      "[Train]\t J_a: 207.66, accuracy: 1.00\n",
      "[Test]\t J_a: 275.99, accuracy: 0.9578\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 200\n",
      "Epoch: 31\n",
      "[Train]\t J_a: 208.22, accuracy: 1.00\n",
      "[Test]\t J_a: 277.27, accuracy: 0.9582\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 200\n",
      "Epoch: 32\n",
      "[Train]\t J_a: 208.20, accuracy: 1.00\n",
      "[Test]\t J_a: 277.82, accuracy: 0.9554\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 200\n",
      "Epoch: 33\n",
      "[Train]\t J_a: 207.80, accuracy: 1.00\n",
      "[Test]\t J_a: 277.61, accuracy: 0.9571\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 200\n",
      "Epoch: 34\n",
      "[Train]\t J_a: 206.60, accuracy: 1.00\n",
      "[Test]\t J_a: 277.48, accuracy: 0.9551\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 200\n",
      "Epoch: 35\n",
      "[Train]\t J_a: 206.27, accuracy: 1.00\n",
      "[Test]\t J_a: 276.55, accuracy: 0.9564\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 200\n",
      "Epoch: 36\n",
      "[Train]\t J_a: 205.57, accuracy: 1.00\n",
      "[Test]\t J_a: 275.90, accuracy: 0.9577\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 200\n",
      "Epoch: 37\n",
      "[Train]\t J_a: 205.05, accuracy: 1.00\n",
      "[Test]\t J_a: 276.75, accuracy: 0.9575\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 200\n",
      "Epoch: 38\n",
      "[Train]\t J_a: 204.73, accuracy: 1.00\n",
      "[Test]\t J_a: 275.50, accuracy: 0.9610\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 200\n",
      "Epoch: 39\n",
      "[Train]\t J_a: 205.36, accuracy: 1.00\n",
      "[Test]\t J_a: 276.23, accuracy: 0.9607\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 200\n",
      "Epoch: 40\n",
      "[Train]\t J_a: 205.17, accuracy: 1.00\n",
      "[Test]\t J_a: 275.05, accuracy: 0.9601\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 200\n",
      "Epoch: 41\n",
      "[Train]\t J_a: 204.03, accuracy: 1.00\n",
      "[Test]\t J_a: 274.14, accuracy: 0.9633\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 200\n",
      "Epoch: 42\n",
      "[Train]\t J_a: 203.96, accuracy: 1.00\n",
      "[Test]\t J_a: 274.98, accuracy: 0.9631\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 200\n",
      "Epoch: 43\n",
      "[Train]\t J_a: 203.13, accuracy: 1.00\n",
      "[Test]\t J_a: 275.41, accuracy: 0.9579\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 200\n",
      "Epoch: 44\n",
      "[Train]\t J_a: 202.64, accuracy: 1.00\n",
      "[Test]\t J_a: 274.41, accuracy: 0.9623\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 200\n",
      "Epoch: 45\n",
      "[Train]\t J_a: 202.21, accuracy: 1.00\n",
      "[Test]\t J_a: 273.93, accuracy: 0.9627\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 200\n",
      "Epoch: 46\n",
      "[Train]\t J_a: 201.93, accuracy: 1.00\n",
      "[Test]\t J_a: 274.45, accuracy: 0.9632\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 200\n",
      "Epoch: 47\n",
      "[Train]\t J_a: 201.93, accuracy: 1.00\n",
      "[Test]\t J_a: 273.55, accuracy: 0.9637\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 200\n",
      "Epoch: 48\n",
      "[Train]\t J_a: 201.54, accuracy: 1.00\n",
      "[Test]\t J_a: 274.37, accuracy: 0.9612\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 200\n",
      "Epoch: 49\n",
      "[Train]\t J_a: 201.24, accuracy: 1.00\n",
      "[Test]\t J_a: 273.88, accuracy: 0.9632\n",
      "./saved_data/MNIST_X_train_labelled_random_100_111.pt\n",
      "./saved_data/MNIST_y_train_labelled_random_100_111.pt\n",
      "300 300\n",
      "./saved_data/MNIST_X_train_unlabelled_random_100_111.pt\n",
      "./saved_data/MNIST_y_train_unlabelled_random_100_111.pt\n",
      "59700 59700\n",
      "./saved_data/MNIST_X_test_111.pt\n",
      "./saved_data/MNIST_y_test_111.pt\n",
      "10000 10000\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 300\n",
      "Epoch: 0\n",
      "[Train]\t J_a: 373.74, accuracy: 0.94\n",
      "[Test]\t J_a: 319.47, accuracy: 0.8839\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 300\n",
      "Epoch: 1\n",
      "[Train]\t J_a: 289.20, accuracy: 0.99\n",
      "[Test]\t J_a: 298.87, accuracy: 0.9025\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 300\n",
      "Epoch: 2\n",
      "[Train]\t J_a: 270.33, accuracy: 1.00\n",
      "[Test]\t J_a: 291.64, accuracy: 0.9084\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 300\n",
      "Epoch: 3\n",
      "[Train]\t J_a: 258.36, accuracy: 1.00\n",
      "[Test]\t J_a: 283.84, accuracy: 0.9244\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 300\n",
      "Epoch: 4\n",
      "[Train]\t J_a: 250.36, accuracy: 1.00\n",
      "[Test]\t J_a: 281.11, accuracy: 0.9280\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 300\n",
      "Epoch: 5\n",
      "[Train]\t J_a: 245.14, accuracy: 1.00\n",
      "[Test]\t J_a: 278.07, accuracy: 0.9292\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 300\n",
      "Epoch: 6\n",
      "[Train]\t J_a: 240.96, accuracy: 1.00\n",
      "[Test]\t J_a: 277.29, accuracy: 0.9297\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 300\n",
      "Epoch: 7\n",
      "[Train]\t J_a: 236.75, accuracy: 1.00\n",
      "[Test]\t J_a: 274.17, accuracy: 0.9378\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 300\n",
      "Epoch: 8\n",
      "[Train]\t J_a: 234.23, accuracy: 1.00\n",
      "[Test]\t J_a: 273.36, accuracy: 0.9379\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 300\n",
      "Epoch: 9\n",
      "[Train]\t J_a: 232.10, accuracy: 1.00\n",
      "[Test]\t J_a: 271.88, accuracy: 0.9408\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 300\n",
      "Epoch: 10\n",
      "[Train]\t J_a: 229.68, accuracy: 1.00\n",
      "[Test]\t J_a: 271.76, accuracy: 0.9406\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 300\n",
      "Epoch: 11\n",
      "[Train]\t J_a: 228.30, accuracy: 1.00\n",
      "[Test]\t J_a: 271.39, accuracy: 0.9399\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 300\n",
      "Epoch: 12\n",
      "[Train]\t J_a: 226.62, accuracy: 1.00\n",
      "[Test]\t J_a: 269.89, accuracy: 0.9488\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 300\n",
      "Epoch: 13\n",
      "[Train]\t J_a: 225.40, accuracy: 1.00\n",
      "[Test]\t J_a: 270.02, accuracy: 0.9470\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 300\n",
      "Epoch: 14\n",
      "[Train]\t J_a: 224.50, accuracy: 1.00\n",
      "[Test]\t J_a: 270.74, accuracy: 0.9461\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 300\n",
      "Epoch: 15\n",
      "[Train]\t J_a: 223.92, accuracy: 1.00\n",
      "[Test]\t J_a: 269.83, accuracy: 0.9454\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 300\n",
      "Epoch: 16\n",
      "[Train]\t J_a: 222.36, accuracy: 1.00\n",
      "[Test]\t J_a: 271.95, accuracy: 0.9392\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 300\n",
      "Epoch: 17\n",
      "[Train]\t J_a: 221.73, accuracy: 1.00\n",
      "[Test]\t J_a: 271.16, accuracy: 0.9443\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 300\n",
      "Epoch: 18\n",
      "[Train]\t J_a: 220.93, accuracy: 1.00\n",
      "[Test]\t J_a: 271.36, accuracy: 0.9432\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 300\n",
      "Epoch: 19\n",
      "[Train]\t J_a: 219.93, accuracy: 1.00\n",
      "[Test]\t J_a: 270.23, accuracy: 0.9492\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 300\n",
      "Epoch: 20\n",
      "[Train]\t J_a: 219.08, accuracy: 1.00\n",
      "[Test]\t J_a: 270.72, accuracy: 0.9470\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 300\n",
      "Epoch: 21\n",
      "[Train]\t J_a: 218.62, accuracy: 1.00\n",
      "[Test]\t J_a: 268.61, accuracy: 0.9508\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 300\n",
      "Epoch: 22\n",
      "[Train]\t J_a: 218.28, accuracy: 1.00\n",
      "[Test]\t J_a: 269.90, accuracy: 0.9485\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 300\n",
      "Epoch: 23\n",
      "[Train]\t J_a: 217.62, accuracy: 1.00\n",
      "[Test]\t J_a: 268.85, accuracy: 0.9537\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 300\n",
      "Epoch: 24\n",
      "[Train]\t J_a: 217.12, accuracy: 1.00\n",
      "[Test]\t J_a: 268.86, accuracy: 0.9519\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 300\n",
      "Epoch: 25\n",
      "[Train]\t J_a: 216.66, accuracy: 1.00\n",
      "[Test]\t J_a: 268.28, accuracy: 0.9552\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 300\n",
      "Epoch: 26\n",
      "[Train]\t J_a: 216.16, accuracy: 1.00\n",
      "[Test]\t J_a: 269.28, accuracy: 0.9509\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 300\n",
      "Epoch: 27\n",
      "[Train]\t J_a: 216.19, accuracy: 1.00\n",
      "[Test]\t J_a: 268.40, accuracy: 0.9534\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 300\n",
      "Epoch: 28\n",
      "[Train]\t J_a: 215.31, accuracy: 1.00\n",
      "[Test]\t J_a: 268.04, accuracy: 0.9534\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 300\n",
      "Epoch: 29\n",
      "[Train]\t J_a: 215.06, accuracy: 1.00\n",
      "[Test]\t J_a: 267.81, accuracy: 0.9565\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 300\n",
      "Epoch: 30\n",
      "[Train]\t J_a: 214.56, accuracy: 1.00\n",
      "[Test]\t J_a: 267.47, accuracy: 0.9591\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 300\n",
      "Epoch: 31\n",
      "[Train]\t J_a: 214.80, accuracy: 1.00\n",
      "[Test]\t J_a: 268.35, accuracy: 0.9548\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 300\n",
      "Epoch: 32\n",
      "[Train]\t J_a: 214.26, accuracy: 1.00\n",
      "[Test]\t J_a: 268.13, accuracy: 0.9568\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 300\n",
      "Epoch: 33\n",
      "[Train]\t J_a: 214.23, accuracy: 1.00\n",
      "[Test]\t J_a: 268.07, accuracy: 0.9532\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 300\n",
      "Epoch: 34\n",
      "[Train]\t J_a: 213.90, accuracy: 1.00\n",
      "[Test]\t J_a: 268.40, accuracy: 0.9530\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 300\n",
      "Epoch: 35\n",
      "[Train]\t J_a: 213.57, accuracy: 1.00\n",
      "[Test]\t J_a: 268.08, accuracy: 0.9567\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 300\n",
      "Epoch: 36\n",
      "[Train]\t J_a: 213.52, accuracy: 1.00\n",
      "[Test]\t J_a: 266.80, accuracy: 0.9575\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 300\n",
      "Epoch: 37\n",
      "[Train]\t J_a: 212.85, accuracy: 1.00\n",
      "[Test]\t J_a: 268.09, accuracy: 0.9559\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 300\n",
      "Epoch: 38\n",
      "[Train]\t J_a: 212.61, accuracy: 1.00\n",
      "[Test]\t J_a: 266.45, accuracy: 0.9595\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 300\n",
      "Epoch: 39\n",
      "[Train]\t J_a: 212.10, accuracy: 1.00\n",
      "[Test]\t J_a: 267.07, accuracy: 0.9574\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 300\n",
      "Epoch: 40\n",
      "[Train]\t J_a: 212.36, accuracy: 1.00\n",
      "[Test]\t J_a: 266.54, accuracy: 0.9613\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 300\n",
      "Epoch: 41\n",
      "[Train]\t J_a: 211.93, accuracy: 1.00\n",
      "[Test]\t J_a: 267.04, accuracy: 0.9603\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 300\n",
      "Epoch: 42\n",
      "[Train]\t J_a: 211.99, accuracy: 1.00\n",
      "[Test]\t J_a: 267.54, accuracy: 0.9532\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 300\n",
      "Epoch: 43\n",
      "[Train]\t J_a: 211.64, accuracy: 1.00\n",
      "[Test]\t J_a: 267.36, accuracy: 0.9573\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 300\n",
      "Epoch: 44\n",
      "[Train]\t J_a: 211.65, accuracy: 1.00\n",
      "[Test]\t J_a: 267.51, accuracy: 0.9579\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 300\n",
      "Epoch: 45\n",
      "[Train]\t J_a: 210.97, accuracy: 1.00\n",
      "[Test]\t J_a: 268.78, accuracy: 0.9525\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 300\n",
      "Epoch: 46\n",
      "[Train]\t J_a: 211.18, accuracy: 1.00\n",
      "[Test]\t J_a: 268.32, accuracy: 0.9531\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 300\n",
      "Epoch: 47\n",
      "[Train]\t J_a: 210.89, accuracy: 1.00\n",
      "[Test]\t J_a: 268.12, accuracy: 0.9570\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 300\n",
      "Epoch: 48\n",
      "[Train]\t J_a: 210.77, accuracy: 1.00\n",
      "[Test]\t J_a: 268.63, accuracy: 0.9550\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 300\n",
      "Epoch: 49\n",
      "[Train]\t J_a: 210.97, accuracy: 1.00\n",
      "[Test]\t J_a: 267.91, accuracy: 0.9596\n",
      "./saved_data/MNIST_X_train_labelled_bald_100_111.pt\n",
      "./saved_data/MNIST_y_train_labelled_bald_100_111.pt\n",
      "300 300\n",
      "./saved_data/MNIST_X_train_unlabelled_bald_100_111.pt\n",
      "./saved_data/MNIST_y_train_unlabelled_bald_100_111.pt\n",
      "59700 59700\n",
      "./saved_data/MNIST_X_test_111.pt\n",
      "./saved_data/MNIST_y_test_111.pt\n",
      "10000 10000\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 300\n",
      "Epoch: 0\n",
      "[Train]\t J_a: 399.88, accuracy: 0.91\n",
      "[Test]\t J_a: 314.86, accuracy: 0.9260\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 300\n",
      "Epoch: 1\n",
      "[Train]\t J_a: 309.75, accuracy: 0.99\n",
      "[Test]\t J_a: 295.74, accuracy: 0.9336\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 300\n",
      "Epoch: 2\n",
      "[Train]\t J_a: 289.82, accuracy: 0.99\n",
      "[Test]\t J_a: 286.81, accuracy: 0.9440\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 300\n",
      "Epoch: 3\n",
      "[Train]\t J_a: 278.34, accuracy: 1.00\n",
      "[Test]\t J_a: 281.68, accuracy: 0.9409\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 300\n",
      "Epoch: 4\n",
      "[Train]\t J_a: 269.80, accuracy: 1.00\n",
      "[Test]\t J_a: 277.76, accuracy: 0.9461\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 300\n",
      "Epoch: 5\n",
      "[Train]\t J_a: 263.73, accuracy: 1.00\n",
      "[Test]\t J_a: 275.09, accuracy: 0.9515\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 300\n",
      "Epoch: 6\n",
      "[Train]\t J_a: 259.14, accuracy: 1.00\n",
      "[Test]\t J_a: 273.26, accuracy: 0.9572\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 300\n",
      "Epoch: 7\n",
      "[Train]\t J_a: 255.15, accuracy: 1.00\n",
      "[Test]\t J_a: 271.81, accuracy: 0.9562\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 300\n",
      "Epoch: 8\n",
      "[Train]\t J_a: 251.91, accuracy: 1.00\n",
      "[Test]\t J_a: 272.04, accuracy: 0.9537\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 300\n",
      "Epoch: 9\n",
      "[Train]\t J_a: 248.74, accuracy: 1.00\n",
      "[Test]\t J_a: 270.98, accuracy: 0.9590\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 300\n",
      "Epoch: 10\n",
      "[Train]\t J_a: 246.23, accuracy: 1.00\n",
      "[Test]\t J_a: 271.13, accuracy: 0.9582\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 300\n",
      "Epoch: 11\n",
      "[Train]\t J_a: 243.29, accuracy: 1.00\n",
      "[Test]\t J_a: 270.24, accuracy: 0.9589\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 300\n",
      "Epoch: 12\n",
      "[Train]\t J_a: 242.03, accuracy: 1.00\n",
      "[Test]\t J_a: 270.15, accuracy: 0.9613\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 300\n",
      "Epoch: 13\n",
      "[Train]\t J_a: 240.01, accuracy: 1.00\n",
      "[Test]\t J_a: 269.22, accuracy: 0.9597\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 300\n",
      "Epoch: 14\n",
      "[Train]\t J_a: 238.88, accuracy: 1.00\n",
      "[Test]\t J_a: 269.18, accuracy: 0.9617\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 300\n",
      "Epoch: 15\n",
      "[Train]\t J_a: 237.04, accuracy: 1.00\n",
      "[Test]\t J_a: 269.59, accuracy: 0.9609\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 300\n",
      "Epoch: 16\n",
      "[Train]\t J_a: 236.10, accuracy: 1.00\n",
      "[Test]\t J_a: 269.67, accuracy: 0.9605\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 300\n",
      "Epoch: 17\n",
      "[Train]\t J_a: 234.86, accuracy: 1.00\n",
      "[Test]\t J_a: 269.19, accuracy: 0.9642\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 300\n",
      "Epoch: 18\n",
      "[Train]\t J_a: 234.10, accuracy: 1.00\n",
      "[Test]\t J_a: 268.96, accuracy: 0.9650\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 300\n",
      "Epoch: 19\n",
      "[Train]\t J_a: 233.37, accuracy: 1.00\n",
      "[Test]\t J_a: 268.33, accuracy: 0.9652\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 300\n",
      "Epoch: 20\n",
      "[Train]\t J_a: 232.30, accuracy: 1.00\n",
      "[Test]\t J_a: 268.49, accuracy: 0.9640\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 300\n",
      "Epoch: 21\n",
      "[Train]\t J_a: 231.00, accuracy: 1.00\n",
      "[Test]\t J_a: 268.23, accuracy: 0.9653\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 300\n",
      "Epoch: 22\n",
      "[Train]\t J_a: 230.70, accuracy: 1.00\n",
      "[Test]\t J_a: 268.77, accuracy: 0.9645\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 300\n",
      "Epoch: 23\n",
      "[Train]\t J_a: 229.59, accuracy: 1.00\n",
      "[Test]\t J_a: 268.30, accuracy: 0.9646\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 300\n",
      "Epoch: 24\n",
      "[Train]\t J_a: 229.25, accuracy: 1.00\n",
      "[Test]\t J_a: 268.52, accuracy: 0.9669\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 300\n",
      "Epoch: 25\n",
      "[Train]\t J_a: 228.54, accuracy: 1.00\n",
      "[Test]\t J_a: 268.28, accuracy: 0.9668\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 300\n",
      "Epoch: 26\n",
      "[Train]\t J_a: 227.92, accuracy: 1.00\n",
      "[Test]\t J_a: 268.91, accuracy: 0.9657\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 300\n",
      "Epoch: 27\n",
      "[Train]\t J_a: 227.81, accuracy: 1.00\n",
      "[Test]\t J_a: 269.64, accuracy: 0.9642\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 300\n",
      "Epoch: 28\n",
      "[Train]\t J_a: 227.26, accuracy: 1.00\n",
      "[Test]\t J_a: 268.32, accuracy: 0.9680\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 300\n",
      "Epoch: 29\n",
      "[Train]\t J_a: 226.35, accuracy: 1.00\n",
      "[Test]\t J_a: 268.25, accuracy: 0.9683\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 300\n",
      "Epoch: 30\n",
      "[Train]\t J_a: 226.01, accuracy: 1.00\n",
      "[Test]\t J_a: 267.91, accuracy: 0.9676\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 300\n",
      "Epoch: 31\n",
      "[Train]\t J_a: 225.58, accuracy: 1.00\n",
      "[Test]\t J_a: 268.00, accuracy: 0.9675\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 300\n",
      "Epoch: 32\n",
      "[Train]\t J_a: 225.50, accuracy: 1.00\n",
      "[Test]\t J_a: 267.91, accuracy: 0.9678\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 300\n",
      "Epoch: 33\n",
      "[Train]\t J_a: 225.18, accuracy: 1.00\n",
      "[Test]\t J_a: 267.97, accuracy: 0.9678\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 300\n",
      "Epoch: 34\n",
      "[Train]\t J_a: 224.15, accuracy: 1.00\n",
      "[Test]\t J_a: 268.56, accuracy: 0.9690\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 300\n",
      "Epoch: 35\n",
      "[Train]\t J_a: 223.39, accuracy: 1.00\n",
      "[Test]\t J_a: 268.91, accuracy: 0.9643\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 300\n",
      "Epoch: 36\n",
      "[Train]\t J_a: 223.30, accuracy: 1.00\n",
      "[Test]\t J_a: 267.62, accuracy: 0.9714\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 300\n",
      "Epoch: 37\n",
      "[Train]\t J_a: 223.74, accuracy: 1.00\n",
      "[Test]\t J_a: 267.64, accuracy: 0.9716\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 300\n",
      "Epoch: 38\n",
      "[Train]\t J_a: 223.42, accuracy: 1.00\n",
      "[Test]\t J_a: 268.03, accuracy: 0.9692\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 300\n",
      "Epoch: 39\n",
      "[Train]\t J_a: 222.68, accuracy: 1.00\n",
      "[Test]\t J_a: 267.73, accuracy: 0.9702\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 300\n",
      "Epoch: 40\n",
      "[Train]\t J_a: 222.93, accuracy: 1.00\n",
      "[Test]\t J_a: 267.76, accuracy: 0.9711\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 300\n",
      "Epoch: 41\n",
      "[Train]\t J_a: 222.49, accuracy: 1.00\n",
      "[Test]\t J_a: 267.66, accuracy: 0.9696\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 300\n",
      "Epoch: 42\n",
      "[Train]\t J_a: 221.90, accuracy: 1.00\n",
      "[Test]\t J_a: 268.39, accuracy: 0.9694\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 300\n",
      "Epoch: 43\n",
      "[Train]\t J_a: 221.69, accuracy: 1.00\n",
      "[Test]\t J_a: 267.68, accuracy: 0.9705\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 300\n",
      "Epoch: 44\n",
      "[Train]\t J_a: 221.26, accuracy: 1.00\n",
      "[Test]\t J_a: 267.80, accuracy: 0.9689\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 300\n",
      "Epoch: 45\n",
      "[Train]\t J_a: 221.03, accuracy: 1.00\n",
      "[Test]\t J_a: 268.46, accuracy: 0.9704\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 300\n",
      "Epoch: 46\n",
      "[Train]\t J_a: 221.24, accuracy: 1.00\n",
      "[Test]\t J_a: 268.05, accuracy: 0.9684\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 300\n",
      "Epoch: 47\n",
      "[Train]\t J_a: 220.93, accuracy: 1.00\n",
      "[Test]\t J_a: 268.05, accuracy: 0.9692\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 300\n",
      "Epoch: 48\n",
      "[Train]\t J_a: 220.64, accuracy: 1.00\n",
      "[Test]\t J_a: 267.66, accuracy: 0.9712\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 300\n",
      "Epoch: 49\n",
      "[Train]\t J_a: 220.24, accuracy: 1.00\n",
      "[Test]\t J_a: 268.54, accuracy: 0.9704\n",
      "./saved_data/MNIST_X_train_labelled_random_100_111.pt\n",
      "./saved_data/MNIST_y_train_labelled_random_100_111.pt\n",
      "400 400\n",
      "./saved_data/MNIST_X_train_unlabelled_random_100_111.pt\n",
      "./saved_data/MNIST_y_train_unlabelled_random_100_111.pt\n",
      "59600 59600\n",
      "./saved_data/MNIST_X_test_111.pt\n",
      "./saved_data/MNIST_y_test_111.pt\n",
      "10000 10000\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 400\n",
      "Epoch: 0\n",
      "[Train]\t J_a: 376.86, accuracy: 0.94\n",
      "[Test]\t J_a: 315.04, accuracy: 0.9036\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 400\n",
      "Epoch: 1\n",
      "[Train]\t J_a: 293.06, accuracy: 0.99\n",
      "[Test]\t J_a: 294.84, accuracy: 0.9284\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 400\n",
      "Epoch: 2\n",
      "[Train]\t J_a: 274.53, accuracy: 1.00\n",
      "[Test]\t J_a: 284.44, accuracy: 0.9309\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 400\n",
      "Epoch: 3\n",
      "[Train]\t J_a: 262.21, accuracy: 1.00\n",
      "[Test]\t J_a: 277.86, accuracy: 0.9392\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 400\n",
      "Epoch: 4\n",
      "[Train]\t J_a: 255.98, accuracy: 1.00\n",
      "[Test]\t J_a: 273.93, accuracy: 0.9389\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 400\n",
      "Epoch: 5\n",
      "[Train]\t J_a: 249.34, accuracy: 1.00\n",
      "[Test]\t J_a: 271.05, accuracy: 0.9417\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 400\n",
      "Epoch: 6\n",
      "[Train]\t J_a: 245.41, accuracy: 1.00\n",
      "[Test]\t J_a: 268.96, accuracy: 0.9464\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 400\n",
      "Epoch: 7\n",
      "[Train]\t J_a: 242.30, accuracy: 1.00\n",
      "[Test]\t J_a: 267.45, accuracy: 0.9425\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 400\n",
      "Epoch: 8\n",
      "[Train]\t J_a: 239.31, accuracy: 1.00\n",
      "[Test]\t J_a: 265.80, accuracy: 0.9479\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 400\n",
      "Epoch: 9\n",
      "[Train]\t J_a: 237.03, accuracy: 1.00\n",
      "[Test]\t J_a: 266.22, accuracy: 0.9492\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 400\n",
      "Epoch: 10\n",
      "[Train]\t J_a: 235.46, accuracy: 1.00\n",
      "[Test]\t J_a: 264.84, accuracy: 0.9496\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 400\n",
      "Epoch: 11\n",
      "[Train]\t J_a: 233.04, accuracy: 1.00\n",
      "[Test]\t J_a: 263.55, accuracy: 0.9509\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 400\n",
      "Epoch: 12\n",
      "[Train]\t J_a: 231.41, accuracy: 1.00\n",
      "[Test]\t J_a: 263.08, accuracy: 0.9491\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 400\n",
      "Epoch: 13\n",
      "[Train]\t J_a: 231.46, accuracy: 1.00\n",
      "[Test]\t J_a: 264.03, accuracy: 0.9493\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 400\n",
      "Epoch: 14\n",
      "[Train]\t J_a: 229.16, accuracy: 1.00\n",
      "[Test]\t J_a: 263.28, accuracy: 0.9523\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 400\n",
      "Epoch: 15\n",
      "[Train]\t J_a: 227.74, accuracy: 1.00\n",
      "[Test]\t J_a: 263.11, accuracy: 0.9504\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 400\n",
      "Epoch: 16\n",
      "[Train]\t J_a: 227.61, accuracy: 1.00\n",
      "[Test]\t J_a: 262.01, accuracy: 0.9536\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 400\n",
      "Epoch: 17\n",
      "[Train]\t J_a: 226.50, accuracy: 1.00\n",
      "[Test]\t J_a: 262.46, accuracy: 0.9537\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 400\n",
      "Epoch: 18\n",
      "[Train]\t J_a: 225.95, accuracy: 1.00\n",
      "[Test]\t J_a: 262.09, accuracy: 0.9566\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 400\n",
      "Epoch: 19\n",
      "[Train]\t J_a: 225.65, accuracy: 1.00\n",
      "[Test]\t J_a: 261.19, accuracy: 0.9588\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 400\n",
      "Epoch: 20\n",
      "[Train]\t J_a: 224.63, accuracy: 1.00\n",
      "[Test]\t J_a: 260.94, accuracy: 0.9592\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 400\n",
      "Epoch: 21\n",
      "[Train]\t J_a: 223.57, accuracy: 1.00\n",
      "[Test]\t J_a: 261.62, accuracy: 0.9542\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 400\n",
      "Epoch: 22\n",
      "[Train]\t J_a: 222.97, accuracy: 1.00\n",
      "[Test]\t J_a: 262.02, accuracy: 0.9574\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 400\n",
      "Epoch: 23\n",
      "[Train]\t J_a: 223.08, accuracy: 1.00\n",
      "[Test]\t J_a: 261.43, accuracy: 0.9590\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 400\n",
      "Epoch: 24\n",
      "[Train]\t J_a: 221.85, accuracy: 1.00\n",
      "[Test]\t J_a: 260.94, accuracy: 0.9584\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 400\n",
      "Epoch: 25\n",
      "[Train]\t J_a: 222.36, accuracy: 1.00\n",
      "[Test]\t J_a: 261.73, accuracy: 0.9585\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 400\n",
      "Epoch: 26\n",
      "[Train]\t J_a: 221.48, accuracy: 1.00\n",
      "[Test]\t J_a: 261.19, accuracy: 0.9575\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 400\n",
      "Epoch: 27\n",
      "[Train]\t J_a: 220.84, accuracy: 1.00\n",
      "[Test]\t J_a: 261.34, accuracy: 0.9586\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 400\n",
      "Epoch: 28\n",
      "[Train]\t J_a: 220.75, accuracy: 1.00\n",
      "[Test]\t J_a: 261.35, accuracy: 0.9576\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 400\n",
      "Epoch: 29\n",
      "[Train]\t J_a: 220.60, accuracy: 1.00\n",
      "[Test]\t J_a: 261.35, accuracy: 0.9605\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 400\n",
      "Epoch: 30\n",
      "[Train]\t J_a: 219.46, accuracy: 1.00\n",
      "[Test]\t J_a: 260.43, accuracy: 0.9614\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 400\n",
      "Epoch: 31\n",
      "[Train]\t J_a: 218.54, accuracy: 1.00\n",
      "[Test]\t J_a: 260.87, accuracy: 0.9598\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 400\n",
      "Epoch: 32\n",
      "[Train]\t J_a: 219.26, accuracy: 1.00\n",
      "[Test]\t J_a: 260.19, accuracy: 0.9642\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 400\n",
      "Epoch: 33\n",
      "[Train]\t J_a: 219.21, accuracy: 1.00\n",
      "[Test]\t J_a: 259.57, accuracy: 0.9635\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 400\n",
      "Epoch: 34\n",
      "[Train]\t J_a: 218.44, accuracy: 1.00\n",
      "[Test]\t J_a: 260.49, accuracy: 0.9626\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 400\n",
      "Epoch: 35\n",
      "[Train]\t J_a: 218.59, accuracy: 1.00\n",
      "[Test]\t J_a: 260.54, accuracy: 0.9617\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 400\n",
      "Epoch: 36\n",
      "[Train]\t J_a: 218.20, accuracy: 1.00\n",
      "[Test]\t J_a: 260.24, accuracy: 0.9619\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 400\n",
      "Epoch: 37\n",
      "[Train]\t J_a: 217.80, accuracy: 1.00\n",
      "[Test]\t J_a: 261.42, accuracy: 0.9587\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 400\n",
      "Epoch: 38\n",
      "[Train]\t J_a: 217.44, accuracy: 1.00\n",
      "[Test]\t J_a: 261.14, accuracy: 0.9601\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 400\n",
      "Epoch: 39\n",
      "[Train]\t J_a: 217.38, accuracy: 1.00\n",
      "[Test]\t J_a: 260.86, accuracy: 0.9602\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 400\n",
      "Epoch: 40\n",
      "[Train]\t J_a: 217.82, accuracy: 1.00\n",
      "[Test]\t J_a: 260.01, accuracy: 0.9656\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 400\n",
      "Epoch: 41\n",
      "[Train]\t J_a: 216.73, accuracy: 1.00\n",
      "[Test]\t J_a: 260.30, accuracy: 0.9633\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 400\n",
      "Epoch: 42\n",
      "[Train]\t J_a: 216.48, accuracy: 1.00\n",
      "[Test]\t J_a: 260.15, accuracy: 0.9638\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 400\n",
      "Epoch: 43\n",
      "[Train]\t J_a: 216.27, accuracy: 1.00\n",
      "[Test]\t J_a: 259.75, accuracy: 0.9632\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 400\n",
      "Epoch: 44\n",
      "[Train]\t J_a: 216.12, accuracy: 1.00\n",
      "[Test]\t J_a: 260.15, accuracy: 0.9628\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 400\n",
      "Epoch: 45\n",
      "[Train]\t J_a: 216.08, accuracy: 1.00\n",
      "[Test]\t J_a: 259.65, accuracy: 0.9662\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 400\n",
      "Epoch: 46\n",
      "[Train]\t J_a: 215.65, accuracy: 1.00\n",
      "[Test]\t J_a: 259.81, accuracy: 0.9659\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 400\n",
      "Epoch: 47\n",
      "[Train]\t J_a: 215.47, accuracy: 1.00\n",
      "[Test]\t J_a: 259.61, accuracy: 0.9651\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 400\n",
      "Epoch: 48\n",
      "[Train]\t J_a: 215.31, accuracy: 1.00\n",
      "[Test]\t J_a: 259.82, accuracy: 0.9631\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 400\n",
      "Epoch: 49\n",
      "[Train]\t J_a: 215.41, accuracy: 1.00\n",
      "[Test]\t J_a: 260.69, accuracy: 0.9610\n",
      "./saved_data/MNIST_X_train_labelled_bald_100_111.pt\n",
      "./saved_data/MNIST_y_train_labelled_bald_100_111.pt\n",
      "400 400\n",
      "./saved_data/MNIST_X_train_unlabelled_bald_100_111.pt\n",
      "./saved_data/MNIST_y_train_unlabelled_bald_100_111.pt\n",
      "59600 59600\n",
      "./saved_data/MNIST_X_test_111.pt\n",
      "./saved_data/MNIST_y_test_111.pt\n",
      "10000 10000\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 400\n",
      "Epoch: 0\n",
      "[Train]\t J_a: 404.06, accuracy: 0.89\n",
      "[Test]\t J_a: 316.17, accuracy: 0.9430\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 400\n",
      "Epoch: 1\n",
      "[Train]\t J_a: 317.68, accuracy: 0.99\n",
      "[Test]\t J_a: 297.11, accuracy: 0.9419\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 400\n",
      "Epoch: 2\n",
      "[Train]\t J_a: 298.86, accuracy: 0.99\n",
      "[Test]\t J_a: 286.58, accuracy: 0.9519\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 400\n",
      "Epoch: 3\n",
      "[Train]\t J_a: 286.34, accuracy: 0.99\n",
      "[Test]\t J_a: 279.14, accuracy: 0.9588\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 400\n",
      "Epoch: 4\n",
      "[Train]\t J_a: 277.52, accuracy: 0.99\n",
      "[Test]\t J_a: 275.74, accuracy: 0.9580\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 400\n",
      "Epoch: 5\n",
      "[Train]\t J_a: 272.16, accuracy: 0.99\n",
      "[Test]\t J_a: 271.68, accuracy: 0.9622\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 400\n",
      "Epoch: 6\n",
      "[Train]\t J_a: 267.36, accuracy: 1.00\n",
      "[Test]\t J_a: 270.87, accuracy: 0.9623\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 400\n",
      "Epoch: 7\n",
      "[Train]\t J_a: 263.37, accuracy: 1.00\n",
      "[Test]\t J_a: 269.16, accuracy: 0.9581\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 400\n",
      "Epoch: 8\n",
      "[Train]\t J_a: 261.08, accuracy: 1.00\n",
      "[Test]\t J_a: 266.73, accuracy: 0.9645\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 400\n",
      "Epoch: 9\n",
      "[Train]\t J_a: 257.90, accuracy: 1.00\n",
      "[Test]\t J_a: 266.60, accuracy: 0.9633\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 400\n",
      "Epoch: 10\n",
      "[Train]\t J_a: 255.49, accuracy: 1.00\n",
      "[Test]\t J_a: 265.89, accuracy: 0.9638\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 400\n",
      "Epoch: 11\n",
      "[Train]\t J_a: 253.52, accuracy: 1.00\n",
      "[Test]\t J_a: 264.82, accuracy: 0.9654\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 400\n",
      "Epoch: 12\n",
      "[Train]\t J_a: 251.11, accuracy: 1.00\n",
      "[Test]\t J_a: 264.42, accuracy: 0.9675\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 400\n",
      "Epoch: 13\n",
      "[Train]\t J_a: 248.39, accuracy: 1.00\n",
      "[Test]\t J_a: 264.23, accuracy: 0.9677\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 400\n",
      "Epoch: 14\n",
      "[Train]\t J_a: 247.01, accuracy: 1.00\n",
      "[Test]\t J_a: 263.67, accuracy: 0.9687\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 400\n",
      "Epoch: 15\n",
      "[Train]\t J_a: 246.09, accuracy: 1.00\n",
      "[Test]\t J_a: 264.27, accuracy: 0.9687\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 400\n",
      "Epoch: 16\n",
      "[Train]\t J_a: 245.03, accuracy: 1.00\n",
      "[Test]\t J_a: 263.40, accuracy: 0.9708\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 400\n",
      "Epoch: 17\n",
      "[Train]\t J_a: 243.74, accuracy: 1.00\n",
      "[Test]\t J_a: 264.36, accuracy: 0.9708\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 400\n",
      "Epoch: 18\n",
      "[Train]\t J_a: 241.11, accuracy: 1.00\n",
      "[Test]\t J_a: 263.11, accuracy: 0.9695\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 400\n",
      "Epoch: 19\n",
      "[Train]\t J_a: 241.57, accuracy: 1.00\n",
      "[Test]\t J_a: 263.76, accuracy: 0.9678\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 400\n",
      "Epoch: 20\n",
      "[Train]\t J_a: 240.50, accuracy: 1.00\n",
      "[Test]\t J_a: 262.86, accuracy: 0.9686\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 400\n",
      "Epoch: 21\n",
      "[Train]\t J_a: 240.05, accuracy: 1.00\n",
      "[Test]\t J_a: 263.51, accuracy: 0.9686\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 400\n",
      "Epoch: 22\n",
      "[Train]\t J_a: 239.13, accuracy: 1.00\n",
      "[Test]\t J_a: 263.06, accuracy: 0.9717\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 400\n",
      "Epoch: 23\n",
      "[Train]\t J_a: 238.59, accuracy: 1.00\n",
      "[Test]\t J_a: 263.63, accuracy: 0.9714\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 400\n",
      "Epoch: 24\n",
      "[Train]\t J_a: 237.79, accuracy: 1.00\n",
      "[Test]\t J_a: 263.89, accuracy: 0.9688\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 400\n",
      "Epoch: 25\n",
      "[Train]\t J_a: 237.32, accuracy: 1.00\n",
      "[Test]\t J_a: 263.14, accuracy: 0.9720\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 400\n",
      "Epoch: 26\n",
      "[Train]\t J_a: 235.74, accuracy: 1.00\n",
      "[Test]\t J_a: 262.79, accuracy: 0.9725\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 400\n",
      "Epoch: 27\n",
      "[Train]\t J_a: 235.57, accuracy: 1.00\n",
      "[Test]\t J_a: 262.57, accuracy: 0.9719\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 400\n",
      "Epoch: 28\n",
      "[Train]\t J_a: 236.65, accuracy: 1.00\n",
      "[Test]\t J_a: 263.12, accuracy: 0.9703\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 400\n",
      "Epoch: 29\n",
      "[Train]\t J_a: 235.16, accuracy: 1.00\n",
      "[Test]\t J_a: 262.82, accuracy: 0.9727\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 400\n",
      "Epoch: 30\n",
      "[Train]\t J_a: 234.50, accuracy: 1.00\n",
      "[Test]\t J_a: 263.32, accuracy: 0.9714\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 400\n",
      "Epoch: 31\n",
      "[Train]\t J_a: 233.96, accuracy: 1.00\n",
      "[Test]\t J_a: 263.02, accuracy: 0.9734\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 400\n",
      "Epoch: 32\n",
      "[Train]\t J_a: 233.40, accuracy: 1.00\n",
      "[Test]\t J_a: 263.21, accuracy: 0.9736\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 400\n",
      "Epoch: 33\n",
      "[Train]\t J_a: 232.71, accuracy: 1.00\n",
      "[Test]\t J_a: 263.20, accuracy: 0.9736\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 400\n",
      "Epoch: 34\n",
      "[Train]\t J_a: 233.28, accuracy: 1.00\n",
      "[Test]\t J_a: 262.05, accuracy: 0.9756\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 400\n",
      "Epoch: 35\n",
      "[Train]\t J_a: 232.05, accuracy: 1.00\n",
      "[Test]\t J_a: 262.98, accuracy: 0.9743\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 400\n",
      "Epoch: 36\n",
      "[Train]\t J_a: 233.04, accuracy: 1.00\n",
      "[Test]\t J_a: 263.18, accuracy: 0.9740\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 400\n",
      "Epoch: 37\n",
      "[Train]\t J_a: 231.11, accuracy: 1.00\n",
      "[Test]\t J_a: 263.72, accuracy: 0.9723\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 400\n",
      "Epoch: 38\n",
      "[Train]\t J_a: 231.69, accuracy: 1.00\n",
      "[Test]\t J_a: 262.83, accuracy: 0.9721\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 400\n",
      "Epoch: 39\n",
      "[Train]\t J_a: 231.43, accuracy: 1.00\n",
      "[Test]\t J_a: 262.62, accuracy: 0.9744\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 400\n",
      "Epoch: 40\n",
      "[Train]\t J_a: 230.58, accuracy: 1.00\n",
      "[Test]\t J_a: 262.23, accuracy: 0.9749\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 400\n",
      "Epoch: 41\n",
      "[Train]\t J_a: 230.20, accuracy: 1.00\n",
      "[Test]\t J_a: 262.91, accuracy: 0.9739\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 400\n",
      "Epoch: 42\n",
      "[Train]\t J_a: 230.77, accuracy: 1.00\n",
      "[Test]\t J_a: 263.29, accuracy: 0.9739\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 400\n",
      "Epoch: 43\n",
      "[Train]\t J_a: 230.67, accuracy: 1.00\n",
      "[Test]\t J_a: 263.17, accuracy: 0.9732\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 400\n",
      "Epoch: 44\n",
      "[Train]\t J_a: 229.81, accuracy: 1.00\n",
      "[Test]\t J_a: 262.19, accuracy: 0.9754\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 400\n",
      "Epoch: 45\n",
      "[Train]\t J_a: 229.46, accuracy: 1.00\n",
      "[Test]\t J_a: 262.97, accuracy: 0.9739\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 400\n",
      "Epoch: 46\n",
      "[Train]\t J_a: 229.01, accuracy: 1.00\n",
      "[Test]\t J_a: 262.91, accuracy: 0.9742\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 400\n",
      "Epoch: 47\n",
      "[Train]\t J_a: 229.47, accuracy: 1.00\n",
      "[Test]\t J_a: 262.23, accuracy: 0.9742\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 400\n",
      "Epoch: 48\n",
      "[Train]\t J_a: 229.43, accuracy: 1.00\n",
      "[Test]\t J_a: 262.96, accuracy: 0.9727\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 400\n",
      "Epoch: 49\n",
      "[Train]\t J_a: 228.12, accuracy: 1.00\n",
      "[Test]\t J_a: 263.64, accuracy: 0.9727\n",
      "./saved_data/MNIST_X_train_labelled_random_100_111.pt\n",
      "./saved_data/MNIST_y_train_labelled_random_100_111.pt\n",
      "500 500\n",
      "./saved_data/MNIST_X_train_unlabelled_random_100_111.pt\n",
      "./saved_data/MNIST_y_train_unlabelled_random_100_111.pt\n",
      "59500 59500\n",
      "./saved_data/MNIST_X_test_111.pt\n",
      "./saved_data/MNIST_y_test_111.pt\n",
      "10000 10000\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 500\n",
      "Epoch: 0\n",
      "[Train]\t J_a: 377.44, accuracy: 0.93\n",
      "[Test]\t J_a: 311.73, accuracy: 0.9164\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 500\n",
      "Epoch: 1\n",
      "[Train]\t J_a: 292.76, accuracy: 0.99\n",
      "[Test]\t J_a: 290.41, accuracy: 0.9330\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 500\n",
      "Epoch: 2\n",
      "[Train]\t J_a: 274.61, accuracy: 1.00\n",
      "[Test]\t J_a: 280.22, accuracy: 0.9313\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 500\n",
      "Epoch: 3\n",
      "[Train]\t J_a: 263.80, accuracy: 1.00\n",
      "[Test]\t J_a: 273.65, accuracy: 0.9376\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 500\n",
      "Epoch: 4\n",
      "[Train]\t J_a: 256.48, accuracy: 1.00\n",
      "[Test]\t J_a: 269.53, accuracy: 0.9412\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 500\n",
      "Epoch: 5\n",
      "[Train]\t J_a: 251.03, accuracy: 1.00\n",
      "[Test]\t J_a: 266.79, accuracy: 0.9425\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 500\n",
      "Epoch: 6\n",
      "[Train]\t J_a: 247.36, accuracy: 1.00\n",
      "[Test]\t J_a: 263.79, accuracy: 0.9453\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 500\n",
      "Epoch: 7\n",
      "[Train]\t J_a: 244.32, accuracy: 1.00\n",
      "[Test]\t J_a: 263.54, accuracy: 0.9485\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 500\n",
      "Epoch: 8\n",
      "[Train]\t J_a: 241.41, accuracy: 1.00\n",
      "[Test]\t J_a: 261.71, accuracy: 0.9485\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 500\n",
      "Epoch: 9\n",
      "[Train]\t J_a: 239.32, accuracy: 1.00\n",
      "[Test]\t J_a: 260.89, accuracy: 0.9486\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 500\n",
      "Epoch: 10\n",
      "[Train]\t J_a: 237.56, accuracy: 1.00\n",
      "[Test]\t J_a: 259.58, accuracy: 0.9516\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 500\n",
      "Epoch: 11\n",
      "[Train]\t J_a: 236.44, accuracy: 1.00\n",
      "[Test]\t J_a: 258.61, accuracy: 0.9520\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 500\n",
      "Epoch: 12\n",
      "[Train]\t J_a: 234.78, accuracy: 1.00\n",
      "[Test]\t J_a: 258.74, accuracy: 0.9523\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 500\n",
      "Epoch: 13\n",
      "[Train]\t J_a: 233.56, accuracy: 1.00\n",
      "[Test]\t J_a: 258.42, accuracy: 0.9550\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 500\n",
      "Epoch: 14\n",
      "[Train]\t J_a: 232.32, accuracy: 1.00\n",
      "[Test]\t J_a: 257.96, accuracy: 0.9564\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 500\n",
      "Epoch: 15\n",
      "[Train]\t J_a: 231.92, accuracy: 1.00\n",
      "[Test]\t J_a: 258.25, accuracy: 0.9559\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 500\n",
      "Epoch: 16\n",
      "[Train]\t J_a: 230.64, accuracy: 1.00\n",
      "[Test]\t J_a: 257.30, accuracy: 0.9581\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 500\n",
      "Epoch: 17\n",
      "[Train]\t J_a: 230.19, accuracy: 1.00\n",
      "[Test]\t J_a: 257.02, accuracy: 0.9601\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 500\n",
      "Epoch: 18\n",
      "[Train]\t J_a: 229.54, accuracy: 1.00\n",
      "[Test]\t J_a: 257.18, accuracy: 0.9593\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 500\n",
      "Epoch: 19\n",
      "[Train]\t J_a: 228.83, accuracy: 1.00\n",
      "[Test]\t J_a: 256.60, accuracy: 0.9583\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 500\n",
      "Epoch: 20\n",
      "[Train]\t J_a: 228.20, accuracy: 1.00\n",
      "[Test]\t J_a: 256.33, accuracy: 0.9579\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 500\n",
      "Epoch: 21\n",
      "[Train]\t J_a: 227.40, accuracy: 1.00\n",
      "[Test]\t J_a: 256.43, accuracy: 0.9585\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 500\n",
      "Epoch: 22\n",
      "[Train]\t J_a: 227.10, accuracy: 1.00\n",
      "[Test]\t J_a: 256.05, accuracy: 0.9622\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 500\n",
      "Epoch: 23\n",
      "[Train]\t J_a: 226.55, accuracy: 1.00\n",
      "[Test]\t J_a: 256.49, accuracy: 0.9619\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 500\n",
      "Epoch: 24\n",
      "[Train]\t J_a: 225.95, accuracy: 1.00\n",
      "[Test]\t J_a: 256.10, accuracy: 0.9618\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 500\n",
      "Epoch: 25\n",
      "[Train]\t J_a: 226.04, accuracy: 1.00\n",
      "[Test]\t J_a: 256.38, accuracy: 0.9611\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 500\n",
      "Epoch: 26\n",
      "[Train]\t J_a: 224.96, accuracy: 1.00\n",
      "[Test]\t J_a: 256.35, accuracy: 0.9598\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 500\n",
      "Epoch: 27\n",
      "[Train]\t J_a: 224.82, accuracy: 1.00\n",
      "[Test]\t J_a: 255.88, accuracy: 0.9611\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 500\n",
      "Epoch: 28\n",
      "[Train]\t J_a: 224.78, accuracy: 1.00\n",
      "[Test]\t J_a: 255.52, accuracy: 0.9607\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 500\n",
      "Epoch: 29\n",
      "[Train]\t J_a: 224.63, accuracy: 1.00\n",
      "[Test]\t J_a: 255.47, accuracy: 0.9609\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 500\n",
      "Epoch: 30\n",
      "[Train]\t J_a: 224.26, accuracy: 1.00\n",
      "[Test]\t J_a: 255.64, accuracy: 0.9637\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 500\n",
      "Epoch: 31\n",
      "[Train]\t J_a: 223.17, accuracy: 1.00\n",
      "[Test]\t J_a: 255.72, accuracy: 0.9602\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 500\n",
      "Epoch: 32\n",
      "[Train]\t J_a: 223.01, accuracy: 1.00\n",
      "[Test]\t J_a: 255.84, accuracy: 0.9623\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 500\n",
      "Epoch: 33\n",
      "[Train]\t J_a: 223.16, accuracy: 1.00\n",
      "[Test]\t J_a: 255.30, accuracy: 0.9629\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 500\n",
      "Epoch: 34\n",
      "[Train]\t J_a: 222.80, accuracy: 1.00\n",
      "[Test]\t J_a: 255.41, accuracy: 0.9636\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 500\n",
      "Epoch: 35\n",
      "[Train]\t J_a: 222.36, accuracy: 1.00\n",
      "[Test]\t J_a: 255.30, accuracy: 0.9641\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 500\n",
      "Epoch: 36\n",
      "[Train]\t J_a: 222.00, accuracy: 1.00\n",
      "[Test]\t J_a: 255.72, accuracy: 0.9645\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 500\n",
      "Epoch: 37\n",
      "[Train]\t J_a: 222.07, accuracy: 1.00\n",
      "[Test]\t J_a: 255.85, accuracy: 0.9607\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 500\n",
      "Epoch: 38\n",
      "[Train]\t J_a: 222.21, accuracy: 1.00\n",
      "[Test]\t J_a: 256.11, accuracy: 0.9643\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 500\n",
      "Epoch: 39\n",
      "[Train]\t J_a: 221.73, accuracy: 1.00\n",
      "[Test]\t J_a: 255.49, accuracy: 0.9664\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 500\n",
      "Epoch: 40\n",
      "[Train]\t J_a: 221.09, accuracy: 1.00\n",
      "[Test]\t J_a: 255.00, accuracy: 0.9646\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 500\n",
      "Epoch: 41\n",
      "[Train]\t J_a: 221.29, accuracy: 1.00\n",
      "[Test]\t J_a: 255.19, accuracy: 0.9660\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 500\n",
      "Epoch: 42\n",
      "[Train]\t J_a: 220.70, accuracy: 1.00\n",
      "[Test]\t J_a: 255.69, accuracy: 0.9618\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 500\n",
      "Epoch: 43\n",
      "[Train]\t J_a: 220.83, accuracy: 1.00\n",
      "[Test]\t J_a: 255.49, accuracy: 0.9628\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 500\n",
      "Epoch: 44\n",
      "[Train]\t J_a: 220.51, accuracy: 1.00\n",
      "[Test]\t J_a: 254.81, accuracy: 0.9669\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 500\n",
      "Epoch: 45\n",
      "[Train]\t J_a: 219.94, accuracy: 1.00\n",
      "[Test]\t J_a: 254.82, accuracy: 0.9680\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 500\n",
      "Epoch: 46\n",
      "[Train]\t J_a: 220.29, accuracy: 1.00\n",
      "[Test]\t J_a: 255.20, accuracy: 0.9650\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 500\n",
      "Epoch: 47\n",
      "[Train]\t J_a: 219.92, accuracy: 1.00\n",
      "[Test]\t J_a: 255.38, accuracy: 0.9637\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 500\n",
      "Epoch: 48\n",
      "[Train]\t J_a: 219.98, accuracy: 1.00\n",
      "[Test]\t J_a: 255.26, accuracy: 0.9682\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 500\n",
      "Epoch: 49\n",
      "[Train]\t J_a: 219.68, accuracy: 1.00\n",
      "[Test]\t J_a: 255.63, accuracy: 0.9688\n",
      "./saved_data/MNIST_X_train_labelled_bald_100_111.pt\n",
      "./saved_data/MNIST_y_train_labelled_bald_100_111.pt\n",
      "500 500\n",
      "./saved_data/MNIST_X_train_unlabelled_bald_100_111.pt\n",
      "./saved_data/MNIST_y_train_unlabelled_bald_100_111.pt\n",
      "59500 59500\n",
      "./saved_data/MNIST_X_test_111.pt\n",
      "./saved_data/MNIST_y_test_111.pt\n",
      "10000 10000\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 500\n",
      "Epoch: 0\n",
      "[Train]\t J_a: 402.60, accuracy: 0.84\n",
      "[Test]\t J_a: 314.23, accuracy: 0.9464\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 500\n",
      "Epoch: 1\n",
      "[Train]\t J_a: 318.25, accuracy: 0.98\n",
      "[Test]\t J_a: 291.80, accuracy: 0.9575\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 500\n",
      "Epoch: 2\n",
      "[Train]\t J_a: 299.79, accuracy: 0.99\n",
      "[Test]\t J_a: 282.11, accuracy: 0.9605\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 500\n",
      "Epoch: 3\n",
      "[Train]\t J_a: 289.06, accuracy: 0.99\n",
      "[Test]\t J_a: 275.34, accuracy: 0.9636\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 500\n",
      "Epoch: 4\n",
      "[Train]\t J_a: 281.92, accuracy: 0.99\n",
      "[Test]\t J_a: 271.12, accuracy: 0.9674\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 500\n",
      "Epoch: 5\n",
      "[Train]\t J_a: 275.88, accuracy: 0.99\n",
      "[Test]\t J_a: 268.71, accuracy: 0.9652\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 500\n",
      "Epoch: 6\n",
      "[Train]\t J_a: 272.00, accuracy: 0.99\n",
      "[Test]\t J_a: 265.83, accuracy: 0.9665\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 500\n",
      "Epoch: 7\n",
      "[Train]\t J_a: 268.03, accuracy: 0.99\n",
      "[Test]\t J_a: 264.43, accuracy: 0.9685\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 500\n",
      "Epoch: 8\n",
      "[Train]\t J_a: 265.07, accuracy: 0.99\n",
      "[Test]\t J_a: 263.44, accuracy: 0.9684\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 500\n",
      "Epoch: 9\n",
      "[Train]\t J_a: 262.27, accuracy: 1.00\n",
      "[Test]\t J_a: 262.43, accuracy: 0.9710\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 500\n",
      "Epoch: 10\n",
      "[Train]\t J_a: 260.37, accuracy: 1.00\n",
      "[Test]\t J_a: 261.34, accuracy: 0.9717\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 500\n",
      "Epoch: 11\n",
      "[Train]\t J_a: 258.25, accuracy: 1.00\n",
      "[Test]\t J_a: 260.89, accuracy: 0.9715\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 500\n",
      "Epoch: 12\n",
      "[Train]\t J_a: 256.36, accuracy: 1.00\n",
      "[Test]\t J_a: 260.42, accuracy: 0.9720\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 500\n",
      "Epoch: 13\n",
      "[Train]\t J_a: 255.09, accuracy: 1.00\n",
      "[Test]\t J_a: 260.63, accuracy: 0.9715\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 500\n",
      "Epoch: 14\n",
      "[Train]\t J_a: 253.42, accuracy: 1.00\n",
      "[Test]\t J_a: 259.72, accuracy: 0.9713\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 500\n",
      "Epoch: 15\n",
      "[Train]\t J_a: 251.79, accuracy: 1.00\n",
      "[Test]\t J_a: 259.35, accuracy: 0.9712\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 500\n",
      "Epoch: 16\n",
      "[Train]\t J_a: 250.96, accuracy: 1.00\n",
      "[Test]\t J_a: 259.57, accuracy: 0.9717\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 500\n",
      "Epoch: 17\n",
      "[Train]\t J_a: 249.54, accuracy: 1.00\n",
      "[Test]\t J_a: 259.70, accuracy: 0.9712\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 500\n",
      "Epoch: 18\n",
      "[Train]\t J_a: 248.69, accuracy: 1.00\n",
      "[Test]\t J_a: 259.19, accuracy: 0.9726\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 500\n",
      "Epoch: 19\n",
      "[Train]\t J_a: 247.82, accuracy: 1.00\n",
      "[Test]\t J_a: 258.91, accuracy: 0.9740\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 500\n",
      "Epoch: 20\n",
      "[Train]\t J_a: 247.11, accuracy: 1.00\n",
      "[Test]\t J_a: 258.91, accuracy: 0.9754\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 500\n",
      "Epoch: 21\n",
      "[Train]\t J_a: 245.67, accuracy: 1.00\n",
      "[Test]\t J_a: 259.41, accuracy: 0.9739\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 500\n",
      "Epoch: 22\n",
      "[Train]\t J_a: 245.30, accuracy: 1.00\n",
      "[Test]\t J_a: 258.66, accuracy: 0.9762\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 500\n",
      "Epoch: 23\n",
      "[Train]\t J_a: 244.83, accuracy: 1.00\n",
      "[Test]\t J_a: 258.97, accuracy: 0.9748\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 500\n",
      "Epoch: 24\n",
      "[Train]\t J_a: 244.26, accuracy: 1.00\n",
      "[Test]\t J_a: 259.23, accuracy: 0.9715\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 500\n",
      "Epoch: 25\n",
      "[Train]\t J_a: 243.91, accuracy: 1.00\n",
      "[Test]\t J_a: 258.50, accuracy: 0.9765\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 500\n",
      "Epoch: 26\n",
      "[Train]\t J_a: 242.91, accuracy: 1.00\n",
      "[Test]\t J_a: 258.69, accuracy: 0.9752\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 500\n",
      "Epoch: 27\n",
      "[Train]\t J_a: 242.07, accuracy: 1.00\n",
      "[Test]\t J_a: 258.29, accuracy: 0.9788\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 500\n",
      "Epoch: 28\n",
      "[Train]\t J_a: 241.99, accuracy: 1.00\n",
      "[Test]\t J_a: 258.45, accuracy: 0.9749\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 500\n",
      "Epoch: 29\n",
      "[Train]\t J_a: 241.14, accuracy: 1.00\n",
      "[Test]\t J_a: 258.59, accuracy: 0.9771\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 500\n",
      "Epoch: 30\n",
      "[Train]\t J_a: 240.98, accuracy: 1.00\n",
      "[Test]\t J_a: 258.53, accuracy: 0.9785\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 500\n",
      "Epoch: 31\n",
      "[Train]\t J_a: 240.66, accuracy: 1.00\n",
      "[Test]\t J_a: 258.67, accuracy: 0.9790\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 500\n",
      "Epoch: 32\n",
      "[Train]\t J_a: 239.99, accuracy: 1.00\n",
      "[Test]\t J_a: 258.46, accuracy: 0.9782\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 500\n",
      "Epoch: 33\n",
      "[Train]\t J_a: 239.94, accuracy: 1.00\n",
      "[Test]\t J_a: 258.79, accuracy: 0.9777\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 500\n",
      "Epoch: 34\n",
      "[Train]\t J_a: 239.31, accuracy: 1.00\n",
      "[Test]\t J_a: 258.83, accuracy: 0.9748\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 500\n",
      "Epoch: 35\n",
      "[Train]\t J_a: 239.06, accuracy: 1.00\n",
      "[Test]\t J_a: 258.66, accuracy: 0.9737\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 500\n",
      "Epoch: 36\n",
      "[Train]\t J_a: 238.98, accuracy: 1.00\n",
      "[Test]\t J_a: 258.81, accuracy: 0.9767\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 500\n",
      "Epoch: 37\n",
      "[Train]\t J_a: 238.58, accuracy: 1.00\n",
      "[Test]\t J_a: 258.72, accuracy: 0.9768\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 500\n",
      "Epoch: 38\n",
      "[Train]\t J_a: 238.31, accuracy: 1.00\n",
      "[Test]\t J_a: 258.70, accuracy: 0.9795\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 500\n",
      "Epoch: 39\n",
      "[Train]\t J_a: 238.17, accuracy: 1.00\n",
      "[Test]\t J_a: 258.55, accuracy: 0.9774\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 500\n",
      "Epoch: 40\n",
      "[Train]\t J_a: 238.12, accuracy: 1.00\n",
      "[Test]\t J_a: 258.67, accuracy: 0.9764\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 500\n",
      "Epoch: 41\n",
      "[Train]\t J_a: 237.43, accuracy: 1.00\n",
      "[Test]\t J_a: 259.26, accuracy: 0.9777\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 500\n",
      "Epoch: 42\n",
      "[Train]\t J_a: 236.97, accuracy: 1.00\n",
      "[Test]\t J_a: 258.24, accuracy: 0.9808\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 500\n",
      "Epoch: 43\n",
      "[Train]\t J_a: 236.66, accuracy: 1.00\n",
      "[Test]\t J_a: 258.73, accuracy: 0.9785\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 500\n",
      "Epoch: 44\n",
      "[Train]\t J_a: 236.26, accuracy: 1.00\n",
      "[Test]\t J_a: 258.29, accuracy: 0.9783\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 500\n",
      "Epoch: 45\n",
      "[Train]\t J_a: 236.38, accuracy: 1.00\n",
      "[Test]\t J_a: 259.15, accuracy: 0.9766\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 500\n",
      "Epoch: 46\n",
      "[Train]\t J_a: 236.46, accuracy: 1.00\n",
      "[Test]\t J_a: 258.95, accuracy: 0.9782\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 500\n",
      "Epoch: 47\n",
      "[Train]\t J_a: 235.80, accuracy: 1.00\n",
      "[Test]\t J_a: 258.56, accuracy: 0.9770\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 500\n",
      "Epoch: 48\n",
      "[Train]\t J_a: 235.87, accuracy: 1.00\n",
      "[Test]\t J_a: 258.33, accuracy: 0.9788\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 500\n",
      "Epoch: 49\n",
      "[Train]\t J_a: 235.45, accuracy: 1.00\n",
      "[Test]\t J_a: 258.84, accuracy: 0.9778\n",
      "./saved_data/MNIST_X_train_labelled_random_100_111.pt\n",
      "./saved_data/MNIST_y_train_labelled_random_100_111.pt\n",
      "600 600\n",
      "./saved_data/MNIST_X_train_unlabelled_random_100_111.pt\n",
      "./saved_data/MNIST_y_train_unlabelled_random_100_111.pt\n",
      "59400 59400\n",
      "./saved_data/MNIST_X_test_111.pt\n",
      "./saved_data/MNIST_y_test_111.pt\n",
      "10000 10000\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 600\n",
      "Epoch: 0\n",
      "[Train]\t J_a: 377.03, accuracy: 0.93\n",
      "[Test]\t J_a: 311.43, accuracy: 0.9201\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 600\n",
      "Epoch: 1\n",
      "[Train]\t J_a: 294.07, accuracy: 0.99\n",
      "[Test]\t J_a: 289.04, accuracy: 0.9340\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 600\n",
      "Epoch: 2\n",
      "[Train]\t J_a: 276.47, accuracy: 0.99\n",
      "[Test]\t J_a: 278.44, accuracy: 0.9395\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 600\n",
      "Epoch: 3\n",
      "[Train]\t J_a: 264.72, accuracy: 1.00\n",
      "[Test]\t J_a: 272.04, accuracy: 0.9408\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 600\n",
      "Epoch: 4\n",
      "[Train]\t J_a: 258.53, accuracy: 1.00\n",
      "[Test]\t J_a: 267.99, accuracy: 0.9439\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 600\n",
      "Epoch: 5\n",
      "[Train]\t J_a: 253.09, accuracy: 1.00\n",
      "[Test]\t J_a: 264.99, accuracy: 0.9442\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 600\n",
      "Epoch: 6\n",
      "[Train]\t J_a: 249.52, accuracy: 1.00\n",
      "[Test]\t J_a: 262.57, accuracy: 0.9476\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 600\n",
      "Epoch: 7\n",
      "[Train]\t J_a: 246.17, accuracy: 1.00\n",
      "[Test]\t J_a: 260.76, accuracy: 0.9464\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 600\n",
      "Epoch: 8\n",
      "[Train]\t J_a: 243.86, accuracy: 1.00\n",
      "[Test]\t J_a: 260.07, accuracy: 0.9488\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 600\n",
      "Epoch: 9\n",
      "[Train]\t J_a: 241.78, accuracy: 1.00\n",
      "[Test]\t J_a: 257.86, accuracy: 0.9499\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 600\n",
      "Epoch: 10\n",
      "[Train]\t J_a: 239.95, accuracy: 1.00\n",
      "[Test]\t J_a: 257.34, accuracy: 0.9511\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 600\n",
      "Epoch: 11\n",
      "[Train]\t J_a: 238.39, accuracy: 1.00\n",
      "[Test]\t J_a: 256.96, accuracy: 0.9522\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 600\n",
      "Epoch: 12\n",
      "[Train]\t J_a: 236.84, accuracy: 1.00\n",
      "[Test]\t J_a: 257.20, accuracy: 0.9509\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 600\n",
      "Epoch: 13\n",
      "[Train]\t J_a: 235.64, accuracy: 1.00\n",
      "[Test]\t J_a: 256.10, accuracy: 0.9553\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 600\n",
      "Epoch: 14\n",
      "[Train]\t J_a: 234.18, accuracy: 1.00\n",
      "[Test]\t J_a: 255.61, accuracy: 0.9549\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 600\n",
      "Epoch: 15\n",
      "[Train]\t J_a: 234.21, accuracy: 1.00\n",
      "[Test]\t J_a: 255.90, accuracy: 0.9545\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 600\n",
      "Epoch: 16\n",
      "[Train]\t J_a: 232.90, accuracy: 1.00\n",
      "[Test]\t J_a: 254.81, accuracy: 0.9564\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 600\n",
      "Epoch: 17\n",
      "[Train]\t J_a: 232.35, accuracy: 1.00\n",
      "[Test]\t J_a: 255.17, accuracy: 0.9564\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 600\n",
      "Epoch: 18\n",
      "[Train]\t J_a: 231.58, accuracy: 1.00\n",
      "[Test]\t J_a: 255.09, accuracy: 0.9611\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 600\n",
      "Epoch: 19\n",
      "[Train]\t J_a: 230.92, accuracy: 1.00\n",
      "[Test]\t J_a: 254.06, accuracy: 0.9608\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 600\n",
      "Epoch: 20\n",
      "[Train]\t J_a: 230.39, accuracy: 1.00\n",
      "[Test]\t J_a: 254.87, accuracy: 0.9567\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 600\n",
      "Epoch: 21\n",
      "[Train]\t J_a: 230.40, accuracy: 1.00\n",
      "[Test]\t J_a: 254.72, accuracy: 0.9568\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 600\n",
      "Epoch: 22\n",
      "[Train]\t J_a: 229.27, accuracy: 1.00\n",
      "[Test]\t J_a: 253.94, accuracy: 0.9576\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 600\n",
      "Epoch: 23\n",
      "[Train]\t J_a: 228.39, accuracy: 1.00\n",
      "[Test]\t J_a: 254.16, accuracy: 0.9608\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 600\n",
      "Epoch: 24\n",
      "[Train]\t J_a: 228.53, accuracy: 1.00\n",
      "[Test]\t J_a: 252.75, accuracy: 0.9622\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 600\n",
      "Epoch: 25\n",
      "[Train]\t J_a: 228.38, accuracy: 1.00\n",
      "[Test]\t J_a: 254.03, accuracy: 0.9602\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 600\n",
      "Epoch: 26\n",
      "[Train]\t J_a: 227.34, accuracy: 1.00\n",
      "[Test]\t J_a: 254.12, accuracy: 0.9586\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 600\n",
      "Epoch: 27\n",
      "[Train]\t J_a: 227.16, accuracy: 1.00\n",
      "[Test]\t J_a: 253.11, accuracy: 0.9623\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 600\n",
      "Epoch: 28\n",
      "[Train]\t J_a: 226.99, accuracy: 1.00\n",
      "[Test]\t J_a: 253.33, accuracy: 0.9603\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 600\n",
      "Epoch: 29\n",
      "[Train]\t J_a: 226.54, accuracy: 1.00\n",
      "[Test]\t J_a: 252.70, accuracy: 0.9628\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 600\n",
      "Epoch: 30\n",
      "[Train]\t J_a: 226.38, accuracy: 1.00\n",
      "[Test]\t J_a: 253.35, accuracy: 0.9637\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 600\n",
      "Epoch: 31\n",
      "[Train]\t J_a: 225.93, accuracy: 1.00\n",
      "[Test]\t J_a: 253.28, accuracy: 0.9632\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 600\n",
      "Epoch: 32\n",
      "[Train]\t J_a: 225.33, accuracy: 1.00\n",
      "[Test]\t J_a: 253.23, accuracy: 0.9598\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 600\n",
      "Epoch: 33\n",
      "[Train]\t J_a: 225.85, accuracy: 1.00\n",
      "[Test]\t J_a: 252.85, accuracy: 0.9631\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 600\n",
      "Epoch: 34\n",
      "[Train]\t J_a: 225.17, accuracy: 1.00\n",
      "[Test]\t J_a: 253.20, accuracy: 0.9611\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 600\n",
      "Epoch: 35\n",
      "[Train]\t J_a: 224.71, accuracy: 1.00\n",
      "[Test]\t J_a: 252.96, accuracy: 0.9650\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 600\n",
      "Epoch: 36\n",
      "[Train]\t J_a: 224.86, accuracy: 1.00\n",
      "[Test]\t J_a: 253.11, accuracy: 0.9657\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 600\n",
      "Epoch: 37\n",
      "[Train]\t J_a: 224.66, accuracy: 1.00\n",
      "[Test]\t J_a: 252.55, accuracy: 0.9649\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 600\n",
      "Epoch: 38\n",
      "[Train]\t J_a: 223.89, accuracy: 1.00\n",
      "[Test]\t J_a: 252.55, accuracy: 0.9642\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 600\n",
      "Epoch: 39\n",
      "[Train]\t J_a: 224.21, accuracy: 1.00\n",
      "[Test]\t J_a: 252.74, accuracy: 0.9655\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 600\n",
      "Epoch: 40\n",
      "[Train]\t J_a: 223.99, accuracy: 1.00\n",
      "[Test]\t J_a: 252.25, accuracy: 0.9653\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 600\n",
      "Epoch: 41\n",
      "[Train]\t J_a: 223.65, accuracy: 1.00\n",
      "[Test]\t J_a: 252.73, accuracy: 0.9618\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 600\n",
      "Epoch: 42\n",
      "[Train]\t J_a: 224.27, accuracy: 1.00\n",
      "[Test]\t J_a: 253.36, accuracy: 0.9644\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 600\n",
      "Epoch: 43\n",
      "[Train]\t J_a: 223.51, accuracy: 1.00\n",
      "[Test]\t J_a: 252.51, accuracy: 0.9629\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 600\n",
      "Epoch: 44\n",
      "[Train]\t J_a: 223.20, accuracy: 1.00\n",
      "[Test]\t J_a: 252.86, accuracy: 0.9637\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 600\n",
      "Epoch: 45\n",
      "[Train]\t J_a: 222.78, accuracy: 1.00\n",
      "[Test]\t J_a: 252.82, accuracy: 0.9650\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 600\n",
      "Epoch: 46\n",
      "[Train]\t J_a: 222.93, accuracy: 1.00\n",
      "[Test]\t J_a: 252.72, accuracy: 0.9642\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 600\n",
      "Epoch: 47\n",
      "[Train]\t J_a: 222.36, accuracy: 1.00\n",
      "[Test]\t J_a: 253.02, accuracy: 0.9621\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 600\n",
      "Epoch: 48\n",
      "[Train]\t J_a: 222.58, accuracy: 1.00\n",
      "[Test]\t J_a: 252.42, accuracy: 0.9644\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 600\n",
      "Epoch: 49\n",
      "[Train]\t J_a: 222.43, accuracy: 1.00\n",
      "[Test]\t J_a: 252.90, accuracy: 0.9644\n",
      "./saved_data/MNIST_X_train_labelled_bald_100_111.pt\n",
      "./saved_data/MNIST_y_train_labelled_bald_100_111.pt\n",
      "600 600\n",
      "./saved_data/MNIST_X_train_unlabelled_bald_100_111.pt\n",
      "./saved_data/MNIST_y_train_unlabelled_bald_100_111.pt\n",
      "59400 59400\n",
      "./saved_data/MNIST_X_test_111.pt\n",
      "./saved_data/MNIST_y_test_111.pt\n",
      "10000 10000\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 600\n",
      "Epoch: 0\n",
      "[Train]\t J_a: 401.22, accuracy: 0.83\n",
      "[Test]\t J_a: 312.99, accuracy: 0.9577\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 600\n",
      "Epoch: 1\n",
      "[Train]\t J_a: 321.77, accuracy: 0.98\n",
      "[Test]\t J_a: 294.52, accuracy: 0.9616\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 600\n",
      "Epoch: 2\n",
      "[Train]\t J_a: 303.43, accuracy: 0.99\n",
      "[Test]\t J_a: 282.73, accuracy: 0.9681\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 600\n",
      "Epoch: 3\n",
      "[Train]\t J_a: 293.21, accuracy: 0.99\n",
      "[Test]\t J_a: 276.49, accuracy: 0.9679\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 600\n",
      "Epoch: 4\n",
      "[Train]\t J_a: 285.23, accuracy: 0.99\n",
      "[Test]\t J_a: 271.23, accuracy: 0.9662\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 600\n",
      "Epoch: 5\n",
      "[Train]\t J_a: 279.84, accuracy: 0.99\n",
      "[Test]\t J_a: 267.92, accuracy: 0.9709\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 600\n",
      "Epoch: 6\n",
      "[Train]\t J_a: 275.60, accuracy: 0.99\n",
      "[Test]\t J_a: 265.44, accuracy: 0.9694\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 600\n",
      "Epoch: 7\n",
      "[Train]\t J_a: 271.94, accuracy: 0.99\n",
      "[Test]\t J_a: 263.67, accuracy: 0.9715\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 600\n",
      "Epoch: 8\n",
      "[Train]\t J_a: 269.37, accuracy: 1.00\n",
      "[Test]\t J_a: 261.92, accuracy: 0.9727\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 600\n",
      "Epoch: 9\n",
      "[Train]\t J_a: 267.37, accuracy: 0.99\n",
      "[Test]\t J_a: 260.60, accuracy: 0.9762\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 600\n",
      "Epoch: 10\n",
      "[Train]\t J_a: 263.66, accuracy: 1.00\n",
      "[Test]\t J_a: 260.74, accuracy: 0.9738\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 600\n",
      "Epoch: 11\n",
      "[Train]\t J_a: 262.47, accuracy: 1.00\n",
      "[Test]\t J_a: 259.17, accuracy: 0.9742\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 600\n",
      "Epoch: 12\n",
      "[Train]\t J_a: 260.46, accuracy: 1.00\n",
      "[Test]\t J_a: 258.34, accuracy: 0.9726\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 600\n",
      "Epoch: 13\n",
      "[Train]\t J_a: 259.21, accuracy: 1.00\n",
      "[Test]\t J_a: 258.15, accuracy: 0.9752\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 600\n",
      "Epoch: 14\n",
      "[Train]\t J_a: 257.87, accuracy: 1.00\n",
      "[Test]\t J_a: 257.49, accuracy: 0.9741\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 600\n",
      "Epoch: 15\n",
      "[Train]\t J_a: 256.15, accuracy: 1.00\n",
      "[Test]\t J_a: 257.43, accuracy: 0.9753\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 600\n",
      "Epoch: 16\n",
      "[Train]\t J_a: 255.12, accuracy: 1.00\n",
      "[Test]\t J_a: 256.98, accuracy: 0.9762\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 600\n",
      "Epoch: 17\n",
      "[Train]\t J_a: 254.07, accuracy: 1.00\n",
      "[Test]\t J_a: 256.65, accuracy: 0.9758\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 600\n",
      "Epoch: 18\n",
      "[Train]\t J_a: 252.88, accuracy: 1.00\n",
      "[Test]\t J_a: 256.68, accuracy: 0.9757\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 600\n",
      "Epoch: 19\n",
      "[Train]\t J_a: 251.52, accuracy: 1.00\n",
      "[Test]\t J_a: 256.86, accuracy: 0.9776\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 600\n",
      "Epoch: 20\n",
      "[Train]\t J_a: 251.00, accuracy: 1.00\n",
      "[Test]\t J_a: 255.97, accuracy: 0.9792\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 600\n",
      "Epoch: 21\n",
      "[Train]\t J_a: 250.64, accuracy: 1.00\n",
      "[Test]\t J_a: 256.95, accuracy: 0.9759\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 600\n",
      "Epoch: 22\n",
      "[Train]\t J_a: 249.65, accuracy: 1.00\n",
      "[Test]\t J_a: 255.95, accuracy: 0.9783\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 600\n",
      "Epoch: 23\n",
      "[Train]\t J_a: 248.66, accuracy: 1.00\n",
      "[Test]\t J_a: 255.81, accuracy: 0.9788\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 600\n",
      "Epoch: 24\n",
      "[Train]\t J_a: 247.39, accuracy: 1.00\n",
      "[Test]\t J_a: 255.95, accuracy: 0.9780\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 600\n",
      "Epoch: 25\n",
      "[Train]\t J_a: 247.30, accuracy: 1.00\n",
      "[Test]\t J_a: 256.09, accuracy: 0.9764\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 600\n",
      "Epoch: 26\n",
      "[Train]\t J_a: 246.76, accuracy: 1.00\n",
      "[Test]\t J_a: 255.74, accuracy: 0.9770\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 600\n",
      "Epoch: 27\n",
      "[Train]\t J_a: 246.54, accuracy: 1.00\n",
      "[Test]\t J_a: 256.12, accuracy: 0.9783\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 600\n",
      "Epoch: 28\n",
      "[Train]\t J_a: 245.90, accuracy: 1.00\n",
      "[Test]\t J_a: 255.78, accuracy: 0.9778\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 600\n",
      "Epoch: 29\n",
      "[Train]\t J_a: 245.63, accuracy: 1.00\n",
      "[Test]\t J_a: 255.35, accuracy: 0.9794\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 600\n",
      "Epoch: 30\n",
      "[Train]\t J_a: 245.08, accuracy: 1.00\n",
      "[Test]\t J_a: 255.54, accuracy: 0.9817\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 600\n",
      "Epoch: 31\n",
      "[Train]\t J_a: 244.57, accuracy: 1.00\n",
      "[Test]\t J_a: 255.70, accuracy: 0.9784\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 600\n",
      "Epoch: 32\n",
      "[Train]\t J_a: 244.47, accuracy: 1.00\n",
      "[Test]\t J_a: 255.59, accuracy: 0.9776\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 600\n",
      "Epoch: 33\n",
      "[Train]\t J_a: 243.89, accuracy: 1.00\n",
      "[Test]\t J_a: 255.63, accuracy: 0.9771\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 600\n",
      "Epoch: 34\n",
      "[Train]\t J_a: 243.67, accuracy: 1.00\n",
      "[Test]\t J_a: 255.39, accuracy: 0.9799\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 600\n",
      "Epoch: 35\n",
      "[Train]\t J_a: 242.83, accuracy: 1.00\n",
      "[Test]\t J_a: 255.47, accuracy: 0.9790\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 600\n",
      "Epoch: 36\n",
      "[Train]\t J_a: 242.79, accuracy: 1.00\n",
      "[Test]\t J_a: 255.43, accuracy: 0.9776\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 600\n",
      "Epoch: 37\n",
      "[Train]\t J_a: 241.87, accuracy: 1.00\n",
      "[Test]\t J_a: 255.54, accuracy: 0.9792\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 600\n",
      "Epoch: 38\n",
      "[Train]\t J_a: 242.13, accuracy: 1.00\n",
      "[Test]\t J_a: 255.72, accuracy: 0.9807\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 600\n",
      "Epoch: 39\n",
      "[Train]\t J_a: 241.92, accuracy: 1.00\n",
      "[Test]\t J_a: 255.52, accuracy: 0.9787\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 600\n",
      "Epoch: 40\n",
      "[Train]\t J_a: 241.71, accuracy: 1.00\n",
      "[Test]\t J_a: 255.74, accuracy: 0.9778\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 600\n",
      "Epoch: 41\n",
      "[Train]\t J_a: 240.95, accuracy: 1.00\n",
      "[Test]\t J_a: 256.07, accuracy: 0.9793\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 600\n",
      "Epoch: 42\n",
      "[Train]\t J_a: 241.25, accuracy: 1.00\n",
      "[Test]\t J_a: 256.08, accuracy: 0.9777\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 600\n",
      "Epoch: 43\n",
      "[Train]\t J_a: 241.08, accuracy: 1.00\n",
      "[Test]\t J_a: 255.48, accuracy: 0.9811\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 600\n",
      "Epoch: 44\n",
      "[Train]\t J_a: 240.37, accuracy: 1.00\n",
      "[Test]\t J_a: 255.51, accuracy: 0.9803\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 600\n",
      "Epoch: 45\n",
      "[Train]\t J_a: 240.19, accuracy: 1.00\n",
      "[Test]\t J_a: 255.69, accuracy: 0.9815\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 600\n",
      "Epoch: 46\n",
      "[Train]\t J_a: 240.00, accuracy: 1.00\n",
      "[Test]\t J_a: 255.71, accuracy: 0.9806\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 600\n",
      "Epoch: 47\n",
      "[Train]\t J_a: 240.06, accuracy: 1.00\n",
      "[Test]\t J_a: 255.36, accuracy: 0.9796\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 600\n",
      "Epoch: 48\n",
      "[Train]\t J_a: 239.56, accuracy: 1.00\n",
      "[Test]\t J_a: 255.28, accuracy: 0.9801\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 600\n",
      "Epoch: 49\n",
      "[Train]\t J_a: 239.23, accuracy: 1.00\n",
      "[Test]\t J_a: 255.83, accuracy: 0.9787\n",
      "./saved_data/MNIST_X_train_labelled_random_100_111.pt\n",
      "./saved_data/MNIST_y_train_labelled_random_100_111.pt\n",
      "700 700\n",
      "./saved_data/MNIST_X_train_unlabelled_random_100_111.pt\n",
      "./saved_data/MNIST_y_train_unlabelled_random_100_111.pt\n",
      "59300 59300\n",
      "./saved_data/MNIST_X_test_111.pt\n",
      "./saved_data/MNIST_y_test_111.pt\n",
      "10000 10000\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 700\n",
      "Epoch: 0\n",
      "[Train]\t J_a: 374.80, accuracy: 0.92\n",
      "[Test]\t J_a: 310.35, accuracy: 0.9317\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 700\n",
      "Epoch: 1\n",
      "[Train]\t J_a: 293.80, accuracy: 0.99\n",
      "[Test]\t J_a: 288.63, accuracy: 0.9365\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 700\n",
      "Epoch: 2\n",
      "[Train]\t J_a: 276.18, accuracy: 0.99\n",
      "[Test]\t J_a: 277.36, accuracy: 0.9372\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 700\n",
      "Epoch: 3\n",
      "[Train]\t J_a: 265.78, accuracy: 0.99\n",
      "[Test]\t J_a: 270.59, accuracy: 0.9475\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 700\n",
      "Epoch: 4\n",
      "[Train]\t J_a: 259.27, accuracy: 1.00\n",
      "[Test]\t J_a: 265.58, accuracy: 0.9427\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 700\n",
      "Epoch: 5\n",
      "[Train]\t J_a: 253.91, accuracy: 1.00\n",
      "[Test]\t J_a: 262.67, accuracy: 0.9475\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 700\n",
      "Epoch: 6\n",
      "[Train]\t J_a: 249.75, accuracy: 1.00\n",
      "[Test]\t J_a: 260.86, accuracy: 0.9463\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 700\n",
      "Epoch: 7\n",
      "[Train]\t J_a: 246.79, accuracy: 1.00\n",
      "[Test]\t J_a: 258.46, accuracy: 0.9494\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 700\n",
      "Epoch: 8\n",
      "[Train]\t J_a: 244.52, accuracy: 1.00\n",
      "[Test]\t J_a: 257.49, accuracy: 0.9462\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 700\n",
      "Epoch: 9\n",
      "[Train]\t J_a: 242.33, accuracy: 1.00\n",
      "[Test]\t J_a: 256.74, accuracy: 0.9511\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 700\n",
      "Epoch: 10\n",
      "[Train]\t J_a: 240.69, accuracy: 1.00\n",
      "[Test]\t J_a: 256.26, accuracy: 0.9519\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 700\n",
      "Epoch: 11\n",
      "[Train]\t J_a: 239.47, accuracy: 1.00\n",
      "[Test]\t J_a: 255.72, accuracy: 0.9511\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 700\n",
      "Epoch: 12\n",
      "[Train]\t J_a: 238.17, accuracy: 1.00\n",
      "[Test]\t J_a: 254.36, accuracy: 0.9549\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 700\n",
      "Epoch: 13\n",
      "[Train]\t J_a: 236.69, accuracy: 1.00\n",
      "[Test]\t J_a: 254.09, accuracy: 0.9507\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 700\n",
      "Epoch: 14\n",
      "[Train]\t J_a: 236.07, accuracy: 1.00\n",
      "[Test]\t J_a: 253.09, accuracy: 0.9614\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 700\n",
      "Epoch: 15\n",
      "[Train]\t J_a: 235.14, accuracy: 1.00\n",
      "[Test]\t J_a: 253.50, accuracy: 0.9583\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 700\n",
      "Epoch: 16\n",
      "[Train]\t J_a: 234.20, accuracy: 1.00\n",
      "[Test]\t J_a: 252.96, accuracy: 0.9575\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 700\n",
      "Epoch: 17\n",
      "[Train]\t J_a: 233.67, accuracy: 1.00\n",
      "[Test]\t J_a: 252.60, accuracy: 0.9560\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 700\n",
      "Epoch: 18\n",
      "[Train]\t J_a: 232.95, accuracy: 1.00\n",
      "[Test]\t J_a: 252.27, accuracy: 0.9578\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 700\n",
      "Epoch: 19\n",
      "[Train]\t J_a: 232.14, accuracy: 1.00\n",
      "[Test]\t J_a: 251.89, accuracy: 0.9611\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 700\n",
      "Epoch: 20\n",
      "[Train]\t J_a: 231.54, accuracy: 1.00\n",
      "[Test]\t J_a: 252.00, accuracy: 0.9588\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 700\n",
      "Epoch: 21\n",
      "[Train]\t J_a: 231.09, accuracy: 1.00\n",
      "[Test]\t J_a: 251.74, accuracy: 0.9603\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 700\n",
      "Epoch: 22\n",
      "[Train]\t J_a: 230.68, accuracy: 1.00\n",
      "[Test]\t J_a: 251.12, accuracy: 0.9636\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 700\n",
      "Epoch: 23\n",
      "[Train]\t J_a: 230.38, accuracy: 1.00\n",
      "[Test]\t J_a: 251.22, accuracy: 0.9637\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 700\n",
      "Epoch: 24\n",
      "[Train]\t J_a: 229.80, accuracy: 1.00\n",
      "[Test]\t J_a: 251.01, accuracy: 0.9623\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 700\n",
      "Epoch: 25\n",
      "[Train]\t J_a: 229.43, accuracy: 1.00\n",
      "[Test]\t J_a: 250.88, accuracy: 0.9577\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 700\n",
      "Epoch: 26\n",
      "[Train]\t J_a: 229.09, accuracy: 1.00\n",
      "[Test]\t J_a: 250.64, accuracy: 0.9655\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 700\n",
      "Epoch: 27\n",
      "[Train]\t J_a: 228.74, accuracy: 1.00\n",
      "[Test]\t J_a: 250.89, accuracy: 0.9641\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 700\n",
      "Epoch: 28\n",
      "[Train]\t J_a: 228.42, accuracy: 1.00\n",
      "[Test]\t J_a: 250.78, accuracy: 0.9626\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 700\n",
      "Epoch: 29\n",
      "[Train]\t J_a: 227.98, accuracy: 1.00\n",
      "[Test]\t J_a: 250.73, accuracy: 0.9645\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 700\n",
      "Epoch: 30\n",
      "[Train]\t J_a: 227.71, accuracy: 1.00\n",
      "[Test]\t J_a: 250.82, accuracy: 0.9637\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 700\n",
      "Epoch: 31\n",
      "[Train]\t J_a: 227.24, accuracy: 1.00\n",
      "[Test]\t J_a: 250.68, accuracy: 0.9616\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 700\n",
      "Epoch: 32\n",
      "[Train]\t J_a: 227.32, accuracy: 1.00\n",
      "[Test]\t J_a: 250.19, accuracy: 0.9637\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 700\n",
      "Epoch: 33\n",
      "[Train]\t J_a: 227.00, accuracy: 1.00\n",
      "[Test]\t J_a: 250.41, accuracy: 0.9640\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 700\n",
      "Epoch: 34\n",
      "[Train]\t J_a: 226.91, accuracy: 1.00\n",
      "[Test]\t J_a: 249.81, accuracy: 0.9648\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 700\n",
      "Epoch: 35\n",
      "[Train]\t J_a: 226.68, accuracy: 1.00\n",
      "[Test]\t J_a: 250.57, accuracy: 0.9606\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 700\n",
      "Epoch: 36\n",
      "[Train]\t J_a: 226.38, accuracy: 1.00\n",
      "[Test]\t J_a: 250.53, accuracy: 0.9670\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 700\n",
      "Epoch: 37\n",
      "[Train]\t J_a: 225.79, accuracy: 1.00\n",
      "[Test]\t J_a: 250.92, accuracy: 0.9655\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 700\n",
      "Epoch: 38\n",
      "[Train]\t J_a: 226.00, accuracy: 1.00\n",
      "[Test]\t J_a: 250.93, accuracy: 0.9624\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 700\n",
      "Epoch: 39\n",
      "[Train]\t J_a: 225.52, accuracy: 1.00\n",
      "[Test]\t J_a: 250.93, accuracy: 0.9622\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 700\n",
      "Epoch: 40\n",
      "[Train]\t J_a: 225.38, accuracy: 1.00\n",
      "[Test]\t J_a: 250.94, accuracy: 0.9672\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 700\n",
      "Epoch: 41\n",
      "[Train]\t J_a: 225.56, accuracy: 1.00\n",
      "[Test]\t J_a: 249.87, accuracy: 0.9689\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 700\n",
      "Epoch: 42\n",
      "[Train]\t J_a: 225.20, accuracy: 1.00\n",
      "[Test]\t J_a: 250.74, accuracy: 0.9641\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 700\n",
      "Epoch: 43\n",
      "[Train]\t J_a: 224.69, accuracy: 1.00\n",
      "[Test]\t J_a: 250.19, accuracy: 0.9653\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 700\n",
      "Epoch: 44\n",
      "[Train]\t J_a: 224.85, accuracy: 1.00\n",
      "[Test]\t J_a: 250.57, accuracy: 0.9651\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 700\n",
      "Epoch: 45\n",
      "[Train]\t J_a: 224.60, accuracy: 1.00\n",
      "[Test]\t J_a: 249.80, accuracy: 0.9677\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 700\n",
      "Epoch: 46\n",
      "[Train]\t J_a: 224.23, accuracy: 1.00\n",
      "[Test]\t J_a: 249.99, accuracy: 0.9667\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 700\n",
      "Epoch: 47\n",
      "[Train]\t J_a: 224.50, accuracy: 1.00\n",
      "[Test]\t J_a: 250.22, accuracy: 0.9657\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 700\n",
      "Epoch: 48\n",
      "[Train]\t J_a: 223.89, accuracy: 1.00\n",
      "[Test]\t J_a: 249.69, accuracy: 0.9663\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 700\n",
      "Epoch: 49\n",
      "[Train]\t J_a: 223.97, accuracy: 1.00\n",
      "[Test]\t J_a: 249.84, accuracy: 0.9668\n",
      "./saved_data/MNIST_X_train_labelled_bald_100_111.pt\n",
      "./saved_data/MNIST_y_train_labelled_bald_100_111.pt\n",
      "700 700\n",
      "./saved_data/MNIST_X_train_unlabelled_bald_100_111.pt\n",
      "./saved_data/MNIST_y_train_unlabelled_bald_100_111.pt\n",
      "59300 59300\n",
      "./saved_data/MNIST_X_test_111.pt\n",
      "./saved_data/MNIST_y_test_111.pt\n",
      "10000 10000\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 700\n",
      "Epoch: 0\n",
      "[Train]\t J_a: 404.07, accuracy: 0.79\n",
      "[Test]\t J_a: 313.28, accuracy: 0.9598\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 700\n",
      "Epoch: 1\n",
      "[Train]\t J_a: 321.59, accuracy: 0.96\n",
      "[Test]\t J_a: 291.33, accuracy: 0.9657\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 700\n",
      "Epoch: 2\n",
      "[Train]\t J_a: 303.13, accuracy: 0.98\n",
      "[Test]\t J_a: 281.56, accuracy: 0.9697\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 700\n",
      "Epoch: 3\n",
      "[Train]\t J_a: 293.10, accuracy: 0.98\n",
      "[Test]\t J_a: 274.75, accuracy: 0.9711\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 700\n",
      "Epoch: 4\n",
      "[Train]\t J_a: 286.31, accuracy: 0.99\n",
      "[Test]\t J_a: 270.11, accuracy: 0.9722\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 700\n",
      "Epoch: 5\n",
      "[Train]\t J_a: 280.97, accuracy: 0.99\n",
      "[Test]\t J_a: 266.96, accuracy: 0.9708\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 700\n",
      "Epoch: 6\n",
      "[Train]\t J_a: 276.52, accuracy: 0.99\n",
      "[Test]\t J_a: 263.60, accuracy: 0.9729\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 700\n",
      "Epoch: 7\n",
      "[Train]\t J_a: 273.79, accuracy: 0.99\n",
      "[Test]\t J_a: 261.56, accuracy: 0.9756\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 700\n",
      "Epoch: 8\n",
      "[Train]\t J_a: 270.79, accuracy: 0.99\n",
      "[Test]\t J_a: 259.68, accuracy: 0.9748\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 700\n",
      "Epoch: 9\n",
      "[Train]\t J_a: 268.23, accuracy: 0.99\n",
      "[Test]\t J_a: 259.59, accuracy: 0.9748\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 700\n",
      "Epoch: 10\n",
      "[Train]\t J_a: 266.53, accuracy: 0.99\n",
      "[Test]\t J_a: 257.87, accuracy: 0.9751\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 700\n",
      "Epoch: 11\n",
      "[Train]\t J_a: 264.33, accuracy: 0.99\n",
      "[Test]\t J_a: 257.71, accuracy: 0.9751\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 700\n",
      "Epoch: 12\n",
      "[Train]\t J_a: 262.64, accuracy: 0.99\n",
      "[Test]\t J_a: 256.33, accuracy: 0.9758\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 700\n",
      "Epoch: 13\n",
      "[Train]\t J_a: 261.28, accuracy: 0.99\n",
      "[Test]\t J_a: 255.89, accuracy: 0.9746\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 700\n",
      "Epoch: 14\n",
      "[Train]\t J_a: 259.92, accuracy: 1.00\n",
      "[Test]\t J_a: 255.95, accuracy: 0.9758\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 700\n",
      "Epoch: 15\n",
      "[Train]\t J_a: 258.77, accuracy: 1.00\n",
      "[Test]\t J_a: 255.23, accuracy: 0.9801\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 700\n",
      "Epoch: 16\n",
      "[Train]\t J_a: 257.67, accuracy: 1.00\n",
      "[Test]\t J_a: 255.51, accuracy: 0.9776\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 700\n",
      "Epoch: 17\n",
      "[Train]\t J_a: 256.87, accuracy: 1.00\n",
      "[Test]\t J_a: 254.68, accuracy: 0.9773\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 700\n",
      "Epoch: 18\n",
      "[Train]\t J_a: 256.03, accuracy: 1.00\n",
      "[Test]\t J_a: 254.96, accuracy: 0.9767\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 700\n",
      "Epoch: 19\n",
      "[Train]\t J_a: 254.98, accuracy: 1.00\n",
      "[Test]\t J_a: 254.10, accuracy: 0.9766\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 700\n",
      "Epoch: 20\n",
      "[Train]\t J_a: 253.84, accuracy: 1.00\n",
      "[Test]\t J_a: 254.53, accuracy: 0.9766\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 700\n",
      "Epoch: 21\n",
      "[Train]\t J_a: 253.35, accuracy: 1.00\n",
      "[Test]\t J_a: 254.00, accuracy: 0.9767\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 700\n",
      "Epoch: 22\n",
      "[Train]\t J_a: 252.75, accuracy: 1.00\n",
      "[Test]\t J_a: 254.27, accuracy: 0.9755\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 700\n",
      "Epoch: 23\n",
      "[Train]\t J_a: 252.07, accuracy: 1.00\n",
      "[Test]\t J_a: 254.09, accuracy: 0.9782\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 700\n",
      "Epoch: 24\n",
      "[Train]\t J_a: 251.60, accuracy: 1.00\n",
      "[Test]\t J_a: 253.94, accuracy: 0.9772\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 700\n",
      "Epoch: 25\n",
      "[Train]\t J_a: 250.94, accuracy: 1.00\n",
      "[Test]\t J_a: 253.84, accuracy: 0.9796\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 700\n",
      "Epoch: 26\n",
      "[Train]\t J_a: 250.48, accuracy: 1.00\n",
      "[Test]\t J_a: 254.28, accuracy: 0.9772\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 700\n",
      "Epoch: 27\n",
      "[Train]\t J_a: 249.88, accuracy: 1.00\n",
      "[Test]\t J_a: 253.10, accuracy: 0.9795\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 700\n",
      "Epoch: 28\n",
      "[Train]\t J_a: 249.14, accuracy: 1.00\n",
      "[Test]\t J_a: 253.41, accuracy: 0.9792\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 700\n",
      "Epoch: 29\n",
      "[Train]\t J_a: 248.98, accuracy: 1.00\n",
      "[Test]\t J_a: 253.38, accuracy: 0.9777\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 700\n",
      "Epoch: 30\n",
      "[Train]\t J_a: 248.31, accuracy: 1.00\n",
      "[Test]\t J_a: 253.49, accuracy: 0.9782\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 700\n",
      "Epoch: 31\n",
      "[Train]\t J_a: 248.01, accuracy: 1.00\n",
      "[Test]\t J_a: 252.90, accuracy: 0.9793\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 700\n",
      "Epoch: 32\n",
      "[Train]\t J_a: 247.55, accuracy: 1.00\n",
      "[Test]\t J_a: 252.87, accuracy: 0.9796\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 700\n",
      "Epoch: 33\n",
      "[Train]\t J_a: 247.46, accuracy: 1.00\n",
      "[Test]\t J_a: 253.53, accuracy: 0.9800\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 700\n",
      "Epoch: 34\n",
      "[Train]\t J_a: 246.87, accuracy: 1.00\n",
      "[Test]\t J_a: 253.21, accuracy: 0.9801\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 700\n",
      "Epoch: 35\n",
      "[Train]\t J_a: 246.88, accuracy: 1.00\n",
      "[Test]\t J_a: 252.85, accuracy: 0.9798\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 700\n",
      "Epoch: 36\n",
      "[Train]\t J_a: 246.51, accuracy: 1.00\n",
      "[Test]\t J_a: 253.68, accuracy: 0.9785\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 700\n",
      "Epoch: 37\n",
      "[Train]\t J_a: 246.12, accuracy: 1.00\n",
      "[Test]\t J_a: 253.24, accuracy: 0.9800\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 700\n",
      "Epoch: 38\n",
      "[Train]\t J_a: 245.87, accuracy: 1.00\n",
      "[Test]\t J_a: 253.32, accuracy: 0.9804\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 700\n",
      "Epoch: 39\n",
      "[Train]\t J_a: 245.50, accuracy: 1.00\n",
      "[Test]\t J_a: 252.95, accuracy: 0.9795\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 700\n",
      "Epoch: 40\n",
      "[Train]\t J_a: 245.35, accuracy: 1.00\n",
      "[Test]\t J_a: 253.28, accuracy: 0.9790\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 700\n",
      "Epoch: 41\n",
      "[Train]\t J_a: 244.68, accuracy: 1.00\n",
      "[Test]\t J_a: 253.12, accuracy: 0.9811\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 700\n",
      "Epoch: 42\n",
      "[Train]\t J_a: 244.47, accuracy: 1.00\n",
      "[Test]\t J_a: 253.56, accuracy: 0.9792\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 700\n",
      "Epoch: 43\n",
      "[Train]\t J_a: 244.23, accuracy: 1.00\n",
      "[Test]\t J_a: 252.48, accuracy: 0.9794\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 700\n",
      "Epoch: 44\n",
      "[Train]\t J_a: 244.19, accuracy: 1.00\n",
      "[Test]\t J_a: 252.84, accuracy: 0.9788\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 700\n",
      "Epoch: 45\n",
      "[Train]\t J_a: 244.27, accuracy: 1.00\n",
      "[Test]\t J_a: 253.22, accuracy: 0.9818\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 700\n",
      "Epoch: 46\n",
      "[Train]\t J_a: 244.00, accuracy: 1.00\n",
      "[Test]\t J_a: 252.12, accuracy: 0.9812\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 700\n",
      "Epoch: 47\n",
      "[Train]\t J_a: 243.58, accuracy: 1.00\n",
      "[Test]\t J_a: 252.69, accuracy: 0.9803\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 700\n",
      "Epoch: 48\n",
      "[Train]\t J_a: 243.47, accuracy: 1.00\n",
      "[Test]\t J_a: 253.55, accuracy: 0.9787\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 700\n",
      "Epoch: 49\n",
      "[Train]\t J_a: 242.99, accuracy: 1.00\n",
      "[Test]\t J_a: 253.81, accuracy: 0.9813\n",
      "./saved_data/MNIST_X_train_labelled_random_100_111.pt\n",
      "./saved_data/MNIST_y_train_labelled_random_100_111.pt\n",
      "800 800\n",
      "./saved_data/MNIST_X_train_unlabelled_random_100_111.pt\n",
      "./saved_data/MNIST_y_train_unlabelled_random_100_111.pt\n",
      "59200 59200\n",
      "./saved_data/MNIST_X_test_111.pt\n",
      "./saved_data/MNIST_y_test_111.pt\n",
      "10000 10000\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 800\n",
      "Epoch: 0\n",
      "[Train]\t J_a: 377.55, accuracy: 0.91\n",
      "[Test]\t J_a: 310.60, accuracy: 0.9335\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 800\n",
      "Epoch: 1\n",
      "[Train]\t J_a: 294.29, accuracy: 0.99\n",
      "[Test]\t J_a: 287.72, accuracy: 0.9383\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 800\n",
      "Epoch: 2\n",
      "[Train]\t J_a: 275.87, accuracy: 0.99\n",
      "[Test]\t J_a: 276.24, accuracy: 0.9450\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 800\n",
      "Epoch: 3\n",
      "[Train]\t J_a: 265.92, accuracy: 0.99\n",
      "[Test]\t J_a: 269.18, accuracy: 0.9476\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 800\n",
      "Epoch: 4\n",
      "[Train]\t J_a: 259.24, accuracy: 1.00\n",
      "[Test]\t J_a: 265.02, accuracy: 0.9465\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 800\n",
      "Epoch: 5\n",
      "[Train]\t J_a: 254.15, accuracy: 1.00\n",
      "[Test]\t J_a: 261.73, accuracy: 0.9485\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 800\n",
      "Epoch: 6\n",
      "[Train]\t J_a: 250.26, accuracy: 1.00\n",
      "[Test]\t J_a: 260.01, accuracy: 0.9491\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 800\n",
      "Epoch: 7\n",
      "[Train]\t J_a: 247.66, accuracy: 1.00\n",
      "[Test]\t J_a: 257.24, accuracy: 0.9521\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 800\n",
      "Epoch: 8\n",
      "[Train]\t J_a: 245.53, accuracy: 1.00\n",
      "[Test]\t J_a: 256.29, accuracy: 0.9535\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 800\n",
      "Epoch: 9\n",
      "[Train]\t J_a: 243.50, accuracy: 1.00\n",
      "[Test]\t J_a: 255.93, accuracy: 0.9518\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 800\n",
      "Epoch: 10\n",
      "[Train]\t J_a: 241.94, accuracy: 1.00\n",
      "[Test]\t J_a: 254.46, accuracy: 0.9555\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 800\n",
      "Epoch: 11\n",
      "[Train]\t J_a: 239.95, accuracy: 1.00\n",
      "[Test]\t J_a: 253.84, accuracy: 0.9533\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 800\n",
      "Epoch: 12\n",
      "[Train]\t J_a: 239.53, accuracy: 1.00\n",
      "[Test]\t J_a: 253.13, accuracy: 0.9571\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 800\n",
      "Epoch: 13\n",
      "[Train]\t J_a: 237.72, accuracy: 1.00\n",
      "[Test]\t J_a: 251.99, accuracy: 0.9575\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 800\n",
      "Epoch: 14\n",
      "[Train]\t J_a: 236.91, accuracy: 1.00\n",
      "[Test]\t J_a: 252.77, accuracy: 0.9561\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 800\n",
      "Epoch: 15\n",
      "[Train]\t J_a: 236.31, accuracy: 1.00\n",
      "[Test]\t J_a: 251.70, accuracy: 0.9593\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 800\n",
      "Epoch: 16\n",
      "[Train]\t J_a: 235.31, accuracy: 1.00\n",
      "[Test]\t J_a: 251.74, accuracy: 0.9498\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 800\n",
      "Epoch: 17\n",
      "[Train]\t J_a: 234.32, accuracy: 1.00\n",
      "[Test]\t J_a: 251.09, accuracy: 0.9604\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 800\n",
      "Epoch: 18\n",
      "[Train]\t J_a: 234.06, accuracy: 1.00\n",
      "[Test]\t J_a: 251.36, accuracy: 0.9604\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 800\n",
      "Epoch: 19\n",
      "[Train]\t J_a: 233.97, accuracy: 1.00\n",
      "[Test]\t J_a: 250.88, accuracy: 0.9574\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 800\n",
      "Epoch: 20\n",
      "[Train]\t J_a: 232.79, accuracy: 1.00\n",
      "[Test]\t J_a: 251.24, accuracy: 0.9593\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 800\n",
      "Epoch: 21\n",
      "[Train]\t J_a: 232.40, accuracy: 1.00\n",
      "[Test]\t J_a: 249.82, accuracy: 0.9636\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 800\n",
      "Epoch: 22\n",
      "[Train]\t J_a: 231.83, accuracy: 1.00\n",
      "[Test]\t J_a: 249.53, accuracy: 0.9640\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 800\n",
      "Epoch: 23\n",
      "[Train]\t J_a: 231.42, accuracy: 1.00\n",
      "[Test]\t J_a: 250.14, accuracy: 0.9636\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 800\n",
      "Epoch: 24\n",
      "[Train]\t J_a: 231.01, accuracy: 1.00\n",
      "[Test]\t J_a: 249.59, accuracy: 0.9636\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 800\n",
      "Epoch: 25\n",
      "[Train]\t J_a: 230.53, accuracy: 1.00\n",
      "[Test]\t J_a: 250.08, accuracy: 0.9614\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 800\n",
      "Epoch: 26\n",
      "[Train]\t J_a: 229.89, accuracy: 1.00\n",
      "[Test]\t J_a: 249.46, accuracy: 0.9619\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 800\n",
      "Epoch: 27\n",
      "[Train]\t J_a: 229.65, accuracy: 1.00\n",
      "[Test]\t J_a: 249.70, accuracy: 0.9637\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 800\n",
      "Epoch: 28\n",
      "[Train]\t J_a: 229.70, accuracy: 1.00\n",
      "[Test]\t J_a: 249.28, accuracy: 0.9621\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 800\n",
      "Epoch: 29\n",
      "[Train]\t J_a: 228.68, accuracy: 1.00\n",
      "[Test]\t J_a: 248.73, accuracy: 0.9637\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 800\n",
      "Epoch: 30\n",
      "[Train]\t J_a: 228.70, accuracy: 1.00\n",
      "[Test]\t J_a: 249.24, accuracy: 0.9646\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 800\n",
      "Epoch: 31\n",
      "[Train]\t J_a: 229.30, accuracy: 1.00\n",
      "[Test]\t J_a: 249.70, accuracy: 0.9613\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 800\n",
      "Epoch: 32\n",
      "[Train]\t J_a: 228.28, accuracy: 1.00\n",
      "[Test]\t J_a: 248.53, accuracy: 0.9649\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 800\n",
      "Epoch: 33\n",
      "[Train]\t J_a: 228.03, accuracy: 1.00\n",
      "[Test]\t J_a: 249.14, accuracy: 0.9620\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 800\n",
      "Epoch: 34\n",
      "[Train]\t J_a: 227.99, accuracy: 1.00\n",
      "[Test]\t J_a: 248.80, accuracy: 0.9669\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 800\n",
      "Epoch: 35\n",
      "[Train]\t J_a: 227.58, accuracy: 1.00\n",
      "[Test]\t J_a: 249.01, accuracy: 0.9638\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 800\n",
      "Epoch: 36\n",
      "[Train]\t J_a: 227.32, accuracy: 1.00\n",
      "[Test]\t J_a: 248.61, accuracy: 0.9628\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 800\n",
      "Epoch: 37\n",
      "[Train]\t J_a: 227.14, accuracy: 1.00\n",
      "[Test]\t J_a: 248.71, accuracy: 0.9652\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 800\n",
      "Epoch: 38\n",
      "[Train]\t J_a: 226.91, accuracy: 1.00\n",
      "[Test]\t J_a: 249.02, accuracy: 0.9657\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 800\n",
      "Epoch: 39\n",
      "[Train]\t J_a: 226.81, accuracy: 1.00\n",
      "[Test]\t J_a: 248.03, accuracy: 0.9664\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 800\n",
      "Epoch: 40\n",
      "[Train]\t J_a: 226.43, accuracy: 1.00\n",
      "[Test]\t J_a: 248.70, accuracy: 0.9647\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 800\n",
      "Epoch: 41\n",
      "[Train]\t J_a: 226.24, accuracy: 1.00\n",
      "[Test]\t J_a: 248.06, accuracy: 0.9667\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 800\n",
      "Epoch: 42\n",
      "[Train]\t J_a: 225.96, accuracy: 1.00\n",
      "[Test]\t J_a: 248.29, accuracy: 0.9679\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 800\n",
      "Epoch: 43\n",
      "[Train]\t J_a: 225.90, accuracy: 1.00\n",
      "[Test]\t J_a: 247.82, accuracy: 0.9678\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 800\n",
      "Epoch: 44\n",
      "[Train]\t J_a: 225.77, accuracy: 1.00\n",
      "[Test]\t J_a: 248.29, accuracy: 0.9655\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 800\n",
      "Epoch: 45\n",
      "[Train]\t J_a: 225.98, accuracy: 1.00\n",
      "[Test]\t J_a: 248.64, accuracy: 0.9628\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 800\n",
      "Epoch: 46\n",
      "[Train]\t J_a: 225.33, accuracy: 1.00\n",
      "[Test]\t J_a: 248.64, accuracy: 0.9639\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 800\n",
      "Epoch: 47\n",
      "[Train]\t J_a: 225.82, accuracy: 1.00\n",
      "[Test]\t J_a: 248.68, accuracy: 0.9632\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 800\n",
      "Epoch: 48\n",
      "[Train]\t J_a: 225.63, accuracy: 1.00\n",
      "[Test]\t J_a: 248.31, accuracy: 0.9687\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 800\n",
      "Epoch: 49\n",
      "[Train]\t J_a: 225.17, accuracy: 1.00\n",
      "[Test]\t J_a: 248.34, accuracy: 0.9670\n",
      "./saved_data/MNIST_X_train_labelled_bald_100_111.pt\n",
      "./saved_data/MNIST_y_train_labelled_bald_100_111.pt\n",
      "800 800\n",
      "./saved_data/MNIST_X_train_unlabelled_bald_100_111.pt\n",
      "./saved_data/MNIST_y_train_unlabelled_bald_100_111.pt\n",
      "59200 59200\n",
      "./saved_data/MNIST_X_test_111.pt\n",
      "./saved_data/MNIST_y_test_111.pt\n",
      "10000 10000\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 800\n",
      "Epoch: 0\n",
      "[Train]\t J_a: 404.00, accuracy: 0.77\n",
      "[Test]\t J_a: 314.12, accuracy: 0.9634\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 800\n",
      "Epoch: 1\n",
      "[Train]\t J_a: 323.78, accuracy: 0.95\n",
      "[Test]\t J_a: 292.47, accuracy: 0.9718\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 800\n",
      "Epoch: 2\n",
      "[Train]\t J_a: 305.55, accuracy: 0.97\n",
      "[Test]\t J_a: 281.27, accuracy: 0.9735\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 800\n",
      "Epoch: 3\n",
      "[Train]\t J_a: 295.14, accuracy: 0.98\n",
      "[Test]\t J_a: 273.99, accuracy: 0.9752\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 800\n",
      "Epoch: 4\n",
      "[Train]\t J_a: 287.84, accuracy: 0.98\n",
      "[Test]\t J_a: 269.54, accuracy: 0.9749\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 800\n",
      "Epoch: 5\n",
      "[Train]\t J_a: 282.97, accuracy: 0.99\n",
      "[Test]\t J_a: 265.96, accuracy: 0.9745\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 800\n",
      "Epoch: 6\n",
      "[Train]\t J_a: 278.48, accuracy: 0.99\n",
      "[Test]\t J_a: 263.41, accuracy: 0.9783\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 800\n",
      "Epoch: 7\n",
      "[Train]\t J_a: 275.47, accuracy: 0.99\n",
      "[Test]\t J_a: 260.94, accuracy: 0.9779\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 800\n",
      "Epoch: 8\n",
      "[Train]\t J_a: 272.70, accuracy: 0.99\n",
      "[Test]\t J_a: 259.46, accuracy: 0.9802\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 800\n",
      "Epoch: 9\n",
      "[Train]\t J_a: 269.83, accuracy: 0.99\n",
      "[Test]\t J_a: 257.61, accuracy: 0.9774\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 800\n",
      "Epoch: 10\n",
      "[Train]\t J_a: 267.82, accuracy: 0.99\n",
      "[Test]\t J_a: 256.66, accuracy: 0.9766\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 800\n",
      "Epoch: 11\n",
      "[Train]\t J_a: 265.98, accuracy: 0.99\n",
      "[Test]\t J_a: 255.84, accuracy: 0.9787\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 800\n",
      "Epoch: 12\n",
      "[Train]\t J_a: 264.62, accuracy: 0.99\n",
      "[Test]\t J_a: 255.35, accuracy: 0.9800\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 800\n",
      "Epoch: 13\n",
      "[Train]\t J_a: 263.17, accuracy: 0.99\n",
      "[Test]\t J_a: 255.20, accuracy: 0.9775\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 800\n",
      "Epoch: 14\n",
      "[Train]\t J_a: 261.79, accuracy: 0.99\n",
      "[Test]\t J_a: 254.52, accuracy: 0.9796\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 800\n",
      "Epoch: 15\n",
      "[Train]\t J_a: 260.63, accuracy: 0.99\n",
      "[Test]\t J_a: 253.67, accuracy: 0.9800\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 800\n",
      "Epoch: 16\n",
      "[Train]\t J_a: 259.48, accuracy: 0.99\n",
      "[Test]\t J_a: 253.62, accuracy: 0.9814\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 800\n",
      "Epoch: 17\n",
      "[Train]\t J_a: 258.45, accuracy: 1.00\n",
      "[Test]\t J_a: 253.37, accuracy: 0.9793\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 800\n",
      "Epoch: 18\n",
      "[Train]\t J_a: 258.14, accuracy: 0.99\n",
      "[Test]\t J_a: 253.44, accuracy: 0.9797\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 800\n",
      "Epoch: 19\n",
      "[Train]\t J_a: 257.42, accuracy: 0.99\n",
      "[Test]\t J_a: 252.36, accuracy: 0.9806\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 800\n",
      "Epoch: 20\n",
      "[Train]\t J_a: 256.43, accuracy: 0.99\n",
      "[Test]\t J_a: 252.58, accuracy: 0.9813\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 800\n",
      "Epoch: 21\n",
      "[Train]\t J_a: 255.44, accuracy: 0.99\n",
      "[Test]\t J_a: 252.10, accuracy: 0.9812\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 800\n",
      "Epoch: 22\n",
      "[Train]\t J_a: 254.67, accuracy: 0.99\n",
      "[Test]\t J_a: 252.21, accuracy: 0.9809\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 800\n",
      "Epoch: 23\n",
      "[Train]\t J_a: 254.46, accuracy: 0.99\n",
      "[Test]\t J_a: 252.62, accuracy: 0.9807\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 800\n",
      "Epoch: 24\n",
      "[Train]\t J_a: 253.68, accuracy: 1.00\n",
      "[Test]\t J_a: 252.50, accuracy: 0.9813\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 800\n",
      "Epoch: 25\n",
      "[Train]\t J_a: 253.25, accuracy: 1.00\n",
      "[Test]\t J_a: 251.84, accuracy: 0.9795\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 800\n",
      "Epoch: 26\n",
      "[Train]\t J_a: 252.95, accuracy: 1.00\n",
      "[Test]\t J_a: 251.60, accuracy: 0.9814\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 800\n",
      "Epoch: 27\n",
      "[Train]\t J_a: 252.49, accuracy: 1.00\n",
      "[Test]\t J_a: 252.03, accuracy: 0.9792\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 800\n",
      "Epoch: 28\n",
      "[Train]\t J_a: 251.78, accuracy: 1.00\n",
      "[Test]\t J_a: 251.69, accuracy: 0.9812\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 800\n",
      "Epoch: 29\n",
      "[Train]\t J_a: 251.10, accuracy: 1.00\n",
      "[Test]\t J_a: 251.88, accuracy: 0.9800\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 800\n",
      "Epoch: 30\n",
      "[Train]\t J_a: 250.85, accuracy: 1.00\n",
      "[Test]\t J_a: 252.02, accuracy: 0.9823\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 800\n",
      "Epoch: 31\n",
      "[Train]\t J_a: 250.32, accuracy: 1.00\n",
      "[Test]\t J_a: 252.44, accuracy: 0.9811\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 800\n",
      "Epoch: 32\n",
      "[Train]\t J_a: 250.46, accuracy: 1.00\n",
      "[Test]\t J_a: 251.59, accuracy: 0.9833\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 800\n",
      "Epoch: 33\n",
      "[Train]\t J_a: 249.93, accuracy: 1.00\n",
      "[Test]\t J_a: 251.53, accuracy: 0.9810\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 800\n",
      "Epoch: 34\n",
      "[Train]\t J_a: 249.71, accuracy: 1.00\n",
      "[Test]\t J_a: 251.31, accuracy: 0.9817\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 800\n",
      "Epoch: 35\n",
      "[Train]\t J_a: 249.05, accuracy: 1.00\n",
      "[Test]\t J_a: 251.62, accuracy: 0.9829\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 800\n",
      "Epoch: 36\n",
      "[Train]\t J_a: 249.09, accuracy: 1.00\n",
      "[Test]\t J_a: 251.73, accuracy: 0.9819\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 800\n",
      "Epoch: 37\n",
      "[Train]\t J_a: 248.47, accuracy: 1.00\n",
      "[Test]\t J_a: 251.53, accuracy: 0.9809\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 800\n",
      "Epoch: 38\n",
      "[Train]\t J_a: 248.12, accuracy: 1.00\n",
      "[Test]\t J_a: 251.68, accuracy: 0.9805\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 800\n",
      "Epoch: 39\n",
      "[Train]\t J_a: 248.39, accuracy: 1.00\n",
      "[Test]\t J_a: 250.85, accuracy: 0.9801\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 800\n",
      "Epoch: 40\n",
      "[Train]\t J_a: 247.57, accuracy: 1.00\n",
      "[Test]\t J_a: 251.41, accuracy: 0.9808\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 800\n",
      "Epoch: 41\n",
      "[Train]\t J_a: 247.69, accuracy: 1.00\n",
      "[Test]\t J_a: 251.27, accuracy: 0.9820\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 800\n",
      "Epoch: 42\n",
      "[Train]\t J_a: 247.31, accuracy: 1.00\n",
      "[Test]\t J_a: 251.33, accuracy: 0.9827\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 800\n",
      "Epoch: 43\n",
      "[Train]\t J_a: 247.16, accuracy: 1.00\n",
      "[Test]\t J_a: 251.17, accuracy: 0.9821\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 800\n",
      "Epoch: 44\n",
      "[Train]\t J_a: 246.99, accuracy: 1.00\n",
      "[Test]\t J_a: 251.57, accuracy: 0.9805\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 800\n",
      "Epoch: 45\n",
      "[Train]\t J_a: 246.56, accuracy: 1.00\n",
      "[Test]\t J_a: 251.67, accuracy: 0.9803\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 800\n",
      "Epoch: 46\n",
      "[Train]\t J_a: 246.55, accuracy: 1.00\n",
      "[Test]\t J_a: 250.86, accuracy: 0.9808\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 800\n",
      "Epoch: 47\n",
      "[Train]\t J_a: 246.30, accuracy: 1.00\n",
      "[Test]\t J_a: 251.16, accuracy: 0.9814\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 800\n",
      "Epoch: 48\n",
      "[Train]\t J_a: 245.84, accuracy: 1.00\n",
      "[Test]\t J_a: 251.30, accuracy: 0.9816\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 800\n",
      "Epoch: 49\n",
      "[Train]\t J_a: 246.23, accuracy: 1.00\n",
      "[Test]\t J_a: 251.41, accuracy: 0.9820\n",
      "./saved_data/MNIST_X_train_labelled_random_100_111.pt\n",
      "./saved_data/MNIST_y_train_labelled_random_100_111.pt\n",
      "900 900\n",
      "./saved_data/MNIST_X_train_unlabelled_random_100_111.pt\n",
      "./saved_data/MNIST_y_train_unlabelled_random_100_111.pt\n",
      "59100 59100\n",
      "./saved_data/MNIST_X_test_111.pt\n",
      "./saved_data/MNIST_y_test_111.pt\n",
      "10000 10000\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 900\n",
      "Epoch: 0\n",
      "[Train]\t J_a: 378.05, accuracy: 0.91\n",
      "[Test]\t J_a: 312.00, accuracy: 0.9319\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 900\n",
      "Epoch: 1\n",
      "[Train]\t J_a: 296.09, accuracy: 0.99\n",
      "[Test]\t J_a: 290.88, accuracy: 0.9393\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 900\n",
      "Epoch: 2\n",
      "[Train]\t J_a: 280.04, accuracy: 0.99\n",
      "[Test]\t J_a: 279.35, accuracy: 0.9465\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 900\n",
      "Epoch: 3\n",
      "[Train]\t J_a: 268.94, accuracy: 0.99\n",
      "[Test]\t J_a: 272.46, accuracy: 0.9465\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 900\n",
      "Epoch: 4\n",
      "[Train]\t J_a: 261.50, accuracy: 0.99\n",
      "[Test]\t J_a: 267.36, accuracy: 0.9475\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 900\n",
      "Epoch: 5\n",
      "[Train]\t J_a: 256.76, accuracy: 1.00\n",
      "[Test]\t J_a: 264.60, accuracy: 0.9495\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 900\n",
      "Epoch: 6\n",
      "[Train]\t J_a: 250.88, accuracy: 1.00\n",
      "[Test]\t J_a: 261.11, accuracy: 0.9534\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 900\n",
      "Epoch: 7\n",
      "[Train]\t J_a: 248.88, accuracy: 1.00\n",
      "[Test]\t J_a: 259.01, accuracy: 0.9486\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 900\n",
      "Epoch: 8\n",
      "[Train]\t J_a: 247.12, accuracy: 1.00\n",
      "[Test]\t J_a: 257.65, accuracy: 0.9556\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 900\n",
      "Epoch: 9\n",
      "[Train]\t J_a: 244.72, accuracy: 1.00\n",
      "[Test]\t J_a: 256.36, accuracy: 0.9563\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 900\n",
      "Epoch: 10\n",
      "[Train]\t J_a: 244.04, accuracy: 1.00\n",
      "[Test]\t J_a: 255.45, accuracy: 0.9571\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 900\n",
      "Epoch: 11\n",
      "[Train]\t J_a: 241.40, accuracy: 1.00\n",
      "[Test]\t J_a: 254.81, accuracy: 0.9514\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 900\n",
      "Epoch: 12\n",
      "[Train]\t J_a: 240.17, accuracy: 1.00\n",
      "[Test]\t J_a: 254.63, accuracy: 0.9571\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 900\n",
      "Epoch: 13\n",
      "[Train]\t J_a: 239.28, accuracy: 1.00\n",
      "[Test]\t J_a: 253.05, accuracy: 0.9524\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 900\n",
      "Epoch: 14\n",
      "[Train]\t J_a: 239.06, accuracy: 1.00\n",
      "[Test]\t J_a: 252.29, accuracy: 0.9577\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 900\n",
      "Epoch: 15\n",
      "[Train]\t J_a: 236.94, accuracy: 1.00\n",
      "[Test]\t J_a: 251.24, accuracy: 0.9612\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 900\n",
      "Epoch: 16\n",
      "[Train]\t J_a: 236.51, accuracy: 1.00\n",
      "[Test]\t J_a: 251.49, accuracy: 0.9600\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 900\n",
      "Epoch: 17\n",
      "[Train]\t J_a: 235.13, accuracy: 1.00\n",
      "[Test]\t J_a: 250.83, accuracy: 0.9615\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 900\n",
      "Epoch: 18\n",
      "[Train]\t J_a: 234.69, accuracy: 1.00\n",
      "[Test]\t J_a: 251.01, accuracy: 0.9619\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 900\n",
      "Epoch: 19\n",
      "[Train]\t J_a: 234.24, accuracy: 1.00\n",
      "[Test]\t J_a: 250.13, accuracy: 0.9593\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 900\n",
      "Epoch: 20\n",
      "[Train]\t J_a: 234.36, accuracy: 1.00\n",
      "[Test]\t J_a: 250.27, accuracy: 0.9608\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 900\n",
      "Epoch: 21\n",
      "[Train]\t J_a: 232.85, accuracy: 1.00\n",
      "[Test]\t J_a: 250.31, accuracy: 0.9626\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 900\n",
      "Epoch: 22\n",
      "[Train]\t J_a: 232.20, accuracy: 1.00\n",
      "[Test]\t J_a: 250.04, accuracy: 0.9608\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 900\n",
      "Epoch: 23\n",
      "[Train]\t J_a: 232.68, accuracy: 1.00\n",
      "[Test]\t J_a: 249.89, accuracy: 0.9639\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 900\n",
      "Epoch: 24\n",
      "[Train]\t J_a: 231.62, accuracy: 1.00\n",
      "[Test]\t J_a: 249.06, accuracy: 0.9626\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 900\n",
      "Epoch: 25\n",
      "[Train]\t J_a: 231.68, accuracy: 1.00\n",
      "[Test]\t J_a: 250.37, accuracy: 0.9609\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 900\n",
      "Epoch: 26\n",
      "[Train]\t J_a: 230.59, accuracy: 1.00\n",
      "[Test]\t J_a: 249.21, accuracy: 0.9645\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 900\n",
      "Epoch: 27\n",
      "[Train]\t J_a: 230.87, accuracy: 1.00\n",
      "[Test]\t J_a: 249.46, accuracy: 0.9623\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 900\n",
      "Epoch: 28\n",
      "[Train]\t J_a: 229.85, accuracy: 1.00\n",
      "[Test]\t J_a: 249.06, accuracy: 0.9628\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 900\n",
      "Epoch: 29\n",
      "[Train]\t J_a: 229.70, accuracy: 1.00\n",
      "[Test]\t J_a: 248.81, accuracy: 0.9635\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 900\n",
      "Epoch: 30\n",
      "[Train]\t J_a: 229.38, accuracy: 1.00\n",
      "[Test]\t J_a: 249.02, accuracy: 0.9648\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 900\n",
      "Epoch: 31\n",
      "[Train]\t J_a: 228.33, accuracy: 1.00\n",
      "[Test]\t J_a: 248.90, accuracy: 0.9630\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 900\n",
      "Epoch: 32\n",
      "[Train]\t J_a: 229.38, accuracy: 1.00\n",
      "[Test]\t J_a: 248.78, accuracy: 0.9644\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 900\n",
      "Epoch: 33\n",
      "[Train]\t J_a: 229.08, accuracy: 1.00\n",
      "[Test]\t J_a: 249.22, accuracy: 0.9628\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 900\n",
      "Epoch: 34\n",
      "[Train]\t J_a: 229.06, accuracy: 1.00\n",
      "[Test]\t J_a: 248.27, accuracy: 0.9638\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 900\n",
      "Epoch: 35\n",
      "[Train]\t J_a: 228.01, accuracy: 1.00\n",
      "[Test]\t J_a: 248.27, accuracy: 0.9662\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 900\n",
      "Epoch: 36\n",
      "[Train]\t J_a: 228.12, accuracy: 1.00\n",
      "[Test]\t J_a: 248.31, accuracy: 0.9654\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 900\n",
      "Epoch: 37\n",
      "[Train]\t J_a: 228.41, accuracy: 1.00\n",
      "[Test]\t J_a: 248.62, accuracy: 0.9642\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 900\n",
      "Epoch: 38\n",
      "[Train]\t J_a: 227.81, accuracy: 1.00\n",
      "[Test]\t J_a: 248.26, accuracy: 0.9634\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 900\n",
      "Epoch: 39\n",
      "[Train]\t J_a: 227.48, accuracy: 1.00\n",
      "[Test]\t J_a: 248.55, accuracy: 0.9662\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 900\n",
      "Epoch: 40\n",
      "[Train]\t J_a: 226.29, accuracy: 1.00\n",
      "[Test]\t J_a: 247.09, accuracy: 0.9662\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 900\n",
      "Epoch: 41\n",
      "[Train]\t J_a: 227.68, accuracy: 1.00\n",
      "[Test]\t J_a: 247.53, accuracy: 0.9692\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 900\n",
      "Epoch: 42\n",
      "[Train]\t J_a: 225.24, accuracy: 1.00\n",
      "[Test]\t J_a: 247.45, accuracy: 0.9676\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 900\n",
      "Epoch: 43\n",
      "[Train]\t J_a: 226.55, accuracy: 1.00\n",
      "[Test]\t J_a: 247.65, accuracy: 0.9686\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 900\n",
      "Epoch: 44\n",
      "[Train]\t J_a: 226.60, accuracy: 1.00\n",
      "[Test]\t J_a: 247.89, accuracy: 0.9668\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 900\n",
      "Epoch: 45\n",
      "[Train]\t J_a: 226.24, accuracy: 1.00\n",
      "[Test]\t J_a: 247.50, accuracy: 0.9675\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 900\n",
      "Epoch: 46\n",
      "[Train]\t J_a: 226.10, accuracy: 1.00\n",
      "[Test]\t J_a: 247.81, accuracy: 0.9663\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 900\n",
      "Epoch: 47\n",
      "[Train]\t J_a: 226.24, accuracy: 1.00\n",
      "[Test]\t J_a: 247.34, accuracy: 0.9686\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 900\n",
      "Epoch: 48\n",
      "[Train]\t J_a: 225.92, accuracy: 1.00\n",
      "[Test]\t J_a: 247.77, accuracy: 0.9651\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 900\n",
      "Epoch: 49\n",
      "[Train]\t J_a: 226.35, accuracy: 1.00\n",
      "[Test]\t J_a: 247.54, accuracy: 0.9668\n",
      "./saved_data/MNIST_X_train_labelled_bald_100_111.pt\n",
      "./saved_data/MNIST_y_train_labelled_bald_100_111.pt\n",
      "900 900\n",
      "./saved_data/MNIST_X_train_unlabelled_bald_100_111.pt\n",
      "./saved_data/MNIST_y_train_unlabelled_bald_100_111.pt\n",
      "59100 59100\n",
      "./saved_data/MNIST_X_test_111.pt\n",
      "./saved_data/MNIST_y_test_111.pt\n",
      "10000 10000\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 900\n",
      "Epoch: 0\n",
      "[Train]\t J_a: 408.54, accuracy: 0.74\n",
      "[Test]\t J_a: 320.30, accuracy: 0.9679\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 900\n",
      "Epoch: 1\n",
      "[Train]\t J_a: 327.13, accuracy: 0.94\n",
      "[Test]\t J_a: 295.96, accuracy: 0.9727\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 900\n",
      "Epoch: 2\n",
      "[Train]\t J_a: 307.81, accuracy: 0.97\n",
      "[Test]\t J_a: 284.76, accuracy: 0.9745\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 900\n",
      "Epoch: 3\n",
      "[Train]\t J_a: 297.75, accuracy: 0.98\n",
      "[Test]\t J_a: 277.57, accuracy: 0.9752\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 900\n",
      "Epoch: 4\n",
      "[Train]\t J_a: 290.38, accuracy: 0.98\n",
      "[Test]\t J_a: 272.51, accuracy: 0.9764\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 900\n",
      "Epoch: 5\n",
      "[Train]\t J_a: 284.83, accuracy: 0.98\n",
      "[Test]\t J_a: 268.17, accuracy: 0.9779\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 900\n",
      "Epoch: 6\n",
      "[Train]\t J_a: 281.65, accuracy: 0.98\n",
      "[Test]\t J_a: 265.77, accuracy: 0.9762\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 900\n",
      "Epoch: 7\n",
      "[Train]\t J_a: 278.09, accuracy: 0.99\n",
      "[Test]\t J_a: 263.37, accuracy: 0.9757\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 900\n",
      "Epoch: 8\n",
      "[Train]\t J_a: 275.15, accuracy: 0.99\n",
      "[Test]\t J_a: 261.85, accuracy: 0.9785\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 900\n",
      "Epoch: 9\n",
      "[Train]\t J_a: 272.05, accuracy: 0.99\n",
      "[Test]\t J_a: 259.61, accuracy: 0.9799\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 900\n",
      "Epoch: 10\n",
      "[Train]\t J_a: 270.75, accuracy: 0.99\n",
      "[Test]\t J_a: 258.53, accuracy: 0.9773\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 900\n",
      "Epoch: 11\n",
      "[Train]\t J_a: 268.52, accuracy: 0.99\n",
      "[Test]\t J_a: 257.74, accuracy: 0.9800\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 900\n",
      "Epoch: 12\n",
      "[Train]\t J_a: 267.24, accuracy: 0.99\n",
      "[Test]\t J_a: 256.91, accuracy: 0.9773\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 900\n",
      "Epoch: 13\n",
      "[Train]\t J_a: 265.76, accuracy: 0.99\n",
      "[Test]\t J_a: 255.52, accuracy: 0.9792\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 900\n",
      "Epoch: 14\n",
      "[Train]\t J_a: 264.64, accuracy: 0.99\n",
      "[Test]\t J_a: 255.60, accuracy: 0.9774\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 900\n",
      "Epoch: 15\n",
      "[Train]\t J_a: 263.28, accuracy: 0.99\n",
      "[Test]\t J_a: 254.52, accuracy: 0.9811\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 900\n",
      "Epoch: 16\n",
      "[Train]\t J_a: 261.86, accuracy: 0.99\n",
      "[Test]\t J_a: 254.23, accuracy: 0.9797\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 900\n",
      "Epoch: 17\n",
      "[Train]\t J_a: 260.91, accuracy: 0.99\n",
      "[Test]\t J_a: 254.66, accuracy: 0.9799\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 900\n",
      "Epoch: 18\n",
      "[Train]\t J_a: 260.02, accuracy: 0.99\n",
      "[Test]\t J_a: 253.31, accuracy: 0.9803\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 900\n",
      "Epoch: 19\n",
      "[Train]\t J_a: 258.81, accuracy: 0.99\n",
      "[Test]\t J_a: 252.93, accuracy: 0.9793\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 900\n",
      "Epoch: 20\n",
      "[Train]\t J_a: 257.08, accuracy: 0.99\n",
      "[Test]\t J_a: 252.96, accuracy: 0.9806\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 900\n",
      "Epoch: 21\n",
      "[Train]\t J_a: 256.62, accuracy: 0.99\n",
      "[Test]\t J_a: 252.65, accuracy: 0.9795\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 900\n",
      "Epoch: 22\n",
      "[Train]\t J_a: 256.49, accuracy: 0.99\n",
      "[Test]\t J_a: 252.54, accuracy: 0.9814\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 900\n",
      "Epoch: 23\n",
      "[Train]\t J_a: 255.98, accuracy: 0.99\n",
      "[Test]\t J_a: 252.28, accuracy: 0.9806\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 900\n",
      "Epoch: 24\n",
      "[Train]\t J_a: 255.47, accuracy: 0.99\n",
      "[Test]\t J_a: 252.10, accuracy: 0.9797\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 900\n",
      "Epoch: 25\n",
      "[Train]\t J_a: 254.39, accuracy: 0.99\n",
      "[Test]\t J_a: 251.98, accuracy: 0.9801\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 900\n",
      "Epoch: 26\n",
      "[Train]\t J_a: 254.28, accuracy: 0.99\n",
      "[Test]\t J_a: 251.69, accuracy: 0.9812\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 900\n",
      "Epoch: 27\n",
      "[Train]\t J_a: 254.00, accuracy: 0.99\n",
      "[Test]\t J_a: 252.07, accuracy: 0.9791\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 900\n",
      "Epoch: 28\n",
      "[Train]\t J_a: 253.02, accuracy: 1.00\n",
      "[Test]\t J_a: 251.58, accuracy: 0.9808\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 900\n",
      "Epoch: 29\n",
      "[Train]\t J_a: 252.58, accuracy: 0.99\n",
      "[Test]\t J_a: 251.07, accuracy: 0.9811\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 900\n",
      "Epoch: 30\n",
      "[Train]\t J_a: 252.04, accuracy: 0.99\n",
      "[Test]\t J_a: 251.72, accuracy: 0.9805\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 900\n",
      "Epoch: 31\n",
      "[Train]\t J_a: 252.39, accuracy: 0.99\n",
      "[Test]\t J_a: 251.39, accuracy: 0.9812\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 900\n",
      "Epoch: 32\n",
      "[Train]\t J_a: 251.59, accuracy: 0.99\n",
      "[Test]\t J_a: 250.96, accuracy: 0.9810\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 900\n",
      "Epoch: 33\n",
      "[Train]\t J_a: 251.26, accuracy: 0.99\n",
      "[Test]\t J_a: 250.99, accuracy: 0.9814\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 900\n",
      "Epoch: 34\n",
      "[Train]\t J_a: 251.43, accuracy: 0.99\n",
      "[Test]\t J_a: 251.36, accuracy: 0.9799\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 900\n",
      "Epoch: 35\n",
      "[Train]\t J_a: 250.51, accuracy: 0.99\n",
      "[Test]\t J_a: 251.44, accuracy: 0.9818\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 900\n",
      "Epoch: 36\n",
      "[Train]\t J_a: 250.34, accuracy: 1.00\n",
      "[Test]\t J_a: 251.10, accuracy: 0.9800\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 900\n",
      "Epoch: 37\n",
      "[Train]\t J_a: 249.98, accuracy: 1.00\n",
      "[Test]\t J_a: 251.03, accuracy: 0.9825\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 900\n",
      "Epoch: 38\n",
      "[Train]\t J_a: 249.72, accuracy: 1.00\n",
      "[Test]\t J_a: 250.95, accuracy: 0.9830\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 900\n",
      "Epoch: 39\n",
      "[Train]\t J_a: 249.37, accuracy: 1.00\n",
      "[Test]\t J_a: 250.47, accuracy: 0.9811\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 900\n",
      "Epoch: 40\n",
      "[Train]\t J_a: 249.51, accuracy: 1.00\n",
      "[Test]\t J_a: 250.26, accuracy: 0.9805\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 900\n",
      "Epoch: 41\n",
      "[Train]\t J_a: 249.05, accuracy: 1.00\n",
      "[Test]\t J_a: 251.17, accuracy: 0.9812\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 900\n",
      "Epoch: 42\n",
      "[Train]\t J_a: 248.56, accuracy: 1.00\n",
      "[Test]\t J_a: 250.52, accuracy: 0.9828\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 900\n",
      "Epoch: 43\n",
      "[Train]\t J_a: 248.53, accuracy: 1.00\n",
      "[Test]\t J_a: 251.67, accuracy: 0.9823\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 900\n",
      "Epoch: 44\n",
      "[Train]\t J_a: 248.05, accuracy: 1.00\n",
      "[Test]\t J_a: 251.27, accuracy: 0.9825\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 900\n",
      "Epoch: 45\n",
      "[Train]\t J_a: 246.91, accuracy: 1.00\n",
      "[Test]\t J_a: 250.46, accuracy: 0.9833\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 900\n",
      "Epoch: 46\n",
      "[Train]\t J_a: 246.86, accuracy: 1.00\n",
      "[Test]\t J_a: 250.57, accuracy: 0.9815\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 900\n",
      "Epoch: 47\n",
      "[Train]\t J_a: 247.40, accuracy: 1.00\n",
      "[Test]\t J_a: 250.61, accuracy: 0.9829\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 900\n",
      "Epoch: 48\n",
      "[Train]\t J_a: 247.83, accuracy: 1.00\n",
      "[Test]\t J_a: 250.65, accuracy: 0.9817\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 900\n",
      "Epoch: 49\n",
      "[Train]\t J_a: 246.64, accuracy: 1.00\n",
      "[Test]\t J_a: 250.38, accuracy: 0.9832\n",
      "./saved_data/MNIST_X_train_labelled_random_100_111.pt\n",
      "./saved_data/MNIST_y_train_labelled_random_100_111.pt\n",
      "1000 1000\n",
      "./saved_data/MNIST_X_train_unlabelled_random_100_111.pt\n",
      "./saved_data/MNIST_y_train_unlabelled_random_100_111.pt\n",
      "59000 59000\n",
      "./saved_data/MNIST_X_test_111.pt\n",
      "./saved_data/MNIST_y_test_111.pt\n",
      "10000 10000\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 1000\n",
      "Epoch: 0\n",
      "[Train]\t J_a: 374.44, accuracy: 0.90\n",
      "[Test]\t J_a: 308.00, accuracy: 0.9357\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 1000\n",
      "Epoch: 1\n",
      "[Train]\t J_a: 294.28, accuracy: 0.98\n",
      "[Test]\t J_a: 286.76, accuracy: 0.9404\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 1000\n",
      "Epoch: 2\n",
      "[Train]\t J_a: 276.41, accuracy: 0.99\n",
      "[Test]\t J_a: 275.40, accuracy: 0.9446\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 1000\n",
      "Epoch: 3\n",
      "[Train]\t J_a: 266.07, accuracy: 0.99\n",
      "[Test]\t J_a: 268.00, accuracy: 0.9469\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 1000\n",
      "Epoch: 4\n",
      "[Train]\t J_a: 259.78, accuracy: 0.99\n",
      "[Test]\t J_a: 263.05, accuracy: 0.9492\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 1000\n",
      "Epoch: 5\n",
      "[Train]\t J_a: 254.77, accuracy: 0.99\n",
      "[Test]\t J_a: 260.12, accuracy: 0.9520\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 1000\n",
      "Epoch: 6\n",
      "[Train]\t J_a: 251.42, accuracy: 1.00\n",
      "[Test]\t J_a: 257.46, accuracy: 0.9539\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 1000\n",
      "Epoch: 7\n",
      "[Train]\t J_a: 248.53, accuracy: 1.00\n",
      "[Test]\t J_a: 255.70, accuracy: 0.9550\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 1000\n",
      "Epoch: 8\n",
      "[Train]\t J_a: 246.70, accuracy: 1.00\n",
      "[Test]\t J_a: 255.10, accuracy: 0.9566\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 1000\n",
      "Epoch: 9\n",
      "[Train]\t J_a: 244.44, accuracy: 1.00\n",
      "[Test]\t J_a: 253.41, accuracy: 0.9532\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 1000\n",
      "Epoch: 10\n",
      "[Train]\t J_a: 243.00, accuracy: 1.00\n",
      "[Test]\t J_a: 252.48, accuracy: 0.9577\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 1000\n",
      "Epoch: 11\n",
      "[Train]\t J_a: 241.63, accuracy: 1.00\n",
      "[Test]\t J_a: 251.63, accuracy: 0.9567\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 1000\n",
      "Epoch: 12\n",
      "[Train]\t J_a: 240.29, accuracy: 1.00\n",
      "[Test]\t J_a: 250.73, accuracy: 0.9569\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 1000\n",
      "Epoch: 13\n",
      "[Train]\t J_a: 239.25, accuracy: 1.00\n",
      "[Test]\t J_a: 250.55, accuracy: 0.9577\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 1000\n",
      "Epoch: 14\n",
      "[Train]\t J_a: 238.15, accuracy: 1.00\n",
      "[Test]\t J_a: 249.95, accuracy: 0.9626\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 1000\n",
      "Epoch: 15\n",
      "[Train]\t J_a: 237.38, accuracy: 1.00\n",
      "[Test]\t J_a: 249.29, accuracy: 0.9619\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 1000\n",
      "Epoch: 16\n",
      "[Train]\t J_a: 236.65, accuracy: 1.00\n",
      "[Test]\t J_a: 249.08, accuracy: 0.9576\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 1000\n",
      "Epoch: 17\n",
      "[Train]\t J_a: 236.04, accuracy: 1.00\n",
      "[Test]\t J_a: 248.76, accuracy: 0.9623\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 1000\n",
      "Epoch: 18\n",
      "[Train]\t J_a: 235.06, accuracy: 1.00\n",
      "[Test]\t J_a: 248.68, accuracy: 0.9629\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 1000\n",
      "Epoch: 19\n",
      "[Train]\t J_a: 234.74, accuracy: 1.00\n",
      "[Test]\t J_a: 247.94, accuracy: 0.9643\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 1000\n",
      "Epoch: 20\n",
      "[Train]\t J_a: 234.46, accuracy: 1.00\n",
      "[Test]\t J_a: 247.75, accuracy: 0.9661\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 1000\n",
      "Epoch: 21\n",
      "[Train]\t J_a: 233.69, accuracy: 1.00\n",
      "[Test]\t J_a: 247.44, accuracy: 0.9649\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 1000\n",
      "Epoch: 22\n",
      "[Train]\t J_a: 232.91, accuracy: 1.00\n",
      "[Test]\t J_a: 247.12, accuracy: 0.9640\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 1000\n",
      "Epoch: 23\n",
      "[Train]\t J_a: 232.88, accuracy: 1.00\n",
      "[Test]\t J_a: 246.85, accuracy: 0.9678\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 1000\n",
      "Epoch: 24\n",
      "[Train]\t J_a: 232.37, accuracy: 1.00\n",
      "[Test]\t J_a: 246.47, accuracy: 0.9672\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 1000\n",
      "Epoch: 25\n",
      "[Train]\t J_a: 232.08, accuracy: 1.00\n",
      "[Test]\t J_a: 246.73, accuracy: 0.9653\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 1000\n",
      "Epoch: 26\n",
      "[Train]\t J_a: 231.92, accuracy: 1.00\n",
      "[Test]\t J_a: 246.80, accuracy: 0.9667\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 1000\n",
      "Epoch: 27\n",
      "[Train]\t J_a: 231.52, accuracy: 1.00\n",
      "[Test]\t J_a: 246.37, accuracy: 0.9655\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 1000\n",
      "Epoch: 28\n",
      "[Train]\t J_a: 231.17, accuracy: 1.00\n",
      "[Test]\t J_a: 246.56, accuracy: 0.9664\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 1000\n",
      "Epoch: 29\n",
      "[Train]\t J_a: 230.62, accuracy: 1.00\n",
      "[Test]\t J_a: 246.16, accuracy: 0.9664\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 1000\n",
      "Epoch: 30\n",
      "[Train]\t J_a: 230.14, accuracy: 1.00\n",
      "[Test]\t J_a: 246.44, accuracy: 0.9670\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 1000\n",
      "Epoch: 31\n",
      "[Train]\t J_a: 230.04, accuracy: 1.00\n",
      "[Test]\t J_a: 246.41, accuracy: 0.9658\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 1000\n",
      "Epoch: 32\n",
      "[Train]\t J_a: 229.90, accuracy: 1.00\n",
      "[Test]\t J_a: 245.52, accuracy: 0.9660\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 1000\n",
      "Epoch: 33\n",
      "[Train]\t J_a: 229.93, accuracy: 1.00\n",
      "[Test]\t J_a: 246.53, accuracy: 0.9651\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 1000\n",
      "Epoch: 34\n",
      "[Train]\t J_a: 229.56, accuracy: 1.00\n",
      "[Test]\t J_a: 246.01, accuracy: 0.9668\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 1000\n",
      "Epoch: 35\n",
      "[Train]\t J_a: 229.49, accuracy: 1.00\n",
      "[Test]\t J_a: 245.88, accuracy: 0.9669\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 1000\n",
      "Epoch: 36\n",
      "[Train]\t J_a: 229.18, accuracy: 1.00\n",
      "[Test]\t J_a: 246.56, accuracy: 0.9664\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 1000\n",
      "Epoch: 37\n",
      "[Train]\t J_a: 228.66, accuracy: 1.00\n",
      "[Test]\t J_a: 245.65, accuracy: 0.9688\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 1000\n",
      "Epoch: 38\n",
      "[Train]\t J_a: 228.83, accuracy: 1.00\n",
      "[Test]\t J_a: 245.55, accuracy: 0.9698\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 1000\n",
      "Epoch: 39\n",
      "[Train]\t J_a: 228.79, accuracy: 1.00\n",
      "[Test]\t J_a: 245.68, accuracy: 0.9694\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 1000\n",
      "Epoch: 40\n",
      "[Train]\t J_a: 228.16, accuracy: 1.00\n",
      "[Test]\t J_a: 245.74, accuracy: 0.9695\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 1000\n",
      "Epoch: 41\n",
      "[Train]\t J_a: 228.29, accuracy: 1.00\n",
      "[Test]\t J_a: 246.22, accuracy: 0.9657\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 1000\n",
      "Epoch: 42\n",
      "[Train]\t J_a: 228.14, accuracy: 1.00\n",
      "[Test]\t J_a: 245.59, accuracy: 0.9698\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 1000\n",
      "Epoch: 43\n",
      "[Train]\t J_a: 227.87, accuracy: 1.00\n",
      "[Test]\t J_a: 245.59, accuracy: 0.9700\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 1000\n",
      "Epoch: 44\n",
      "[Train]\t J_a: 228.02, accuracy: 1.00\n",
      "[Test]\t J_a: 245.74, accuracy: 0.9691\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 1000\n",
      "Epoch: 45\n",
      "[Train]\t J_a: 227.51, accuracy: 1.00\n",
      "[Test]\t J_a: 245.37, accuracy: 0.9697\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 1000\n",
      "Epoch: 46\n",
      "[Train]\t J_a: 227.49, accuracy: 1.00\n",
      "[Test]\t J_a: 245.72, accuracy: 0.9677\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 1000\n",
      "Epoch: 47\n",
      "[Train]\t J_a: 227.22, accuracy: 1.00\n",
      "[Test]\t J_a: 245.04, accuracy: 0.9720\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 1000\n",
      "Epoch: 48\n",
      "[Train]\t J_a: 227.21, accuracy: 1.00\n",
      "[Test]\t J_a: 245.15, accuracy: 0.9667\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 1000\n",
      "Epoch: 49\n",
      "[Train]\t J_a: 227.20, accuracy: 1.00\n",
      "[Test]\t J_a: 245.46, accuracy: 0.9696\n",
      "./saved_data/MNIST_X_train_labelled_bald_100_111.pt\n",
      "./saved_data/MNIST_y_train_labelled_bald_100_111.pt\n",
      "1000 1000\n",
      "./saved_data/MNIST_X_train_unlabelled_bald_100_111.pt\n",
      "./saved_data/MNIST_y_train_unlabelled_bald_100_111.pt\n",
      "59000 59000\n",
      "./saved_data/MNIST_X_test_111.pt\n",
      "./saved_data/MNIST_y_test_111.pt\n",
      "10000 10000\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 1000\n",
      "Epoch: 0\n",
      "[Train]\t J_a: 402.92, accuracy: 0.71\n",
      "[Test]\t J_a: 314.29, accuracy: 0.9692\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 1000\n",
      "Epoch: 1\n",
      "[Train]\t J_a: 323.64, accuracy: 0.93\n",
      "[Test]\t J_a: 291.34, accuracy: 0.9721\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 1000\n",
      "Epoch: 2\n",
      "[Train]\t J_a: 304.98, accuracy: 0.96\n",
      "[Test]\t J_a: 280.04, accuracy: 0.9742\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 1000\n",
      "Epoch: 3\n",
      "[Train]\t J_a: 295.57, accuracy: 0.97\n",
      "[Test]\t J_a: 273.62, accuracy: 0.9758\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 1000\n",
      "Epoch: 4\n",
      "[Train]\t J_a: 288.68, accuracy: 0.98\n",
      "[Test]\t J_a: 268.61, accuracy: 0.9750\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 1000\n",
      "Epoch: 5\n",
      "[Train]\t J_a: 284.45, accuracy: 0.98\n",
      "[Test]\t J_a: 265.59, accuracy: 0.9781\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 1000\n",
      "Epoch: 6\n",
      "[Train]\t J_a: 280.38, accuracy: 0.98\n",
      "[Test]\t J_a: 261.84, accuracy: 0.9791\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 1000\n",
      "Epoch: 7\n",
      "[Train]\t J_a: 277.23, accuracy: 0.98\n",
      "[Test]\t J_a: 259.66, accuracy: 0.9782\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 1000\n",
      "Epoch: 8\n",
      "[Train]\t J_a: 274.72, accuracy: 0.99\n",
      "[Test]\t J_a: 257.93, accuracy: 0.9795\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 1000\n",
      "Epoch: 9\n",
      "[Train]\t J_a: 272.19, accuracy: 0.99\n",
      "[Test]\t J_a: 256.30, accuracy: 0.9783\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 1000\n",
      "Epoch: 10\n",
      "[Train]\t J_a: 270.48, accuracy: 0.99\n",
      "[Test]\t J_a: 255.62, accuracy: 0.9793\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 1000\n",
      "Epoch: 11\n",
      "[Train]\t J_a: 268.80, accuracy: 0.99\n",
      "[Test]\t J_a: 254.27, accuracy: 0.9789\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 1000\n",
      "Epoch: 12\n",
      "[Train]\t J_a: 267.39, accuracy: 0.99\n",
      "[Test]\t J_a: 253.90, accuracy: 0.9794\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 1000\n",
      "Epoch: 13\n",
      "[Train]\t J_a: 265.96, accuracy: 0.99\n",
      "[Test]\t J_a: 253.15, accuracy: 0.9798\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 1000\n",
      "Epoch: 14\n",
      "[Train]\t J_a: 264.77, accuracy: 0.99\n",
      "[Test]\t J_a: 252.74, accuracy: 0.9802\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 1000\n",
      "Epoch: 15\n",
      "[Train]\t J_a: 263.68, accuracy: 0.99\n",
      "[Test]\t J_a: 251.78, accuracy: 0.9792\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 1000\n",
      "Epoch: 16\n",
      "[Train]\t J_a: 262.71, accuracy: 0.99\n",
      "[Test]\t J_a: 252.33, accuracy: 0.9799\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 1000\n",
      "Epoch: 17\n",
      "[Train]\t J_a: 261.69, accuracy: 0.99\n",
      "[Test]\t J_a: 251.38, accuracy: 0.9802\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 1000\n",
      "Epoch: 18\n",
      "[Train]\t J_a: 260.88, accuracy: 0.99\n",
      "[Test]\t J_a: 250.97, accuracy: 0.9811\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 1000\n",
      "Epoch: 19\n",
      "[Train]\t J_a: 259.94, accuracy: 0.99\n",
      "[Test]\t J_a: 250.22, accuracy: 0.9806\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 1000\n",
      "Epoch: 20\n",
      "[Train]\t J_a: 259.20, accuracy: 0.99\n",
      "[Test]\t J_a: 250.96, accuracy: 0.9802\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 1000\n",
      "Epoch: 21\n",
      "[Train]\t J_a: 258.75, accuracy: 0.99\n",
      "[Test]\t J_a: 250.08, accuracy: 0.9807\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 1000\n",
      "Epoch: 22\n",
      "[Train]\t J_a: 257.98, accuracy: 0.99\n",
      "[Test]\t J_a: 250.12, accuracy: 0.9789\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 1000\n",
      "Epoch: 23\n",
      "[Train]\t J_a: 257.17, accuracy: 0.99\n",
      "[Test]\t J_a: 249.80, accuracy: 0.9813\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 1000\n",
      "Epoch: 24\n",
      "[Train]\t J_a: 256.83, accuracy: 0.99\n",
      "[Test]\t J_a: 250.01, accuracy: 0.9812\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 1000\n",
      "Epoch: 25\n",
      "[Train]\t J_a: 255.91, accuracy: 0.99\n",
      "[Test]\t J_a: 249.83, accuracy: 0.9802\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 1000\n",
      "Epoch: 26\n",
      "[Train]\t J_a: 255.94, accuracy: 0.99\n",
      "[Test]\t J_a: 249.36, accuracy: 0.9819\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 1000\n",
      "Epoch: 27\n",
      "[Train]\t J_a: 255.45, accuracy: 0.99\n",
      "[Test]\t J_a: 249.22, accuracy: 0.9816\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 1000\n",
      "Epoch: 28\n",
      "[Train]\t J_a: 254.74, accuracy: 0.99\n",
      "[Test]\t J_a: 249.60, accuracy: 0.9818\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 1000\n",
      "Epoch: 29\n",
      "[Train]\t J_a: 254.21, accuracy: 0.99\n",
      "[Test]\t J_a: 249.38, accuracy: 0.9804\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 1000\n",
      "Epoch: 30\n",
      "[Train]\t J_a: 254.31, accuracy: 0.99\n",
      "[Test]\t J_a: 249.45, accuracy: 0.9806\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 1000\n",
      "Epoch: 31\n",
      "[Train]\t J_a: 253.43, accuracy: 0.99\n",
      "[Test]\t J_a: 248.90, accuracy: 0.9821\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 1000\n",
      "Epoch: 32\n",
      "[Train]\t J_a: 253.37, accuracy: 0.99\n",
      "[Test]\t J_a: 248.98, accuracy: 0.9829\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 1000\n",
      "Epoch: 33\n",
      "[Train]\t J_a: 252.99, accuracy: 0.99\n",
      "[Test]\t J_a: 248.99, accuracy: 0.9837\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 1000\n",
      "Epoch: 34\n",
      "[Train]\t J_a: 252.90, accuracy: 0.99\n",
      "[Test]\t J_a: 248.55, accuracy: 0.9825\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 1000\n",
      "Epoch: 35\n",
      "[Train]\t J_a: 252.65, accuracy: 0.99\n",
      "[Test]\t J_a: 248.81, accuracy: 0.9820\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 1000\n",
      "Epoch: 36\n",
      "[Train]\t J_a: 252.25, accuracy: 0.99\n",
      "[Test]\t J_a: 248.54, accuracy: 0.9834\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 1000\n",
      "Epoch: 37\n",
      "[Train]\t J_a: 251.93, accuracy: 0.99\n",
      "[Test]\t J_a: 249.03, accuracy: 0.9814\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 1000\n",
      "Epoch: 38\n",
      "[Train]\t J_a: 251.59, accuracy: 0.99\n",
      "[Test]\t J_a: 248.31, accuracy: 0.9828\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 1000\n",
      "Epoch: 39\n",
      "[Train]\t J_a: 251.01, accuracy: 0.99\n",
      "[Test]\t J_a: 248.46, accuracy: 0.9823\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 1000\n",
      "Epoch: 40\n",
      "[Train]\t J_a: 251.07, accuracy: 0.99\n",
      "[Test]\t J_a: 248.56, accuracy: 0.9852\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 1000\n",
      "Epoch: 41\n",
      "[Train]\t J_a: 250.91, accuracy: 1.00\n",
      "[Test]\t J_a: 248.53, accuracy: 0.9828\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 1000\n",
      "Epoch: 42\n",
      "[Train]\t J_a: 250.74, accuracy: 0.99\n",
      "[Test]\t J_a: 248.69, accuracy: 0.9840\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 1000\n",
      "Epoch: 43\n",
      "[Train]\t J_a: 250.35, accuracy: 1.00\n",
      "[Test]\t J_a: 248.87, accuracy: 0.9852\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 1000\n",
      "Epoch: 44\n",
      "[Train]\t J_a: 250.37, accuracy: 0.99\n",
      "[Test]\t J_a: 248.59, accuracy: 0.9841\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 1000\n",
      "Epoch: 45\n",
      "[Train]\t J_a: 250.16, accuracy: 1.00\n",
      "[Test]\t J_a: 249.08, accuracy: 0.9832\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 1000\n",
      "Epoch: 46\n",
      "[Train]\t J_a: 249.74, accuracy: 1.00\n",
      "[Test]\t J_a: 248.47, accuracy: 0.9829\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 1000\n",
      "Epoch: 47\n",
      "[Train]\t J_a: 249.71, accuracy: 1.00\n",
      "[Test]\t J_a: 248.90, accuracy: 0.9835\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 1000\n",
      "Epoch: 48\n",
      "[Train]\t J_a: 249.50, accuracy: 1.00\n",
      "[Test]\t J_a: 248.74, accuracy: 0.9824\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 1000\n",
      "Epoch: 49\n",
      "[Train]\t J_a: 249.55, accuracy: 1.00\n",
      "[Test]\t J_a: 248.20, accuracy: 0.9840\n",
      "./saved_data/MNIST_X_train_labelled_random_100_111.pt\n",
      "./saved_data/MNIST_y_train_labelled_random_100_111.pt\n",
      "1100 1100\n",
      "./saved_data/MNIST_X_train_unlabelled_random_100_111.pt\n",
      "./saved_data/MNIST_y_train_unlabelled_random_100_111.pt\n",
      "58900 58900\n",
      "./saved_data/MNIST_X_test_111.pt\n",
      "./saved_data/MNIST_y_test_111.pt\n",
      "10000 10000\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 1100\n",
      "Epoch: 0\n",
      "[Train]\t J_a: 375.89, accuracy: 0.91\n",
      "[Test]\t J_a: 309.61, accuracy: 0.9324\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 1100\n",
      "Epoch: 1\n",
      "[Train]\t J_a: 296.40, accuracy: 0.98\n",
      "[Test]\t J_a: 287.95, accuracy: 0.9473\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 1100\n",
      "Epoch: 2\n",
      "[Train]\t J_a: 279.47, accuracy: 0.99\n",
      "[Test]\t J_a: 276.36, accuracy: 0.9504\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 1100\n",
      "Epoch: 3\n",
      "[Train]\t J_a: 268.35, accuracy: 0.99\n",
      "[Test]\t J_a: 269.19, accuracy: 0.9461\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 1100\n",
      "Epoch: 4\n",
      "[Train]\t J_a: 261.29, accuracy: 0.99\n",
      "[Test]\t J_a: 264.91, accuracy: 0.9491\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 1100\n",
      "Epoch: 5\n",
      "[Train]\t J_a: 256.21, accuracy: 0.99\n",
      "[Test]\t J_a: 260.90, accuracy: 0.9521\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 1100\n",
      "Epoch: 6\n",
      "[Train]\t J_a: 252.85, accuracy: 0.99\n",
      "[Test]\t J_a: 258.01, accuracy: 0.9566\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 1100\n",
      "Epoch: 7\n",
      "[Train]\t J_a: 249.71, accuracy: 1.00\n",
      "[Test]\t J_a: 256.31, accuracy: 0.9497\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 1100\n",
      "Epoch: 8\n",
      "[Train]\t J_a: 246.99, accuracy: 1.00\n",
      "[Test]\t J_a: 255.57, accuracy: 0.9537\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 1100\n",
      "Epoch: 9\n",
      "[Train]\t J_a: 245.50, accuracy: 1.00\n",
      "[Test]\t J_a: 253.93, accuracy: 0.9579\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 1100\n",
      "Epoch: 10\n",
      "[Train]\t J_a: 243.82, accuracy: 1.00\n",
      "[Test]\t J_a: 252.70, accuracy: 0.9550\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 1100\n",
      "Epoch: 11\n",
      "[Train]\t J_a: 242.96, accuracy: 1.00\n",
      "[Test]\t J_a: 251.95, accuracy: 0.9563\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 1100\n",
      "Epoch: 12\n",
      "[Train]\t J_a: 241.50, accuracy: 1.00\n",
      "[Test]\t J_a: 251.02, accuracy: 0.9606\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 1100\n",
      "Epoch: 13\n",
      "[Train]\t J_a: 240.51, accuracy: 1.00\n",
      "[Test]\t J_a: 251.20, accuracy: 0.9575\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 1100\n",
      "Epoch: 14\n",
      "[Train]\t J_a: 239.39, accuracy: 1.00\n",
      "[Test]\t J_a: 249.53, accuracy: 0.9601\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 1100\n",
      "Epoch: 15\n",
      "[Train]\t J_a: 238.62, accuracy: 1.00\n",
      "[Test]\t J_a: 249.41, accuracy: 0.9604\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 1100\n",
      "Epoch: 16\n",
      "[Train]\t J_a: 238.14, accuracy: 1.00\n",
      "[Test]\t J_a: 249.04, accuracy: 0.9628\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 1100\n",
      "Epoch: 17\n",
      "[Train]\t J_a: 236.98, accuracy: 1.00\n",
      "[Test]\t J_a: 248.74, accuracy: 0.9599\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 1100\n",
      "Epoch: 18\n",
      "[Train]\t J_a: 236.63, accuracy: 1.00\n",
      "[Test]\t J_a: 248.91, accuracy: 0.9600\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 1100\n",
      "Epoch: 19\n",
      "[Train]\t J_a: 235.92, accuracy: 1.00\n",
      "[Test]\t J_a: 248.30, accuracy: 0.9610\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 1100\n",
      "Epoch: 20\n",
      "[Train]\t J_a: 235.56, accuracy: 1.00\n",
      "[Test]\t J_a: 248.35, accuracy: 0.9604\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 1100\n",
      "Epoch: 21\n",
      "[Train]\t J_a: 235.28, accuracy: 1.00\n",
      "[Test]\t J_a: 247.77, accuracy: 0.9646\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 1100\n",
      "Epoch: 22\n",
      "[Train]\t J_a: 234.95, accuracy: 1.00\n",
      "[Test]\t J_a: 247.65, accuracy: 0.9625\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 1100\n",
      "Epoch: 23\n",
      "[Train]\t J_a: 234.30, accuracy: 1.00\n",
      "[Test]\t J_a: 247.59, accuracy: 0.9646\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 1100\n",
      "Epoch: 24\n",
      "[Train]\t J_a: 234.47, accuracy: 1.00\n",
      "[Test]\t J_a: 247.58, accuracy: 0.9650\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 1100\n",
      "Epoch: 25\n",
      "[Train]\t J_a: 233.24, accuracy: 1.00\n",
      "[Test]\t J_a: 246.81, accuracy: 0.9655\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 1100\n",
      "Epoch: 26\n",
      "[Train]\t J_a: 232.95, accuracy: 1.00\n",
      "[Test]\t J_a: 247.25, accuracy: 0.9653\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 1100\n",
      "Epoch: 27\n",
      "[Train]\t J_a: 232.55, accuracy: 1.00\n",
      "[Test]\t J_a: 246.32, accuracy: 0.9663\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 1100\n",
      "Epoch: 28\n",
      "[Train]\t J_a: 232.17, accuracy: 1.00\n",
      "[Test]\t J_a: 246.72, accuracy: 0.9666\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 1100\n",
      "Epoch: 29\n",
      "[Train]\t J_a: 231.58, accuracy: 1.00\n",
      "[Test]\t J_a: 246.50, accuracy: 0.9656\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 1100\n",
      "Epoch: 30\n",
      "[Train]\t J_a: 231.35, accuracy: 1.00\n",
      "[Test]\t J_a: 246.68, accuracy: 0.9666\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 1100\n",
      "Epoch: 31\n",
      "[Train]\t J_a: 231.03, accuracy: 1.00\n",
      "[Test]\t J_a: 246.04, accuracy: 0.9674\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 1100\n",
      "Epoch: 32\n",
      "[Train]\t J_a: 231.09, accuracy: 1.00\n",
      "[Test]\t J_a: 246.23, accuracy: 0.9665\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 1100\n",
      "Epoch: 33\n",
      "[Train]\t J_a: 230.74, accuracy: 1.00\n",
      "[Test]\t J_a: 246.39, accuracy: 0.9673\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 1100\n",
      "Epoch: 34\n",
      "[Train]\t J_a: 230.70, accuracy: 1.00\n",
      "[Test]\t J_a: 245.98, accuracy: 0.9667\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 1100\n",
      "Epoch: 35\n",
      "[Train]\t J_a: 230.45, accuracy: 1.00\n",
      "[Test]\t J_a: 246.17, accuracy: 0.9653\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 1100\n",
      "Epoch: 36\n",
      "[Train]\t J_a: 230.60, accuracy: 1.00\n",
      "[Test]\t J_a: 246.00, accuracy: 0.9653\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 1100\n",
      "Epoch: 37\n",
      "[Train]\t J_a: 229.62, accuracy: 1.00\n",
      "[Test]\t J_a: 245.89, accuracy: 0.9664\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 1100\n",
      "Epoch: 38\n",
      "[Train]\t J_a: 230.04, accuracy: 1.00\n",
      "[Test]\t J_a: 245.71, accuracy: 0.9667\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 1100\n",
      "Epoch: 39\n",
      "[Train]\t J_a: 229.92, accuracy: 1.00\n",
      "[Test]\t J_a: 245.99, accuracy: 0.9672\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 1100\n",
      "Epoch: 40\n",
      "[Train]\t J_a: 229.61, accuracy: 1.00\n",
      "[Test]\t J_a: 245.67, accuracy: 0.9673\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 1100\n",
      "Epoch: 41\n",
      "[Train]\t J_a: 229.05, accuracy: 1.00\n",
      "[Test]\t J_a: 245.72, accuracy: 0.9669\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 1100\n",
      "Epoch: 42\n",
      "[Train]\t J_a: 228.86, accuracy: 1.00\n",
      "[Test]\t J_a: 245.33, accuracy: 0.9671\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 1100\n",
      "Epoch: 43\n",
      "[Train]\t J_a: 229.11, accuracy: 1.00\n",
      "[Test]\t J_a: 245.71, accuracy: 0.9666\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 1100\n",
      "Epoch: 44\n",
      "[Train]\t J_a: 228.61, accuracy: 1.00\n",
      "[Test]\t J_a: 244.51, accuracy: 0.9698\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 1100\n",
      "Epoch: 45\n",
      "[Train]\t J_a: 228.41, accuracy: 1.00\n",
      "[Test]\t J_a: 244.70, accuracy: 0.9703\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 1100\n",
      "Epoch: 46\n",
      "[Train]\t J_a: 228.50, accuracy: 1.00\n",
      "[Test]\t J_a: 245.31, accuracy: 0.9680\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 1100\n",
      "Epoch: 47\n",
      "[Train]\t J_a: 228.18, accuracy: 1.00\n",
      "[Test]\t J_a: 245.29, accuracy: 0.9677\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 1100\n",
      "Epoch: 48\n",
      "[Train]\t J_a: 228.44, accuracy: 1.00\n",
      "[Test]\t J_a: 245.13, accuracy: 0.9666\n",
      "Dataset: MNIST, Seed: 111, Algorithm: random, Cap: 1100\n",
      "Epoch: 49\n",
      "[Train]\t J_a: 227.91, accuracy: 1.00\n",
      "[Test]\t J_a: 244.97, accuracy: 0.9679\n",
      "./saved_data/MNIST_X_train_labelled_bald_100_111.pt\n",
      "./saved_data/MNIST_y_train_labelled_bald_100_111.pt\n",
      "1100 1100\n",
      "./saved_data/MNIST_X_train_unlabelled_bald_100_111.pt\n",
      "./saved_data/MNIST_y_train_unlabelled_bald_100_111.pt\n",
      "58900 58900\n",
      "./saved_data/MNIST_X_test_111.pt\n",
      "./saved_data/MNIST_y_test_111.pt\n",
      "10000 10000\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 1100\n",
      "Epoch: 0\n",
      "[Train]\t J_a: 402.87, accuracy: 0.70\n",
      "[Test]\t J_a: 313.16, accuracy: 0.9672\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 1100\n",
      "Epoch: 1\n",
      "[Train]\t J_a: 322.79, accuracy: 0.92\n",
      "[Test]\t J_a: 292.08, accuracy: 0.9713\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 1100\n",
      "Epoch: 2\n",
      "[Train]\t J_a: 305.07, accuracy: 0.96\n",
      "[Test]\t J_a: 282.03, accuracy: 0.9742\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 1100\n",
      "Epoch: 3\n",
      "[Train]\t J_a: 296.52, accuracy: 0.97\n",
      "[Test]\t J_a: 274.70, accuracy: 0.9756\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 1100\n",
      "Epoch: 4\n",
      "[Train]\t J_a: 290.34, accuracy: 0.97\n",
      "[Test]\t J_a: 269.62, accuracy: 0.9763\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 1100\n",
      "Epoch: 5\n",
      "[Train]\t J_a: 284.27, accuracy: 0.98\n",
      "[Test]\t J_a: 265.21, accuracy: 0.9769\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 1100\n",
      "Epoch: 6\n",
      "[Train]\t J_a: 280.97, accuracy: 0.98\n",
      "[Test]\t J_a: 262.36, accuracy: 0.9786\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 1100\n",
      "Epoch: 7\n",
      "[Train]\t J_a: 278.14, accuracy: 0.98\n",
      "[Test]\t J_a: 260.08, accuracy: 0.9770\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 1100\n",
      "Epoch: 8\n",
      "[Train]\t J_a: 275.15, accuracy: 0.98\n",
      "[Test]\t J_a: 258.39, accuracy: 0.9777\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 1100\n",
      "Epoch: 9\n",
      "[Train]\t J_a: 273.20, accuracy: 0.99\n",
      "[Test]\t J_a: 257.34, accuracy: 0.9786\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 1100\n",
      "Epoch: 10\n",
      "[Train]\t J_a: 271.13, accuracy: 0.99\n",
      "[Test]\t J_a: 255.98, accuracy: 0.9795\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 1100\n",
      "Epoch: 11\n",
      "[Train]\t J_a: 269.65, accuracy: 0.99\n",
      "[Test]\t J_a: 254.80, accuracy: 0.9779\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 1100\n",
      "Epoch: 12\n",
      "[Train]\t J_a: 267.53, accuracy: 0.99\n",
      "[Test]\t J_a: 253.71, accuracy: 0.9789\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 1100\n",
      "Epoch: 13\n",
      "[Train]\t J_a: 266.33, accuracy: 0.99\n",
      "[Test]\t J_a: 253.86, accuracy: 0.9791\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 1100\n",
      "Epoch: 14\n",
      "[Train]\t J_a: 265.79, accuracy: 0.99\n",
      "[Test]\t J_a: 252.23, accuracy: 0.9791\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 1100\n",
      "Epoch: 15\n",
      "[Train]\t J_a: 264.47, accuracy: 0.99\n",
      "[Test]\t J_a: 253.44, accuracy: 0.9801\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 1100\n",
      "Epoch: 16\n",
      "[Train]\t J_a: 263.95, accuracy: 0.99\n",
      "[Test]\t J_a: 251.63, accuracy: 0.9810\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 1100\n",
      "Epoch: 17\n",
      "[Train]\t J_a: 262.82, accuracy: 0.99\n",
      "[Test]\t J_a: 251.18, accuracy: 0.9800\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 1100\n",
      "Epoch: 18\n",
      "[Train]\t J_a: 262.19, accuracy: 0.99\n",
      "[Test]\t J_a: 251.55, accuracy: 0.9784\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 1100\n",
      "Epoch: 19\n",
      "[Train]\t J_a: 261.17, accuracy: 0.99\n",
      "[Test]\t J_a: 250.65, accuracy: 0.9812\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 1100\n",
      "Epoch: 20\n",
      "[Train]\t J_a: 260.49, accuracy: 0.99\n",
      "[Test]\t J_a: 251.12, accuracy: 0.9810\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 1100\n",
      "Epoch: 21\n",
      "[Train]\t J_a: 260.34, accuracy: 0.99\n",
      "[Test]\t J_a: 250.55, accuracy: 0.9829\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 1100\n",
      "Epoch: 22\n",
      "[Train]\t J_a: 258.70, accuracy: 0.99\n",
      "[Test]\t J_a: 250.26, accuracy: 0.9798\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 1100\n",
      "Epoch: 23\n",
      "[Train]\t J_a: 257.98, accuracy: 0.99\n",
      "[Test]\t J_a: 250.21, accuracy: 0.9815\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 1100\n",
      "Epoch: 24\n",
      "[Train]\t J_a: 258.53, accuracy: 0.99\n",
      "[Test]\t J_a: 249.31, accuracy: 0.9820\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 1100\n",
      "Epoch: 25\n",
      "[Train]\t J_a: 257.67, accuracy: 0.99\n",
      "[Test]\t J_a: 249.38, accuracy: 0.9824\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 1100\n",
      "Epoch: 26\n",
      "[Train]\t J_a: 257.45, accuracy: 0.99\n",
      "[Test]\t J_a: 249.58, accuracy: 0.9829\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 1100\n",
      "Epoch: 27\n",
      "[Train]\t J_a: 256.21, accuracy: 0.99\n",
      "[Test]\t J_a: 248.98, accuracy: 0.9830\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 1100\n",
      "Epoch: 28\n",
      "[Train]\t J_a: 256.13, accuracy: 0.99\n",
      "[Test]\t J_a: 249.13, accuracy: 0.9813\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 1100\n",
      "Epoch: 29\n",
      "[Train]\t J_a: 256.46, accuracy: 0.99\n",
      "[Test]\t J_a: 249.16, accuracy: 0.9827\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 1100\n",
      "Epoch: 30\n",
      "[Train]\t J_a: 255.02, accuracy: 0.99\n",
      "[Test]\t J_a: 248.96, accuracy: 0.9835\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 1100\n",
      "Epoch: 31\n",
      "[Train]\t J_a: 254.90, accuracy: 0.99\n",
      "[Test]\t J_a: 249.17, accuracy: 0.9830\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 1100\n",
      "Epoch: 32\n",
      "[Train]\t J_a: 254.12, accuracy: 0.99\n",
      "[Test]\t J_a: 248.57, accuracy: 0.9807\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 1100\n",
      "Epoch: 33\n",
      "[Train]\t J_a: 253.88, accuracy: 0.99\n",
      "[Test]\t J_a: 248.51, accuracy: 0.9849\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 1100\n",
      "Epoch: 34\n",
      "[Train]\t J_a: 253.94, accuracy: 0.99\n",
      "[Test]\t J_a: 249.28, accuracy: 0.9835\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 1100\n",
      "Epoch: 35\n",
      "[Train]\t J_a: 253.22, accuracy: 0.99\n",
      "[Test]\t J_a: 249.01, accuracy: 0.9823\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 1100\n",
      "Epoch: 36\n",
      "[Train]\t J_a: 253.84, accuracy: 0.99\n",
      "[Test]\t J_a: 248.85, accuracy: 0.9834\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 1100\n",
      "Epoch: 37\n",
      "[Train]\t J_a: 253.58, accuracy: 0.99\n",
      "[Test]\t J_a: 248.55, accuracy: 0.9819\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 1100\n",
      "Epoch: 38\n",
      "[Train]\t J_a: 253.88, accuracy: 0.99\n",
      "[Test]\t J_a: 248.61, accuracy: 0.9829\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 1100\n",
      "Epoch: 39\n",
      "[Train]\t J_a: 252.54, accuracy: 0.99\n",
      "[Test]\t J_a: 248.06, accuracy: 0.9853\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 1100\n",
      "Epoch: 40\n",
      "[Train]\t J_a: 252.33, accuracy: 0.99\n",
      "[Test]\t J_a: 248.24, accuracy: 0.9835\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 1100\n",
      "Epoch: 41\n",
      "[Train]\t J_a: 251.98, accuracy: 0.99\n",
      "[Test]\t J_a: 248.02, accuracy: 0.9829\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 1100\n",
      "Epoch: 42\n",
      "[Train]\t J_a: 252.20, accuracy: 0.99\n",
      "[Test]\t J_a: 247.99, accuracy: 0.9845\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 1100\n",
      "Epoch: 43\n",
      "[Train]\t J_a: 251.44, accuracy: 0.99\n",
      "[Test]\t J_a: 247.71, accuracy: 0.9853\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 1100\n",
      "Epoch: 44\n",
      "[Train]\t J_a: 251.64, accuracy: 0.99\n",
      "[Test]\t J_a: 248.00, accuracy: 0.9848\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 1100\n",
      "Epoch: 45\n",
      "[Train]\t J_a: 251.46, accuracy: 0.99\n",
      "[Test]\t J_a: 248.34, accuracy: 0.9829\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 1100\n",
      "Epoch: 46\n",
      "[Train]\t J_a: 251.72, accuracy: 0.99\n",
      "[Test]\t J_a: 248.37, accuracy: 0.9835\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 1100\n",
      "Epoch: 47\n",
      "[Train]\t J_a: 251.56, accuracy: 0.99\n",
      "[Test]\t J_a: 247.58, accuracy: 0.9835\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 1100\n",
      "Epoch: 48\n",
      "[Train]\t J_a: 250.34, accuracy: 0.99\n",
      "[Test]\t J_a: 247.61, accuracy: 0.9838\n",
      "Dataset: MNIST, Seed: 111, Algorithm: bald, Cap: 1100\n",
      "Epoch: 49\n",
      "[Train]\t J_a: 250.63, accuracy: 1.00\n",
      "[Test]\t J_a: 247.70, accuracy: 0.9836\n"
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "SSL_progressive_performance = {'random':[],\n",
    "                                'bald':[]}\n",
    "\n",
    "for cap in range(100,1101,100):\n",
    "    SSL_metrics = {'random':{'train_loss_history':None,\n",
    "                                'train_accuracy_history': None,\n",
    "                                'test_loss_history': None,\n",
    "                                'test_accuracy_history': None},\n",
    "                    'bald':{'train_loss_history':None,\n",
    "                                'train_accuracy_history': None,\n",
    "                                'test_loss_history': None,\n",
    "                                'test_accuracy_history': None},\n",
    "                    }\n",
    "    for algorithm in SSL_metrics.keys():\n",
    "        \n",
    "        # Only use INITIAL_LABEL_PER_CLASS labelled examples per class\n",
    "        # The rest of the data is unlabelled.\n",
    "        labelled, unlabelled, test = get_dataset(location=\"{BASE_DIR}/saved_data\", dataset = DATASET, seed = SEED, batch_size=64,\n",
    "                                    labels_per_class=INITIAL_LABEL_PER_CLASS, algorithm=algorithm, data_size_cap=cap)\n",
    "\n",
    "        # Prepare the model and the optimizer\n",
    "        model = DeepGenerativeModel([x_dim, y_dim, z_dim, h_dim])\n",
    "\n",
    "        if cuda: model = model.cuda()\n",
    "        alpha = 0.1 * len(unlabelled) / len(labelled)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=3e-4, betas=(0.9, 0.999))\n",
    "\n",
    "        # Prepare a sampler and the elbo object\n",
    "        # You can use importance weighted samples [Burda, 2015] to get a better estimate\n",
    "        # on the log-likelihood.\n",
    "        sampler = ImportanceWeightedSampler(mc=1, iw=1)\n",
    "        elbo = SVI(model, likelihood=binary_cross_entropy, sampler=sampler)\n",
    "\n",
    "\n",
    "        SSL_train_loss_history = []\n",
    "        SSL_train_accuracy_history = []\n",
    "        SSL_test_loss_history = []\n",
    "        SSL_test_accuracy_history = []\n",
    "\n",
    "        for epoch in range(SSL_EPOCHS):\n",
    "            model.train()\n",
    "            total_loss, accuracy = (0, 0)\n",
    "            for (x, y), (u, _) in zip(cycle(labelled), unlabelled):\n",
    "                # Wrap in variables\n",
    "                x, y, u = Variable(x).cuda(device=0), Variable(y).cuda(device=0), Variable(u).cuda(device=0)\n",
    "\n",
    "                J_alpha, logits = calculate_J_alpha(x.reshape(-1, 784), y, u, alpha, model)\n",
    "\n",
    "                J_alpha.backward()\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                total_loss += J_alpha.data\n",
    "                accuracy += torch.mean((torch.max(logits, 1)[1].data == torch.max(y, 1)[1].data).float())\n",
    "                \n",
    "            if epoch % 1 == 0:\n",
    "                model.eval()\n",
    "                m = len(unlabelled)\n",
    "\n",
    "                train_loss = total_loss/m\n",
    "                train_accuracy = accuracy/m\n",
    "\n",
    "                SSL_train_loss_history.append(train_loss)\n",
    "                SSL_train_accuracy_history.append(train_accuracy)\n",
    "                print(\"Dataset: {}, Seed: {}, Algorithm: {}, Cap: {}\".format(DATASET, SEED, algorithm, cap))\n",
    "                print(\"Epoch: {}\".format(epoch))\n",
    "                print(\"[Train]\\t J_a: {:.2f}, accuracy: {:.2f}\".format(train_loss, train_accuracy))\n",
    "\n",
    "                total_loss, accuracy = (0, 0)\n",
    "                for x, y in test:\n",
    "                    x, y = Variable(x).cuda(device=0), Variable(y).cuda(device=0)\n",
    "\n",
    "                    J_alpha, logits = calculate_J_alpha(x.reshape(-1, 784), y, x.reshape(-1, 784), alpha, model)\n",
    "\n",
    "                    total_loss += J_alpha.data\n",
    "\n",
    "                    _, pred_idx = torch.max(logits, 1)\n",
    "                    _, lab_idx = torch.max(y, 1)\n",
    "                    accuracy += torch.mean((torch.max(logits, 1)[1].data == torch.max(y, 1)[1].data).float())\n",
    "\n",
    "                m = len(test)\n",
    "\n",
    "                test_loss = total_loss/m\n",
    "                test_accuracy = accuracy/m\n",
    "\n",
    "                SSL_test_loss_history.append(test_loss)\n",
    "                SSL_test_accuracy_history.append(test_accuracy)\n",
    "\n",
    "                print(\"[Test]\\t J_a: {:.2f}, accuracy: {:.4f}\".format(test_loss, test_accuracy))\n",
    "\n",
    "        SSL_metrics[algorithm]['train_loss_history'] = [x.item() for x in SSL_train_loss_history]\n",
    "        SSL_metrics[algorithm]['train_accuracy_history'] = [x.item() for x in SSL_train_accuracy_history]\n",
    "        SSL_metrics[algorithm]['test_loss_history'] = [x.item() for x in SSL_test_loss_history]\n",
    "        SSL_metrics[algorithm]['test_accuracy_history'] = [x.item() for x in SSL_test_accuracy_history]\n",
    "        \n",
    "        SSL_progressive_performance[algorithm].append(SSL_metrics[algorithm]['test_accuracy_history'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d75a1218",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(SSL_progressive_performance).to_csv(f'{BASE_DIR}/saved_data/{DATASET}_SSL_progressive_performance_{N_LABELS*INITIAL_LABEL_PER_CLASS}_{SEED}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca762ec",
   "metadata": {},
   "source": [
    "## Performance Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7212d5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "SSL_perf_df = pd.read_csv(f'{BASE_DIR}/saved_data/{DATASET}_SSL_progressive_performance_{N_LABELS*INITIAL_LABEL_PER_CLASS}_{SEED}.csv')\n",
    "AL_perf_df = pd.read_csv(f'{BASE_DIR}/saved_data/{DATASET}_active_learning_performance_histories_{N_LABELS*INITIAL_LABEL_PER_CLASS}_{SEED}.csv').loc[range(0,1001, 100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc3d2947",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0.945860\n",
       "1     0.963177\n",
       "2     0.970442\n",
       "3     0.972731\n",
       "4     0.977807\n",
       "5     0.978702\n",
       "6     0.981290\n",
       "7     0.981986\n",
       "8     0.983181\n",
       "9     0.983977\n",
       "10    0.983579\n",
       "Name: bald, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SSL_perf_df['bald']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee6ba5a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0.938495\n",
       "1     0.943770\n",
       "2     0.959594\n",
       "3     0.960987\n",
       "4     0.968750\n",
       "5     0.964371\n",
       "6     0.966760\n",
       "7     0.966959\n",
       "8     0.966760\n",
       "9     0.969646\n",
       "10    0.967854\n",
       "Name: random, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SSL_perf_df['random']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96451aed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.7728\n",
       "100     0.8721\n",
       "200     0.9111\n",
       "300     0.9141\n",
       "400     0.9283\n",
       "500     0.9336\n",
       "600     0.9383\n",
       "700     0.9419\n",
       "800     0.9501\n",
       "900     0.9469\n",
       "1000    0.9542\n",
       "Name: random, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AL_perf_df['random']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "91bea664",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.7994\n",
       "100     0.9010\n",
       "200     0.9310\n",
       "300     0.9468\n",
       "400     0.9671\n",
       "500     0.9736\n",
       "600     0.9771\n",
       "700     0.9785\n",
       "800     0.9767\n",
       "900     0.9794\n",
       "1000    0.9821\n",
       "Name: bald, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AL_perf_df['bald']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ff9d1ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the SSL-AL Performance\n",
    "# Plot\n",
    "sns.set()\n",
    "\n",
    "\n",
    "fig, (ax0, ax1) = plt.subplots(nrows=1, ncols=2, sharex=True,\n",
    "                                    figsize=(16, 8))\n",
    "\n",
    "# Set y axis format\n",
    "ax0.yaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
    "# Major ticks every 20, minor ticks every 5\n",
    "major_ticks = np.arange(0, 1001,100)\n",
    "ax0.set_xticks(major_ticks)\n",
    "\n",
    "x_ticks = np.arange(0, 1001,100)\n",
    "ax0.plot(x_ticks, AL_perf_df['random'], label = 'AL')\n",
    "ax0.plot(x_ticks, SSL_perf_df['random'], label = 'AL SSL')\n",
    "ax0.set_title('Random')\n",
    "ax0.set_ylim([0.8,1])\n",
    "ax0.set_ylabel(\"Accuracy\")\n",
    "ax0.set_xlabel(\"Number of acquired data points\")\n",
    "ax0.legend()\n",
    "\n",
    "# Set y axis format\n",
    "ax1.yaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
    "# Major ticks every 20, minor ticks every 5\n",
    "major_ticks = np.arange(0, 1001,100)\n",
    "ax1.set_xticks(major_ticks)\n",
    "\n",
    "x_ticks = np.arange(0, 1001,100)\n",
    "ax1.plot(x_ticks, AL_perf_df['bald'], label = 'AL')\n",
    "ax1.plot(x_ticks, SSL_perf_df['bald'], label = 'AL SSL')\n",
    "ax1.set_title('Bald')\n",
    "ax1.set_ylim([0.8,1])\n",
    "ax1.set_ylabel(\"Accuracy\")\n",
    "ax1.set_xlabel(\"Number of acquired data points\")\n",
    "ax1.legend()\n",
    "\n",
    "fig.suptitle(\"Performance of Active Learning (AL) vs Active Learning Semi-Supervised Learning (AL SSL)\")\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f4784b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the SSL-AL Performance\n",
    "sns.set()\n",
    "\n",
    "\n",
    "fig, (ax0) = plt.subplots(\n",
    "                                    figsize=(12, 10))\n",
    "\n",
    "# Set y axis format\n",
    "ax0.yaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
    "# Major ticks every 20, minor ticks every 5\n",
    "major_ticks = np.arange(0, 1001,100)\n",
    "ax0.set_xticks(major_ticks)\n",
    "\n",
    "x_ticks = np.arange(0, 1001,100)\n",
    "ax0.plot(x_ticks, AL_perf_df['random'], '--r', label = '[Random] AL')\n",
    "ax0.plot(x_ticks, SSL_perf_df['random'], '-r', label = '[Random] AL SSL')\n",
    "ax0.plot(x_ticks, AL_perf_df['bald'], '--b', label = '[BALD] AL')\n",
    "ax0.plot(x_ticks, SSL_perf_df['bald'], '-b', label = '[BALD] AL SSL')\n",
    "ax0.set_title('Random')\n",
    "ax0.set_ylim([0.8,1])\n",
    "ax0.set_ylabel(\"Accuracy\")\n",
    "ax0.set_xlabel(\"Number of acquired data points\")\n",
    "ax0.legend()\n",
    "\n",
    "fig.suptitle(\"Performance of Active Learning (AL) vs Active Learning Semi-Supervised Learning (AL SSL)\")\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147686e9",
   "metadata": {},
   "source": [
    "# ORIGINAL DGM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "414755ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/dissertation/lib/python3.8/site-packages/torchvision/datasets/mnist.py:65: UserWarning: train_labels has been renamed targets\n",
      "  warnings.warn(\"train_labels has been renamed targets\")\n",
      "/root/anaconda3/envs/dissertation/lib/python3.8/site-packages/torchvision/datasets/mnist.py:70: UserWarning: test_labels has been renamed targets\n",
      "  warnings.warn(\"test_labels has been renamed targets\")\n"
     ]
    }
   ],
   "source": [
    "from datautils import get_mnist, get_mnist_legacy\n",
    "\n",
    "# Only use 10 labelled examples per class\n",
    "# The rest of the data is unlabelled.\n",
    "labelled, unlabelled, validation = get_mnist_legacy(location=f\"{BASE_DIR}/\", batch_size=64, labels_per_class=10)\n",
    "alpha = 0.1 * len(unlabelled) / len(labelled)\n",
    "\n",
    "def binary_cross_entropy(r, x):\n",
    "    return -torch.sum(x * torch.log(r + 1e-8) + (1 - x) * torch.log(1 - r + 1e-8), dim=-1)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4, betas=(0.9, 0.999))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b841fda7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/ucl/dissertation/./semi-supervised/models/vae.py:114: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
      "  init.xavier_normal(m.weight.data)\n"
     ]
    }
   ],
   "source": [
    "model = DeepGenerativeModel([x_dim, y_dim, z_dim, h_dim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "281624f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeepGenerativeModel(\n",
       "  (encoder): Encoder(\n",
       "    (hidden): ModuleList(\n",
       "      (0): Linear(in_features=794, out_features=256, bias=True)\n",
       "      (1): Linear(in_features=256, out_features=128, bias=True)\n",
       "    )\n",
       "    (sample): GaussianSample(\n",
       "      (mu): Linear(in_features=128, out_features=32, bias=True)\n",
       "      (log_var): Linear(in_features=128, out_features=32, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (hidden): ModuleList(\n",
       "      (0): Linear(in_features=42, out_features=128, bias=True)\n",
       "      (1): Linear(in_features=128, out_features=256, bias=True)\n",
       "    )\n",
       "    (reconstruction): Linear(in_features=256, out_features=784, bias=True)\n",
       "    (output_activation): Sigmoid()\n",
       "  )\n",
       "  (classifier): Classifier(\n",
       "    (dense): Linear(in_features=784, out_features=256, bias=True)\n",
       "    (logits): Linear(in_features=256, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e56338df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import cycle\n",
    "from inference import SVI, ImportanceWeightedSampler\n",
    "\n",
    "# You can use importance weighted samples [Burda, 2015] to get a better estimate\n",
    "# on the log-likelihood.\n",
    "sampler = ImportanceWeightedSampler(mc=1, iw=1)\n",
    "\n",
    "if cuda: model = model.cuda()\n",
    "elbo = SVI(model, likelihood=binary_cross_entropy, sampler=sampler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "05be3002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "[Train]\t\t J_a: 367.64, accuracy: 0.11\n",
      "[Validation]\t J_a: 412.32, accuracy: 0.09\n",
      "Epoch: 1\n",
      "[Train]\t\t J_a: 353.14, accuracy: 0.10\n",
      "[Validation]\t J_a: 408.88, accuracy: 0.09\n",
      "Epoch: 2\n",
      "[Train]\t\t J_a: 342.47, accuracy: 0.09\n",
      "[Validation]\t J_a: 406.34, accuracy: 0.09\n",
      "Epoch: 3\n",
      "[Train]\t\t J_a: 336.06, accuracy: 0.10\n",
      "[Validation]\t J_a: 404.00, accuracy: 0.09\n",
      "Epoch: 4\n",
      "[Train]\t\t J_a: 330.59, accuracy: 0.08\n",
      "[Validation]\t J_a: 403.16, accuracy: 0.09\n",
      "Epoch: 5\n",
      "[Train]\t\t J_a: 326.06, accuracy: 0.08\n",
      "[Validation]\t J_a: 401.80, accuracy: 0.09\n",
      "Epoch: 6\n",
      "[Train]\t\t J_a: 323.45, accuracy: 0.07\n",
      "[Validation]\t J_a: 401.03, accuracy: 0.09\n",
      "Epoch: 7\n",
      "[Train]\t\t J_a: 320.10, accuracy: 0.10\n",
      "[Validation]\t J_a: 400.12, accuracy: 0.09\n",
      "Epoch: 8\n",
      "[Train]\t\t J_a: 316.43, accuracy: 0.12\n",
      "[Validation]\t J_a: 398.01, accuracy: 0.09\n",
      "Epoch: 9\n",
      "[Train]\t\t J_a: 314.60, accuracy: 0.09\n",
      "[Validation]\t J_a: 397.12, accuracy: 0.09\n"
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    total_loss, accuracy = (0, 0)\n",
    "    for (x, y), (u, _) in zip(cycle(labelled), unlabelled):\n",
    "        # Wrap in variables\n",
    "        x, y, u = Variable(x), Variable(y), Variable(u)\n",
    "\n",
    "        if cuda:\n",
    "            # They need to be on the same device and be synchronized.\n",
    "            x, y = x.cuda(device=0), y.cuda(device=0)\n",
    "            u = u.cuda(device=0)\n",
    "\n",
    "        L = -elbo(x, y)\n",
    "        U = -elbo(u)\n",
    "\n",
    "        # Add auxiliary classification loss q(y|x)\n",
    "        logits = model.classify(x)\n",
    "        \n",
    "        # Regular cross entropy\n",
    "        classication_loss = torch.sum(y * torch.log(logits + 1e-8), dim=1).mean()\n",
    "\n",
    "        J_alpha = L - alpha * classication_loss + U\n",
    "\n",
    "        J_alpha.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        total_loss += J_alpha.data\n",
    "        accuracy += torch.mean((torch.max(logits, 1)[1].data == torch.max(y, 1)[1].data).float())\n",
    "        \n",
    "    if epoch % 1 == 0:\n",
    "        model.eval()\n",
    "        m = len(unlabelled)\n",
    "        print(\"Epoch: {}\".format(epoch))\n",
    "        print(\"[Train]\\t\\t J_a: {:.2f}, accuracy: {:.2f}\".format(total_loss / m, accuracy / m))\n",
    "\n",
    "        total_loss, accuracy = (0, 0)\n",
    "        for x, y in validation:\n",
    "            x, y = Variable(x), Variable(y)\n",
    "\n",
    "            if cuda:\n",
    "                x, y = x.cuda(device=0), y.cuda(device=0)\n",
    "\n",
    "            L = -elbo(x, y)\n",
    "            U = -elbo(x)\n",
    "\n",
    "            logits = model.classify(x)\n",
    "            classication_loss = -torch.sum(y * torch.log(logits + 1e-8), dim=1).mean()\n",
    "\n",
    "            J_alpha = L + alpha * classication_loss + U\n",
    "\n",
    "            total_loss += J_alpha.data\n",
    "\n",
    "            _, pred_idx = torch.max(logits, 1)\n",
    "            _, lab_idx = torch.max(y, 1)\n",
    "            accuracy += torch.mean((torch.max(logits, 1)[1].data == torch.max(y, 1)[1].data).float())\n",
    "\n",
    "        m = len(validation)\n",
    "        print(\"[Validation]\\t J_a: {:.2f}, accuracy: {:.2f}\".format(total_loss / m, accuracy / m))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "09596923",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ConvolutionalClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvolutionalClassifier, self).__init__()        \n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(64, 32, kernel_size=3)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=4)\n",
    "\n",
    "        size = int((28 - 3) + 1)//4\n",
    "        size = int((size - 3) + 1)//4\n",
    "                \n",
    "        self.fc1 = nn.Linear(32*size**2, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch, *_ = x.size()\n",
    "        x = x.view(-1, 1, 28, 28)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(x.view(batch, -1))\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return F.softmax(x, dim=-1)\n",
    "\n",
    "classifier = ConvolutionalClassifier()\n",
    "model.classifier = classifier.cuda()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1e921aa318e5430d00fe89aa1ddefe9ab510ef49c3817fcc19c2997607dbb8d0"
  },
  "kernelspec": {
   "display_name": "dissertation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
