{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6612ba4",
   "metadata": {},
   "source": [
    "This notebook serves as the Deep Bayesian Active Learning paper implementation based on:\n",
    "- https://github.com/damienlancry/DBAL/blob/master/dbal_pytorch.ipynb\n",
    "- https://github.com/wohlert/semi-supervised-pytorch/blob/master/examples/notebooks/Deep%20Generative%20Model.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6582b740",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56fa5b9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor, ToPILImage\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from skorch import NeuralNetClassifier\n",
    "from modAL.models import ActiveLearner\n",
    "from torchsummary import summary\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8800ea06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use cuda if available\n",
    "cuda = torch.cuda.is_available()\n",
    "# Add a semi supervised module\n",
    "sys.path.insert(0, './semi-supervised')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0425ef",
   "metadata": {},
   "source": [
    "### Network Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "349924b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super(CNN, self).__init__()\n",
    "        self.convs = nn.Sequential(\n",
    "                        nn.Conv2d(1, 32, 4),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Conv2d(32, 32, 4),\n",
    "                        nn.ReLU(),\n",
    "                        nn.MaxPool2d(2),\n",
    "                        nn.Dropout(0.25),\n",
    "                        nn.Flatten(),\n",
    "                        nn.Linear(11*11*32, 128),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Dropout(0.5),\n",
    "                        nn.Linear(128, 10)\n",
    "                    )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = x\n",
    "        out = self.convs(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "539f8cb0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 25, 25]             544\n",
      "              ReLU-2           [-1, 32, 25, 25]               0\n",
      "            Conv2d-3           [-1, 32, 22, 22]          16,416\n",
      "              ReLU-4           [-1, 32, 22, 22]               0\n",
      "         MaxPool2d-5           [-1, 32, 11, 11]               0\n",
      "           Dropout-6           [-1, 32, 11, 11]               0\n",
      "           Flatten-7                 [-1, 3872]               0\n",
      "            Linear-8                  [-1, 128]         495,744\n",
      "              ReLU-9                  [-1, 128]               0\n",
      "          Dropout-10                  [-1, 128]               0\n",
      "           Linear-11                   [-1, 10]           1,290\n",
      "================================================================\n",
      "Total params: 513,994\n",
      "Trainable params: 513,994\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.63\n",
      "Params size (MB): 1.96\n",
      "Estimated Total Size (MB): 2.60\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(CNN().convs, (1,28,28), device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa309851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "train = MNIST('.', train=True, download=True, transform=ToTensor())\n",
    "test = MNIST('.', train=False, download=True, transform=ToTensor())\n",
    "train_data_loader = DataLoader(train, shuffle = True, batch_size = 60_000)\n",
    "test_data_loader = DataLoader(test, shuffle = True, batch_size = 10_000)\n",
    "X_train, y_train = next(iter(train_data_loader))\n",
    "X_train = X_train.detach().cpu().numpy()\n",
    "y_train = y_train.detach().cpu().numpy()\n",
    "\n",
    "X_test, y_test = next(iter(test_data_loader))\n",
    "X_test = X_test.detach().cpu().numpy()\n",
    "y_test = y_test.detach().cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9537453a",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27f454c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(60_000, 1, 28, 28)\n",
    "X_test = X_test.reshape(10_000, 1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ac0a665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create initial labelled data\n",
    "# Take 2 samples from each digit\n",
    "initial_labelled_idx = np.array([],dtype=np.int64)\n",
    "for i in range(10):\n",
    "    idx = np.random.choice(np.where(y_train==i)[0], size=10, replace=False)\n",
    "    initial_labelled_idx = np.concatenate((initial_labelled_idx, idx))\n",
    "\n",
    "X_train_labelled_initial = X_train[initial_labelled_idx]\n",
    "y_train_labelled_initial = y_train[initial_labelled_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9dc03dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pool of unlabelled data\n",
    "X_train_unlabelled = np.delete(X_train, initial_labelled_idx, axis = 0)\n",
    "y_train_unlabelled = np.delete(y_train, initial_labelled_idx, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "921f0376",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6,\n",
       "       6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8,\n",
       "       8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_labelled_initial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a499c75",
   "metadata": {},
   "source": [
    "### Query Strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d81f0dc",
   "metadata": {},
   "source": [
    "#### Random (Uniform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "301a3d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniform(learner, X, n_instances = 1):\n",
    "    query_idx = np.random.choice(range(len(X)), size = n_instances, replace = False)\n",
    "    return query_idx, X[query_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae2d126",
   "metadata": {},
   "source": [
    "#### Max Entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ee8320",
   "metadata": {},
   "source": [
    "Formula:\n",
    "\n",
    "$$\\mathbb{H} = -\\sum_{c}p_clog(p_c)$$\n",
    "\n",
    "Where $p_c$ is the probability of the instance being in the class $c$ and is approximated by:\n",
    "\n",
    "$$p_c = \\dfrac{1}{T}\\sum_{c}p_c^{(t)}$$\n",
    "\n",
    "Where $p_c^{(t)}$ is the probability of the instance being in the class $c$ at t-th forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "debe359b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_entropy(learner, X, n_instances=1, T=100):\n",
    "    random_subset = np.random.choice(range(len(X)), size=2000, replace=False)\n",
    "    with torch.no_grad():\n",
    "        outputs = np.stack([torch.softmax(learner.estimator.forward(X[random_subset], training=True),dim=-1).cpu().numpy()\n",
    "                            for t in range(100)])\n",
    "    pc = outputs.mean(axis=0)\n",
    "    acquisition = (-pc*np.log(pc + 1e-10)).sum(axis=-1)\n",
    "    idx = (-acquisition).argsort()[:n_instances]\n",
    "    query_idx = random_subset[idx]\n",
    "    return query_idx, X[query_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ead77e",
   "metadata": {},
   "source": [
    "#### Bald"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "48e2dc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bald(learner, X, n_instances=1, T=100):\n",
    "    random_subset = np.random.choice(range(len(X)), size=2000, replace=False)\n",
    "    with torch.no_grad():\n",
    "        outputs = np.stack([torch.softmax(learner.estimator.forward(X[random_subset], training=True),dim=-1).cpu().numpy()\n",
    "                            for t in range(100)])\n",
    "    pc = outputs.mean(axis=0)\n",
    "    H   = (-pc*np.log(pc + 1e-10)).sum(axis=-1)\n",
    "    E_H = - np.mean(np.sum(outputs * np.log(outputs + 1e-10), axis=-1), axis=0)  # [batch size]\n",
    "    acquisition = H - E_H\n",
    "    idx = (-acquisition).argsort()[:n_instances]\n",
    "    query_idx = random_subset[idx]\n",
    "    return query_idx, X[query_idx]    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6640132",
   "metadata": {},
   "source": [
    "### Active Learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b42c881a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "query_strategies = {'random':{'function':uniform,\n",
    "                                'classifier': None,\n",
    "                                'learner': None,\n",
    "                                'performance_history': None},\n",
    "                    # 'max_entropy':{'function':max_entropy,\n",
    "                    #             'classifier': None,\n",
    "                    #             'learner': None,\n",
    "                    #             'performance_history': None},\n",
    "                    'bald':{'function':bald,\n",
    "                                'classifier': None,\n",
    "                                'learner': None,\n",
    "                                'performance_history': None},\n",
    "                    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8db2c23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def active_learning_procedure(query_strategy,\n",
    "                              X_test,\n",
    "                              y_test,\n",
    "                              X_pool,\n",
    "                              y_pool,\n",
    "                              X_initial,\n",
    "                              y_initial,\n",
    "                              estimator,\n",
    "                              n_queries=100,\n",
    "                              n_instances=10,\n",
    "                              query_strategy_label=''):\n",
    "    learner = ActiveLearner(estimator=estimator,\n",
    "                            X_training=X_initial,\n",
    "                            y_training=y_initial,\n",
    "                            query_strategy=query_strategy,\n",
    "                           )\n",
    "    perf_hist = [learner.score(X_test, y_test)]\n",
    "    for index in range(n_queries):\n",
    "        query_idx, query_instance = learner.query(X_pool, n_instances)\n",
    "        learner.teach(X_pool[query_idx], y_pool[query_idx])\n",
    "        X_pool = np.delete(X_pool, query_idx, axis=0)\n",
    "        y_pool = np.delete(y_pool, query_idx, axis=0)\n",
    "        model_accuracy = learner.score(X_test, y_test)\n",
    "        print('{q}Accuracy after query {n}: {acc:0.4f}'.format(q=f'[{query_strategy_label}] ', n=index + 1, acc=model_accuracy))\n",
    "        perf_hist.append(model_accuracy)\n",
    "\n",
    "    # Save after-query labelled and unlabelled data\n",
    "    torch.save(learner.X_training, f'./saved_data/X_train_labelled_{query_strategy_label}.pt')\n",
    "    torch.save(learner.y_training, f'./saved_data/y_train_labelled_{query_strategy_label}.pt')\n",
    "\n",
    "    torch.save(X_pool, f'./saved_data/X_train_unlabelled_{query_strategy_label}.pt')\n",
    "    torch.save(y_pool, f'./saved_data/y_train_unlabelled_{query_strategy_label}.pt')\n",
    "\n",
    "    return learner, perf_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8dba7250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[random] Accuracy after query 1: 0.8198\n",
      "[random] Accuracy after query 2: 0.8229\n",
      "[random] Accuracy after query 3: 0.8270\n",
      "[random] Accuracy after query 4: 0.8560\n",
      "[random] Accuracy after query 5: 0.8347\n",
      "[random] Accuracy after query 6: 0.8529\n",
      "[random] Accuracy after query 7: 0.8513\n",
      "[random] Accuracy after query 8: 0.8553\n",
      "[random] Accuracy after query 9: 0.8538\n",
      "[random] Accuracy after query 10: 0.8610\n",
      "[random] Accuracy after query 11: 0.8652\n",
      "[random] Accuracy after query 12: 0.8729\n",
      "[random] Accuracy after query 13: 0.8689\n",
      "[random] Accuracy after query 14: 0.8818\n",
      "[random] Accuracy after query 15: 0.8687\n",
      "[random] Accuracy after query 16: 0.8864\n",
      "[random] Accuracy after query 17: 0.8753\n",
      "[random] Accuracy after query 18: 0.8866\n",
      "[random] Accuracy after query 19: 0.8815\n",
      "[random] Accuracy after query 20: 0.8780\n",
      "[random] Accuracy after query 21: 0.8853\n",
      "[random] Accuracy after query 22: 0.8949\n",
      "[random] Accuracy after query 23: 0.8982\n",
      "[random] Accuracy after query 24: 0.8934\n",
      "[random] Accuracy after query 25: 0.9034\n",
      "[random] Accuracy after query 26: 0.9051\n",
      "[random] Accuracy after query 27: 0.8969\n",
      "[random] Accuracy after query 28: 0.9131\n",
      "[random] Accuracy after query 29: 0.9108\n",
      "[random] Accuracy after query 30: 0.9121\n",
      "[random] Accuracy after query 31: 0.9187\n",
      "[random] Accuracy after query 32: 0.9182\n",
      "[random] Accuracy after query 33: 0.9215\n",
      "[random] Accuracy after query 34: 0.9186\n",
      "[random] Accuracy after query 35: 0.9276\n",
      "[random] Accuracy after query 36: 0.9186\n",
      "[random] Accuracy after query 37: 0.9244\n",
      "[random] Accuracy after query 38: 0.9196\n",
      "[random] Accuracy after query 39: 0.9258\n",
      "[random] Accuracy after query 40: 0.9216\n",
      "[random] Accuracy after query 41: 0.9161\n",
      "[random] Accuracy after query 42: 0.9217\n",
      "[random] Accuracy after query 43: 0.9224\n",
      "[random] Accuracy after query 44: 0.9282\n",
      "[random] Accuracy after query 45: 0.9244\n",
      "[random] Accuracy after query 46: 0.9301\n",
      "[random] Accuracy after query 47: 0.9239\n",
      "[random] Accuracy after query 48: 0.9317\n",
      "[random] Accuracy after query 49: 0.9340\n",
      "[random] Accuracy after query 50: 0.9362\n",
      "[random] Accuracy after query 51: 0.9351\n",
      "[random] Accuracy after query 52: 0.9357\n",
      "[random] Accuracy after query 53: 0.9314\n",
      "[random] Accuracy after query 54: 0.9354\n",
      "[random] Accuracy after query 55: 0.9299\n",
      "[random] Accuracy after query 56: 0.9335\n",
      "[random] Accuracy after query 57: 0.9387\n",
      "[random] Accuracy after query 58: 0.9329\n",
      "[random] Accuracy after query 59: 0.9387\n",
      "[random] Accuracy after query 60: 0.9373\n",
      "[random] Accuracy after query 61: 0.9428\n",
      "[random] Accuracy after query 62: 0.9449\n",
      "[random] Accuracy after query 63: 0.9361\n",
      "[random] Accuracy after query 64: 0.9420\n",
      "[random] Accuracy after query 65: 0.9418\n",
      "[random] Accuracy after query 66: 0.9399\n",
      "[random] Accuracy after query 67: 0.9358\n",
      "[random] Accuracy after query 68: 0.9425\n",
      "[random] Accuracy after query 69: 0.9358\n",
      "[random] Accuracy after query 70: 0.9406\n",
      "[random] Accuracy after query 71: 0.9386\n",
      "[random] Accuracy after query 72: 0.9415\n",
      "[random] Accuracy after query 73: 0.9426\n",
      "[random] Accuracy after query 74: 0.9428\n",
      "[random] Accuracy after query 75: 0.9440\n",
      "[random] Accuracy after query 76: 0.9369\n",
      "[random] Accuracy after query 77: 0.9413\n",
      "[random] Accuracy after query 78: 0.9391\n",
      "[random] Accuracy after query 79: 0.9463\n",
      "[random] Accuracy after query 80: 0.9416\n",
      "[random] Accuracy after query 81: 0.9452\n",
      "[random] Accuracy after query 82: 0.9431\n",
      "[random] Accuracy after query 83: 0.9420\n",
      "[random] Accuracy after query 84: 0.9472\n",
      "[random] Accuracy after query 85: 0.9463\n",
      "[random] Accuracy after query 86: 0.9471\n",
      "[random] Accuracy after query 87: 0.9483\n",
      "[random] Accuracy after query 88: 0.9428\n",
      "[random] Accuracy after query 89: 0.9466\n",
      "[random] Accuracy after query 90: 0.9463\n",
      "[random] Accuracy after query 91: 0.9479\n",
      "[random] Accuracy after query 92: 0.9464\n",
      "[random] Accuracy after query 93: 0.9491\n",
      "[random] Accuracy after query 94: 0.9493\n",
      "[random] Accuracy after query 95: 0.9491\n",
      "[random] Accuracy after query 96: 0.9496\n",
      "[random] Accuracy after query 97: 0.9512\n",
      "[random] Accuracy after query 98: 0.9537\n",
      "[random] Accuracy after query 99: 0.9507\n",
      "[random] Accuracy after query 100: 0.9492\n",
      "[bald] Accuracy after query 1: 0.8303\n",
      "[bald] Accuracy after query 2: 0.8275\n",
      "[bald] Accuracy after query 3: 0.8521\n",
      "[bald] Accuracy after query 4: 0.8192\n",
      "[bald] Accuracy after query 5: 0.8565\n",
      "[bald] Accuracy after query 6: 0.8542\n",
      "[bald] Accuracy after query 7: 0.8590\n",
      "[bald] Accuracy after query 8: 0.8606\n",
      "[bald] Accuracy after query 9: 0.8802\n",
      "[bald] Accuracy after query 10: 0.9002\n",
      "[bald] Accuracy after query 11: 0.8956\n",
      "[bald] Accuracy after query 12: 0.8973\n",
      "[bald] Accuracy after query 13: 0.9134\n",
      "[bald] Accuracy after query 14: 0.9189\n",
      "[bald] Accuracy after query 15: 0.9148\n",
      "[bald] Accuracy after query 16: 0.9036\n",
      "[bald] Accuracy after query 17: 0.9237\n",
      "[bald] Accuracy after query 18: 0.9295\n",
      "[bald] Accuracy after query 19: 0.9287\n",
      "[bald] Accuracy after query 20: 0.9241\n",
      "[bald] Accuracy after query 21: 0.9244\n",
      "[bald] Accuracy after query 22: 0.9342\n",
      "[bald] Accuracy after query 23: 0.9376\n",
      "[bald] Accuracy after query 24: 0.9361\n",
      "[bald] Accuracy after query 25: 0.9358\n",
      "[bald] Accuracy after query 26: 0.9480\n",
      "[bald] Accuracy after query 27: 0.9450\n",
      "[bald] Accuracy after query 28: 0.9524\n",
      "[bald] Accuracy after query 29: 0.9484\n",
      "[bald] Accuracy after query 30: 0.9440\n",
      "[bald] Accuracy after query 31: 0.9453\n",
      "[bald] Accuracy after query 32: 0.9505\n",
      "[bald] Accuracy after query 33: 0.9569\n",
      "[bald] Accuracy after query 34: 0.9569\n",
      "[bald] Accuracy after query 35: 0.9595\n",
      "[bald] Accuracy after query 36: 0.9556\n",
      "[bald] Accuracy after query 37: 0.9617\n",
      "[bald] Accuracy after query 38: 0.9471\n",
      "[bald] Accuracy after query 39: 0.9619\n",
      "[bald] Accuracy after query 40: 0.9615\n",
      "[bald] Accuracy after query 41: 0.9581\n",
      "[bald] Accuracy after query 42: 0.9577\n",
      "[bald] Accuracy after query 43: 0.9571\n",
      "[bald] Accuracy after query 44: 0.9559\n",
      "[bald] Accuracy after query 45: 0.9625\n",
      "[bald] Accuracy after query 46: 0.9658\n",
      "[bald] Accuracy after query 47: 0.9629\n",
      "[bald] Accuracy after query 48: 0.9655\n",
      "[bald] Accuracy after query 49: 0.9670\n",
      "[bald] Accuracy after query 50: 0.9650\n",
      "[bald] Accuracy after query 51: 0.9687\n",
      "[bald] Accuracy after query 52: 0.9641\n",
      "[bald] Accuracy after query 53: 0.9665\n",
      "[bald] Accuracy after query 54: 0.9667\n",
      "[bald] Accuracy after query 55: 0.9708\n",
      "[bald] Accuracy after query 56: 0.9693\n",
      "[bald] Accuracy after query 57: 0.9695\n",
      "[bald] Accuracy after query 58: 0.9711\n",
      "[bald] Accuracy after query 59: 0.9740\n",
      "[bald] Accuracy after query 60: 0.9676\n",
      "[bald] Accuracy after query 61: 0.9733\n",
      "[bald] Accuracy after query 62: 0.9733\n",
      "[bald] Accuracy after query 63: 0.9743\n",
      "[bald] Accuracy after query 64: 0.9752\n",
      "[bald] Accuracy after query 65: 0.9708\n",
      "[bald] Accuracy after query 66: 0.9751\n",
      "[bald] Accuracy after query 67: 0.9701\n",
      "[bald] Accuracy after query 68: 0.9717\n",
      "[bald] Accuracy after query 69: 0.9749\n",
      "[bald] Accuracy after query 70: 0.9769\n",
      "[bald] Accuracy after query 71: 0.9766\n",
      "[bald] Accuracy after query 72: 0.9743\n"
     ]
    }
   ],
   "source": [
    "for query_strategy_name, query_strategy in query_strategies.items():\n",
    "    query_strategy['classifier'] = NeuralNetClassifier(CNN,\n",
    "                                max_epochs=50,\n",
    "                                batch_size=128,\n",
    "                                lr=0.001,\n",
    "                                optimizer=torch.optim.Adam,\n",
    "                                criterion=torch.nn.CrossEntropyLoss,\n",
    "                                train_split=None,\n",
    "                                verbose=0,\n",
    "                                device=device)\n",
    "    query_strategy['learner'], query_strategy['performance_history'] = active_learning_procedure(query_strategy['function'],\n",
    "                                                X_test,\n",
    "                                                y_test,\n",
    "                                                X_train_unlabelled,\n",
    "                                                y_train_unlabelled,\n",
    "                                                X_train_labelled_initial,\n",
    "                                                y_train_labelled_initial,\n",
    "                                                query_strategy['classifier'],\n",
    "                                                query_strategy_label=query_strategy_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69232167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save models and data\n",
    "performance_histories = {}\n",
    "for query_strategy_name, query_strategy in query_strategies.items():\n",
    "    # Save classifiers\n",
    "    query_strategy['classifier'].save_params(f_params=f'./saved_models/{query_strategy_name}.pkl')\n",
    "\n",
    "    # Save data after queries:\n",
    "    # torch.save(query_strategy['learner'].X_training, f'./saved_data/X_training_{query_strategy_name}.pt')\n",
    "    # torch.save(query_strategy['learner'].y_training, f'./saved_data/y_training_{query_strategy_name}.pt')\n",
    "\n",
    "# Save initial labelled and unlabelled data\n",
    "X_train_labelled_initial = X_train[initial_labelled_idx]\n",
    "y_train_labelled_initial = y_train[initial_labelled_idx]\n",
    "torch.save(X_train_labelled_initial, f'./saved_data/X_train_labelled.pt')\n",
    "torch.save(y_train_labelled_initial, f'./saved_data/y_train_labelled.pt')\n",
    "torch.save(X_train_unlabelled, f'./saved_data/X_train_unlabelled.pt')\n",
    "torch.save(y_train_unlabelled, f'./saved_data/y_train_unlabelled.pt')\n",
    "\n",
    "# Save test data\n",
    "torch.save(X_test, f'./saved_data/X_test.pt')\n",
    "torch.save(y_test, f'./saved_data/y_test.pt')\n",
    "\n",
    "# Save performance histories (preprocessing)\n",
    "performance_histories = {query_strategy_name: query_strategy['performance_history'] for query_strategy_name, query_strategy in query_strategies.items()}\n",
    "pd.DataFrame(performance_histories).to_csv(f'./saved_data/active_learning_performance_histories.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6654fe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fb24c8285b0>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot\n",
    "sns.set()\n",
    "# plt.plot(query_strategies['max_entropy']['performance_history'], label=\"max entropy\")\n",
    "plt.plot(query_strategies['bald']['performance_history'], label=\"bald\")\n",
    "plt.plot(query_strategies['random']['performance_history'], label=\"random\")\n",
    "plt.ylim([0.7,1])\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5e79de",
   "metadata": {},
   "source": [
    "###  Semi-supervised Learning\n",
    "\n",
    "<img src=\"./images/dgm.png\" width=\"400px\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "042cd798",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/ucl/dissertation/./semi-supervised/models/vae.py:114: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
      "  init.xavier_normal(m.weight.data)\n"
     ]
    }
   ],
   "source": [
    "from models import DeepGenerativeModel\n",
    "\n",
    "x_dim = 784\n",
    "y_dim = 10\n",
    "z_dim = 32\n",
    "h_dim = [256, 128]\n",
    "\n",
    "model = DeepGenerativeModel([x_dim, y_dim, z_dim, h_dim])\n",
    "# model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35b66488",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datautils import SemiSupervisedActiveLearningDataset\n",
    "from utils import onehot\n",
    "flatten_bernoulli = lambda x: transforms.ToTensor()(x).view(-1).bernoulli()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4edae815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./saved_data/X_train_labelled_bald.pt\n",
      "./saved_data/y_train_labelled_bald.pt\n",
      "1100 1100\n",
      "./saved_data/X_train_unlabelled_bald.pt\n",
      "./saved_data/y_train_unlabelled_bald.pt\n",
      "58901 58901\n",
      "./saved_data/X_test.pt\n",
      "./saved_data/y_test.pt\n",
      "10000 10000\n"
     ]
    }
   ],
   "source": [
    "from datautils import get_mnist\n",
    "\n",
    "# Only use 10 labelled examples per class\n",
    "# The rest of the data is unlabelled.\n",
    "labelled, unlabelled, test = get_mnist(location=\"./saved_data\", batch_size=64, labels_per_class=10, algorithm='bald')\n",
    "alpha = 0.1 * len(unlabelled) / len(labelled)\n",
    "\n",
    "def binary_cross_entropy(y_pred, y):\n",
    "    return -torch.sum(y * torch.log(y_pred + 1e-8) + (1 - y) * torch.log(1 - y_pred + 1e-8), dim=-1)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4, betas=(0.9, 0.999))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5563ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import cycle\n",
    "from inference import SVI, ImportanceWeightedSampler\n",
    "\n",
    "# You can use importance weighted samples [Burda, 2015] to get a better estimate\n",
    "# on the log-likelihood.\n",
    "sampler = ImportanceWeightedSampler(mc=1, iw=1)\n",
    "\n",
    "if cuda: model = model.cuda()\n",
    "elbo = SVI(model, likelihood=binary_cross_entropy, sampler=sampler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d45d84fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "[Train]\t\t J_a: 112.78, accuracy: 0.46\n",
      "[Validation]\t J_a: 77.42, accuracy: 0.33\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m J_alpha \u001b[38;5;241m=\u001b[39m L \u001b[38;5;241m-\u001b[39m alpha \u001b[38;5;241m*\u001b[39m classication_loss \u001b[38;5;241m+\u001b[39m U\n\u001b[1;32m     26\u001b[0m J_alpha\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 27\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     30\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m J_alpha\u001b[38;5;241m.\u001b[39mdata\n",
      "File \u001b[0;32m~/anaconda3/envs/dissertation/lib/python3.8/site-packages/torch/optim/optimizer.py:109\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    107\u001b[0m profile_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimizer.step#\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.step\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m--> 109\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/dissertation/lib/python3.8/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/dissertation/lib/python3.8/site-packages/torch/optim/adam.py:157\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    153\u001b[0m                 max_exp_avg_sqs\u001b[38;5;241m.\u001b[39mappend(state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_exp_avg_sq\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    155\u001b[0m             state_steps\u001b[38;5;241m.\u001b[39mappend(state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m--> 157\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m         \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m         \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m         \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m         \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m         \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m         \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m         \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m         \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m         \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m         \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m         \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m         \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m         \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m         \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/anaconda3/envs/dissertation/lib/python3.8/site-packages/torch/optim/adam.py:213\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    211\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 213\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/dissertation/lib/python3.8/site-packages/torch/optim/adam.py:258\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable)\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m step_t\u001b[38;5;241m.\u001b[39mis_cuda, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf capturable=False, state_steps should not be CUDA tensors.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;66;03m# update step\u001b[39;00m\n\u001b[0;32m--> 258\u001b[0m step_t \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weight_decay \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    261\u001b[0m     grad \u001b[38;5;241m=\u001b[39m grad\u001b[38;5;241m.\u001b[39madd(param, alpha\u001b[38;5;241m=\u001b[39mweight_decay)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    total_loss, accuracy = (0, 0)\n",
    "    for (x, y), (u, _) in zip(cycle(labelled), unlabelled):\n",
    "        # Wrap in variables\n",
    "        x, y, u = Variable(x), Variable(y), Variable(u)\n",
    "\n",
    "        if cuda:\n",
    "            # They need to be on the same device and be synchronized.\n",
    "            x, y = x.cuda(device=0), y.cuda(device=0)\n",
    "            u = u.cuda(device=0)\n",
    "\n",
    "        L = -elbo(x, y)\n",
    "        U = -elbo(u)\n",
    "\n",
    "        # Add auxiliary classification loss q(y|x)\n",
    "        logits = model.classify(x)\n",
    "        \n",
    "        # Regular cross entropy\n",
    "        classication_loss = torch.sum(y * torch.log(logits + 1e-8), dim=1).mean()\n",
    "\n",
    "        J_alpha = L - alpha * classication_loss + U\n",
    "\n",
    "        J_alpha.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        total_loss += J_alpha.data\n",
    "        accuracy += torch.mean((torch.max(logits, 1)[1].data == torch.max(y, 1)[1].data).float())\n",
    "        \n",
    "    if epoch % 1 == 0:\n",
    "        model.eval()\n",
    "        m = len(unlabelled)\n",
    "        print(\"Epoch: {}\".format(epoch))\n",
    "        print(\"[Train]\\t\\t J_a: {:.2f}, accuracy: {:.2f}\".format(total_loss / m, accuracy / m))\n",
    "\n",
    "        total_loss, accuracy = (0, 0)\n",
    "        for x, y in test:\n",
    "            x, y = Variable(x), Variable(y)\n",
    "\n",
    "            if cuda:\n",
    "                x, y = x.cuda(device=0), y.cuda(device=0)\n",
    "\n",
    "            L = -elbo(x, y)\n",
    "            U = -elbo(x)\n",
    "\n",
    "            logits = model.classify(x)\n",
    "            classication_loss = -torch.sum(y * torch.log(logits + 1e-8), dim=1).mean()\n",
    "\n",
    "            J_alpha = L + alpha * classication_loss + U\n",
    "\n",
    "            total_loss += J_alpha.data\n",
    "\n",
    "            _, pred_idx = torch.max(logits, 1)\n",
    "            _, lab_idx = torch.max(y, 1)\n",
    "            accuracy += torch.mean((torch.max(logits, 1)[1].data == torch.max(y, 1)[1].data).float())\n",
    "\n",
    "        m = len(test)\n",
    "        print(\"[Validation]\\t J_a: {:.2f}, accuracy: {:.2f}\".format(total_loss / m, accuracy / m))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbbd824",
   "metadata": {},
   "source": [
    "### Original DGM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "042cd798",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import DeepGenerativeModel\n",
    "\n",
    "y_dim = 10\n",
    "z_dim = 32\n",
    "h_dim = [256, 128]\n",
    "\n",
    "model = DeepGenerativeModel([784, y_dim, z_dim, h_dim])\n",
    "# model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0540f75f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "from datautils import get_mnist, get_mnist_legacy, get_mnist_v2\n",
    "\n",
    "# Only use 10 labelled examples per class\n",
    "# The rest of the data is unlabelled.\n",
    "labelled, unlabelled, test = get_mnist_legacy(location=\"./\", batch_size=64, labels_per_class=10)\n",
    "alpha = 0.1 * len(unlabelled) / len(labelled)\n",
    "\n",
    "def binary_cross_entropy(y_pred, y):\n",
    "    return -torch.sum(y * torch.log(y_pred + 1e-8) + (1 - y) * torch.log(1 - y_pred + 1e-8), dim=-1)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4, betas=(0.9, 0.999))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aadde7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import cycle\n",
    "from inference import SVI, ImportanceWeightedSampler\n",
    "\n",
    "# You can use importance weighted samples [Burda, 2015] to get a better estimate\n",
    "# on the log-likelihood.\n",
    "sampler = ImportanceWeightedSampler(mc=1, iw=1)\n",
    "\n",
    "if cuda: model = model.cuda()\n",
    "elbo = SVI(model, likelihood=binary_cross_entropy, sampler=sampler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1e1d1779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "[Train]\t\t J_a: 339.83, accuracy: 1.00\n",
      "[Validation]\t J_a: 355.88, accuracy: 0.73\n",
      "Epoch: 1\n",
      "[Train]\t\t J_a: 261.63, accuracy: 1.00\n",
      "[Validation]\t J_a: 345.94, accuracy: 0.77\n",
      "Epoch: 2\n",
      "[Train]\t\t J_a: 242.33, accuracy: 1.00\n",
      "[Validation]\t J_a: 348.58, accuracy: 0.77\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [26]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Regular cross entropy\u001b[39;00m\n\u001b[1;32m     22\u001b[0m classication_loss \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(y \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mlog(logits \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1e-8\u001b[39m), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mmean()\n\u001b[0;32m---> 24\u001b[0m J_alpha \u001b[38;5;241m=\u001b[39m \u001b[43mL\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mclassication_loss\u001b[49m \u001b[38;5;241m+\u001b[39m U\n\u001b[1;32m     26\u001b[0m J_alpha\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     27\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/root/anaconda3/envs/dissertation/lib/python3.8/multiprocessing/queues.py\", line 245, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/root/anaconda3/envs/dissertation/lib/python3.8/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/root/anaconda3/envs/dissertation/lib/python3.8/multiprocessing/connection.py\", line 411, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/root/anaconda3/envs/dissertation/lib/python3.8/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/anaconda3/envs/dissertation/lib/python3.8/multiprocessing/queues.py\", line 245, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/root/anaconda3/envs/dissertation/lib/python3.8/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/root/anaconda3/envs/dissertation/lib/python3.8/multiprocessing/connection.py\", line 411, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/root/anaconda3/envs/dissertation/lib/python3.8/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    },
    {
     "ename": "EOFError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/dissertation/lib/python3.8/multiprocessing/resource_sharer.py:142\u001b[0m, in \u001b[0;36m_ResourceSharer._serve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 142\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_listener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccept\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m conn:\n\u001b[1;32m    143\u001b[0m             msg \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mrecv()\n\u001b[1;32m    144\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m msg \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/dissertation/lib/python3.8/multiprocessing/connection.py:466\u001b[0m, in \u001b[0;36mListener.accept\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    464\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_authkey:\n\u001b[1;32m    465\u001b[0m     deliver_challenge(c, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_authkey)\n\u001b[0;32m--> 466\u001b[0m     \u001b[43manswer_challenge\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_authkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    467\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m c\n",
      "File \u001b[0;32m~/anaconda3/envs/dissertation/lib/python3.8/multiprocessing/connection.py:752\u001b[0m, in \u001b[0;36manswer_challenge\u001b[0;34m(connection, authkey)\u001b[0m\n\u001b[1;32m    749\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(authkey, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[1;32m    750\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    751\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAuthkey must be bytes, not \u001b[39m\u001b[38;5;132;01m{0!s}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mtype\u001b[39m(authkey)))\n\u001b[0;32m--> 752\u001b[0m message \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m)\u001b[49m         \u001b[38;5;66;03m# reject large message\u001b[39;00m\n\u001b[1;32m    753\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m message[:\u001b[38;5;28mlen\u001b[39m(CHALLENGE)] \u001b[38;5;241m==\u001b[39m CHALLENGE, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessage = \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m message\n\u001b[1;32m    754\u001b[0m message \u001b[38;5;241m=\u001b[39m message[\u001b[38;5;28mlen\u001b[39m(CHALLENGE):]\n",
      "File \u001b[0;32m~/anaconda3/envs/dissertation/lib/python3.8/multiprocessing/connection.py:216\u001b[0m, in \u001b[0;36m_ConnectionBase.recv_bytes\u001b[0;34m(self, maxlength)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m maxlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m maxlength \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnegative maxlength\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 216\u001b[0m buf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_recv_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaxlength\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m buf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bad_message_length()\n",
      "File \u001b[0;32m~/anaconda3/envs/dissertation/lib/python3.8/multiprocessing/connection.py:414\u001b[0m, in \u001b[0;36mConnection._recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_recv_bytes\u001b[39m(\u001b[38;5;28mself\u001b[39m, maxsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 414\u001b[0m     buf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_recv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    415\u001b[0m     size, \u001b[38;5;241m=\u001b[39m struct\u001b[38;5;241m.\u001b[39munpack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m!i\u001b[39m\u001b[38;5;124m\"\u001b[39m, buf\u001b[38;5;241m.\u001b[39mgetvalue())\n\u001b[1;32m    416\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m size \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/dissertation/lib/python3.8/multiprocessing/connection.py:383\u001b[0m, in \u001b[0;36mConnection._recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    382\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m remaining \u001b[38;5;241m==\u001b[39m size:\n\u001b[0;32m--> 383\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEOFError\u001b[39;00m\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    385\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgot end of file during message\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mEOFError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    total_loss, accuracy = (0, 0)\n",
    "    for (x, y), (u, _) in zip(cycle(labelled), unlabelled):\n",
    "        # Wrap in variables\n",
    "        x, y, u = Variable(x), Variable(y), Variable(u)\n",
    "\n",
    "        if cuda:\n",
    "            # They need to be on the same device and be synchronized.\n",
    "            x, y = x.cuda(device=0), y.cuda(device=0)\n",
    "            u = u.cuda(device=0)\n",
    "\n",
    "        L = -elbo(x, y)\n",
    "        U = -elbo(u)\n",
    "\n",
    "        # Add auxiliary classification loss q(y|x)\n",
    "        logits = model.classify(x)\n",
    "        \n",
    "        # Regular cross entropy\n",
    "        classication_loss = torch.sum(y * torch.log(logits + 1e-8), dim=1).mean()\n",
    "\n",
    "        J_alpha = L - alpha * classication_loss + U\n",
    "\n",
    "        J_alpha.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        total_loss += J_alpha.data\n",
    "        accuracy += torch.mean((torch.max(logits, 1)[1].data == torch.max(y, 1)[1].data).float())\n",
    "        \n",
    "    if epoch % 1 == 0:\n",
    "        model.eval()\n",
    "        m = len(unlabelled)\n",
    "        print(\"Epoch: {}\".format(epoch))\n",
    "        print(\"[Train]\\t\\t J_a: {:.2f}, accuracy: {:.2f}\".format(total_loss / m, accuracy / m))\n",
    "\n",
    "        total_loss, accuracy = (0, 0)\n",
    "        for x, y in test:\n",
    "            x, y = Variable(x), Variable(y)\n",
    "\n",
    "            if cuda:\n",
    "                x, y = x.cuda(device=0), y.cuda(device=0)\n",
    "\n",
    "            L = -elbo(x, y)\n",
    "            U = -elbo(x)\n",
    "\n",
    "            logits = model.classify(x)\n",
    "            classication_loss = -torch.sum(y * torch.log(logits + 1e-8), dim=1).mean()\n",
    "\n",
    "            J_alpha = L + alpha * classication_loss + U\n",
    "\n",
    "            total_loss += J_alpha.data\n",
    "\n",
    "            _, pred_idx = torch.max(logits, 1)\n",
    "            _, lab_idx = torch.max(y, 1)\n",
    "            accuracy += torch.mean((torch.max(logits, 1)[1].data == torch.max(y, 1)[1].data).float())\n",
    "\n",
    "        m = len(test)\n",
    "        print(\"[Validation]\\t J_a: {:.2f}, accuracy: {:.2f}\".format(total_loss / m, accuracy / m))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e33b153",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from datautils import get_mnist_dataset, get_mnist_legacy_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c84dc02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./saved_data/X_train_labelled.pt\n",
      "./saved_data/y_train_labelled.pt\n",
      "100 100\n",
      "./saved_data/X_train_unlabelled.pt\n",
      "./saved_data/y_train_unlabelled.pt\n",
      "59901 59901\n",
      "./saved_data/X_test.pt\n",
      "./saved_data/y_test.pt\n",
      "10000 10000\n"
     ]
    }
   ],
   "source": [
    "l, u, t = get_mnist_dataset(location=\"./saved_data\", batch_size=64, labels_per_class=10, algorithm=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b212c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "tr, va = get_mnist_legacy_dataset(location=\"./\", batch_size=64, labels_per_class=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "731e1de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.load('./saved_data/y_train_labelled.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "818e2f97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "234ffe76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 7, 0,  ..., 5, 3, 1])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5d676ff1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,  51, 159, 253, 159,  50,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          48, 238, 252, 252, 252, 237,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  54,\n",
       "         227, 253, 252, 239, 233, 252,  57,   6,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  10,  60, 224,\n",
       "         252, 253, 252, 202,  84, 252, 253, 122,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 163, 252, 252,\n",
       "         252, 253, 252, 252,  96, 189, 253, 167,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  51, 238, 253, 253,\n",
       "         190, 114, 253, 228,  47,  79, 255, 168,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,  48, 238, 252, 252, 179,\n",
       "          12,  75, 121,  21,   0,   0, 253, 243,  50,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,  38, 165, 253, 233, 208,  84,\n",
       "           0,   0,   0,   0,   0,   0, 253, 252, 165,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   7, 178, 252, 240,  71,  19,  28,\n",
       "           0,   0,   0,   0,   0,   0, 253, 252, 195,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,  57, 252, 252,  63,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0, 253, 252, 195,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0, 198, 253, 190,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0, 255, 253, 196,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,  76, 246, 252, 112,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0, 253, 252, 148,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,  85, 252, 230,  25,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   7, 135, 253, 186,  12,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,  85, 252, 223,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   7, 131, 252, 225,  71,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,  85, 252, 145,   0,   0,   0,   0,   0,\n",
       "           0,   0,  48, 165, 252, 173,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,  86, 253, 225,   0,   0,   0,   0,   0,\n",
       "           0, 114, 238, 253, 162,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,  85, 252, 249, 146,  48,  29,  85, 178,\n",
       "         225, 253, 223, 167,  56,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,  85, 252, 252, 252, 229, 215, 252, 252,\n",
       "         252, 196, 130,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,  28, 199, 252, 252, 253, 252, 252, 233,\n",
       "         145,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,  25, 128, 252, 253, 252, 141,  37,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]],\n",
       "       dtype=torch.uint8)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr.data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708effda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1e921aa318e5430d00fe89aa1ddefe9ab510ef49c3817fcc19c2997607dbb8d0"
  },
  "kernelspec": {
   "display_name": "dissertation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
